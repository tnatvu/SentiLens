{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Data preparation](#toc1_)    \n",
    "  - 1.1. [Tokenize sentence and aspect BIO encoding class](#toc1_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from highlight_text import HighlightText, ax_text, fig_text\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# from sklearn_crfsuite import CRF\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Data preparation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. <a id='toc1_1_'></a>[Tokenize sentence and aspect BIO encoding class](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceToken:\n",
    "  '''\n",
    "    SentenceToken\n",
    "\n",
    "  '''\n",
    "  def __init__(self, sentence, aspect_type=None, aspects=None, sentence_id=None):\n",
    "    \n",
    "    if sentence_id is not None:\n",
    "      print(sentence_id)\n",
    "\n",
    "    self.sentence_id = sentence_id\n",
    "    self.sentence = sentence.replace(u\"\\u00A0\", \" \").replace(u'\\xa0',' ') # Double check '\\xa0'\n",
    "                            \n",
    "    self.aspect_bio_tags = None\n",
    "    self.unified_aspect_bio_tags = None\n",
    "    self.token_span = None\n",
    "    self.space_pre_token = None\n",
    "\n",
    "    # Tokenize sentence\n",
    "    self.__tokenize_sentence(self.sentence)\n",
    "\n",
    "    if aspect_type == 'dict':\n",
    "      self.set_aspect_tagging_from_dict(aspects)\n",
    "    elif aspect_type == 'bio':\n",
    "      self.set_aspect_bio_tags(aspects)\n",
    "    elif aspect_type == 'unified bio':\n",
    "      self.set_aspect_unified_bio_tags(aspects)\n",
    "  \n",
    "  def __tokenize_sentence(self, sentence):\n",
    "    # self.sentence = sentence\n",
    "    \n",
    "    token_span = list(TreebankWordTokenizer().span_tokenize(sentence))\n",
    "\n",
    "    new_token_span = []\n",
    "    \n",
    "    for k in token_span:\n",
    "      token_start = k[0]\n",
    "      token_end = k[1]\n",
    "\n",
    "      token = sentence[token_start:token_end]\n",
    "      sub_tokens = re.split(r'([^\\w,\\d])', token)\n",
    "      \n",
    "      sub_token_start = token_start\n",
    "      for sub_token in sub_tokens:\n",
    "        if len(sub_token) != 0:\n",
    "          sub_token_end = sub_token_start + len(sub_token)\n",
    "          new_token_span.append((sub_token_start, sub_token_end))\n",
    "          sub_token_start = sub_token_end\n",
    "    \n",
    "    self.token_span = new_token_span\n",
    "    self.space_pre_token = [True if sentence[k[0]-1:k[0]] == ' ' else False for i,k in enumerate(new_token_span)]\n",
    "\n",
    "\n",
    "  def set_aspect_tagging_from_dict(self, aspects):\n",
    "    polarity_map = {'positive':'POS'\n",
    "              ,'negative': 'NEG'\n",
    "              ,'conflict': 'NEG' # Switch to Negative\n",
    "              ,'neutral': 'NEU'}\n",
    "    \n",
    "    bio_tags = ['O'] * len(self.token_span)\n",
    "    unified_bio_tags = bio_tags\n",
    "\n",
    "    for x in aspects:\n",
    "      if x['term'] != '':\n",
    "        # print(x['term'], int(x['from']), int(x['to']))\n",
    "        aspect_from = int(x['from'])\n",
    "        aspect_to = int(x['to'])\n",
    "        polarity = '-' + polarity_map[x['polarity']]\n",
    "        aspect_token_ids =  [i for i, v in enumerate(self.token_span) if (v[0] >= aspect_from) & (v[1] <= aspect_to)]\n",
    "        aspect_from_index = min(aspect_token_ids)\n",
    "        aspect_to_index = max(aspect_token_ids)\n",
    "        aspect_from = int(x['from'])\n",
    "        aspect_length = aspect_to_index - aspect_from_index\n",
    "        bio_tags = bio_tags[:aspect_from_index] + ['B'] + ['I'] * (aspect_length) + bio_tags[aspect_to_index+1:]\n",
    "        unified_bio_tags = unified_bio_tags[:aspect_from_index] + ['B' + polarity] + ['I'+ polarity] * (aspect_length) + unified_bio_tags[aspect_to_index+1:]\n",
    "    \n",
    "    self.set_aspect_bio_tags(bio_tags)\n",
    "    self.set_aspect_unified_bio_tags(unified_bio_tags)\n",
    "\n",
    "  def rebuild_sentence_from_token(self):\n",
    "    return ''.join([(' ' if self.space_pre_token[i] else '') + self.sentence[k[0]:k[1]] for i, k in enumerate(self.token_span)])\n",
    "  \n",
    "  def get_sentence_token_with_aspect_bio_tag(self, unified_bio_tag=False):\n",
    "    if (unified_bio_tag == False) & (self.aspect_bio_tags is None):\n",
    "      raise Exception('No BIO tags provided. Use \"SentenceToken.set_aspect_bio_tags()\" method to add bio_tags')\n",
    "    elif (unified_bio_tag == True) & (self.aspect_unified_bio_tags is None):\n",
    "      raise Exception('No Unified BIO tags provided. Use \"SentenceToken.set_aspect_unified_bio_tags()\" method to add unified_bio_tags')\n",
    "    else:\n",
    "      return [(self.sentence[k[0]:k[1]], self.aspect_unified_bio_tags[i] if unified_bio_tag else self.aspect_bio_tags[i]) for i, k in enumerate(self.token_span)]\n",
    "\n",
    "  def set_aspect_bio_tags(self, aspect_bio_tags):\n",
    "    self.aspect_bio_tags = aspect_bio_tags\n",
    "    self.aspect_unified_bio_tags = aspect_bio_tags\n",
    "\n",
    "  def set_aspect_unified_bio_tags(self, aspect_unified_bio_tags):\n",
    "    self.aspect_unified_bio_tags = aspect_unified_bio_tags\n",
    "    self.aspect_bio_tags = [k[0:1] for k in aspect_unified_bio_tags]\n",
    "\n",
    "  def check_rebuild_sentence_from_token(self):\n",
    "    return re.sub(r'\\s+', ' ',self.sentence.strip()) == self.rebuild_sentence_from_token().strip()\n",
    "  \n",
    "  def get_tokens(self):\n",
    "    return [self.sentence[k[0]:k[1]] for k in self.token_span]\n",
    "\n",
    "  def check_rebuild_aspect_terms(self, aspect_dict):\n",
    "    # print(self.token_span)\n",
    "    aspect_dict = sorted(aspect_dict, key=lambda d: int(d['from']))\n",
    "    # aspect_input = ', '.join([k['term'] for k in aspect_dict])\n",
    "    # aspect_computed = ''.join([(',' if k == 'B' else '') + (' ' if self.space_pre_token[i] else '') + self.sentence[self.token_span[i][0]:self.token_span[i][1]] for i,k in enumerate(self.aspect_bio_tags) if k in ['B','I'] ])[2:]\n",
    "    aspect_input = [k['term'].replace(u\"\\u00A0\", \" \").replace(u'\\xa0',' ') for k in aspect_dict if k['term'] != '' ]\n",
    "    aspect_computed = []\n",
    "    aspect = ''\n",
    "    \n",
    "    for i,k in enumerate(self.aspect_bio_tags):\n",
    "      # print(i, len(self.aspect_bio_tags), i == (len(self.aspect_bio_tags) - 1))\n",
    "      token = self.sentence[self.token_span[i][0]:self.token_span[i][1]]\n",
    "      # print(token, k)\n",
    "      \n",
    "      if k == 'B':\n",
    "        if (self.aspect_bio_tags[i-1] == 'B' if i > 0 else False):\n",
    "          aspect_computed.append(aspect)\n",
    "        aspect = token\n",
    "      elif k == 'I':\n",
    "        aspect += ' ' * ((self.token_span[i][0] -  self.token_span[i-1][1]) if i > 0 else 0) + token\n",
    "        # print(aspect)\n",
    "      \n",
    "      # print('Curr ', token, ' is aspect ', aspect)\n",
    "      if (aspect != '') & ((k == 'O') or (i == (len(self.aspect_bio_tags) - 1))):\n",
    "          aspect_computed.append(aspect)\n",
    "          aspect = ''\n",
    "      \n",
    "      # print(((self.aspect_bio_tags[i-1] == 'B') & (k == 'B')))\n",
    "      # print(aspect_computed)\n",
    "    # if aspect != '':\n",
    "    #   aspect_computed.append(aspect)\n",
    "    # aspect_computed = [(',' if k == 'B' else '') + (' ' if self.space_pre_token[i] else '') + self.sentence[self.token_span[i][0]:self.token_span[i][1]] for i,k in enumerate(self.aspect_bio_tags) if k in ['B','I'] ])[2:]\n",
    "    # print(aspect_computed)\n",
    "    return [aspect_input == aspect_computed, aspect_input, aspect_computed]\n",
    "\n",
    "  def __str__(self):\n",
    "    return self.rebuild_sentence_from_token()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_json('data/laptop/train.json')\n",
    "# # df_train.set_index('id', inplace=True).reset_index()\n",
    "# print('df_train shape: ', df_train.shape)\n",
    "\n",
    "# df_val = pd.read_json('data/laptop/validate.json') # This will only be used for the very last step to evaluate how well the model is, but is input now for validating the BIO tagging to ensure the function works properly\n",
    "# # df_val.set_index('id', inplace=True).reset_index()\n",
    "# print('df_val shape: ', df_val.shape)\n",
    "\n",
    "# # First, I will need to drop some duplicated data in our training dataset, as identified in the EDA process.\n",
    "# df_train.drop_duplicates(subset='text', inplace=True)\n",
    "\n",
    "# # We have removed 12 duplicated records in our training dataset\n",
    "# print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_Data():\n",
    "  df_train = pd.read_json('data/laptop/train.json')\n",
    "  # First, I will need to drop some duplicated data in our training dataset, as identified in the EDA process.\n",
    "  # We have removed 12 duplicated records in our training dataset\n",
    "  df_train.drop_duplicates(subset='text', inplace=True)\n",
    "  print('df_train shape: ', df_train.shape)\n",
    "\n",
    "  df_val = pd.read_json('data/laptop/validate.json') # This will only be used for the very last step to evaluate how well the model is, but is input now for validating the BIO tagging to ensure the function works properly\n",
    "  # df_val.set_index('id', inplace=True).reset_index()\n",
    "  print('df_val shape: ', df_val.shape)\n",
    "\n",
    "  df_train['sentence_token'] = df_train.apply(lambda x: SentenceToken(x['text'], 'dict', x['aspects']), axis=1)\n",
    "  df_train['sentence_check'] = df_train.apply(lambda x: x['sentence_token'].check_rebuild_sentence_from_token(), axis=1)\n",
    "  df_train['aspect_check'] = df_train.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects']), axis=1)\n",
    "  df_train['aspect_check_TF'] = df_train.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects'])[0], axis=1)\n",
    "  df_train['tokens'] = df_train.apply(lambda x: x['sentence_token'].get_tokens(), axis=1)\n",
    "  df_train['tags'] = df_train.apply(lambda x: x['sentence_token'].aspect_unified_bio_tags, axis=1)\n",
    "\n",
    "  df_val['sentence_token'] = df_val.apply(lambda x: SentenceToken(x['text'], 'dict', x['aspects']), axis=1)\n",
    "  df_val['sentence_check'] = df_val.apply(lambda x: x['sentence_token'].check_rebuild_sentence_from_token(), axis=1)\n",
    "  df_val['aspect_check'] = df_val.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects']), axis=1)\n",
    "  df_val['aspect_check_TF'] = df_val.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects'])[0], axis=1)\n",
    "  df_val['tokens'] = df_val.apply(lambda x: x['sentence_token'].get_tokens(), axis=1)\n",
    "  df_val['tags'] = df_val.apply(lambda x: x['sentence_token'].aspect_unified_bio_tags, axis=1)\n",
    "  return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape:  (3036, 3)\n",
      "df_val shape:  (800, 3)\n",
      "# of df_train records having tokenizing issues:  0\n",
      "# of df_train records having aspect bio tagging issues:  0\n",
      "# of df_test records having tokenizing issues:  0\n",
      "# of df_test records having aspect bio tagging issues:  1\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = reload_Data()\n",
    "print('# of df_train records having tokenizing issues: ', len(df_train[df_train['sentence_check']==False]))\n",
    "# print('# of df_train records having aspect bio tagging issues: ', len(df_train[df_train['aspect_check'].apply(lambda x: x[0]==False)]))\n",
    "print('# of df_train records having aspect bio tagging issues: ', len(df_train[df_train['aspect_check_TF']==False]))\n",
    "print('# of df_test records having tokenizing issues: ', len(df_test[df_test['sentence_check']==False]))\n",
    "# print('# of df_val records having  aspect bio tagging issues: ', len(df_val[df_val['aspect_check'].apply(lambda x: x[0]==False)]))\n",
    "print('# of df_test records having aspect bio tagging issues: ', len(df_test[df_test['aspect_check_TF']==False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags', '__index_level_0__'],\n",
      "        num_rows: 2428\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags', '__index_level_0__'],\n",
      "        num_rows: 608\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "tds = Dataset.from_pandas(df_train[['tokens','tags']])\n",
    "vds = Dataset.from_pandas(df_val[['tokens','tags']])\n",
    "tsds = Dataset.from_pandas(df_test[['tokens','tags']])\n",
    "\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = tds\n",
    "ds['validation'] = vds\n",
    "ds['test'] = tsds\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import get_dataset_config_names\n",
    "\n",
    "# xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "# print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "# panx_subsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# load_dataset(\"xtreme\", name='PAN-X.de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide_output\n",
    "# from collections import defaultdict\n",
    "# from datasets import DatasetDict\n",
    "\n",
    "# langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "# fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# # Return a DatasetDict if a key doesn't exist\n",
    "# panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "# for lang, frac in zip(langs, fracs):\n",
    "#     # Load monolingual corpus\n",
    "#     ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "#     # Shuffle and downsample each split according to spoken proportion\n",
    "#     for split in ds:\n",
    "#         panx_ch[lang][split] = (\n",
    "#             ds[split]\n",
    "#             .shuffle(seed=0)\n",
    "#             .select(range(int(frac * ds[split].num_rows))))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "#              index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element = panx_ch[\"de\"][\"train\"][0]\n",
    "# for key, value in element.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "# print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-NEG', 'B-NEU', 'B-POS', 'I-NEG', 'I-NEU', 'I-POS', 'O'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = set(sum(ds['train']['tags'],[]))\n",
    "# int2str\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide_output\n",
    "# def create_tag_names(batch):\n",
    "#     return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "# panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide_output\n",
    "# de_example = panx_de[\"train\"][0]\n",
    "# pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "# ['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_example = df_train.iloc[0]\n",
    "# pd.DataFrame([df_example[\"tokens\"], df_example[\"tags\"]],\n",
    "# ['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# split2freqs = defaultdict(Counter)\n",
    "# for split, dataset in panx_de.items():\n",
    "#     for row in dataset[\"ner_tags_str\"]:\n",
    "#         for tag in row:\n",
    "#             if tag.startswith(\"B\"):\n",
    "#                 tag_type = tag.split(\"-\")[1]\n",
    "#                 split2freqs[split][tag_type] += 1\n",
    "# pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>NEG</th>\n",
       "      <th>NEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>789</td>\n",
       "      <td>687</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Validation</th>\n",
       "      <td>199</td>\n",
       "      <td>224</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>341</td>\n",
       "      <td>144</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            POS  NEG  NEU\n",
       "Train       789  687  348\n",
       "Validation  199  224  115\n",
       "Test        341  144  169"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "pd.DataFrame([Counter([tag.split(\"-\")[1] for tag in sum(ds['train']['tags'],[]) if tag.startswith(\"B\")])\n",
    "              ,Counter([tag.split(\"-\")[1] for tag in sum(ds['validation']['tags'],[]) if tag.startswith(\"B\")])\n",
    "              ,Counter([tag.split(\"-\")[1] for tag in sum(ds['test']['tags'],[]) if tag.startswith(\"B\")])]\n",
    "              ,['Train','Validation','Test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Closer Look at Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "# bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = ds['train'][0]['tokens']\n",
    "# bert_tokens = bert_tokenizer(text, is_split_into_words=True).tokens()\n",
    "# xlmr_tokens = xlmr_tokenizer(text, is_split_into_words=True).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hide_input\n",
    "# df = pd.DataFrame([bert_tokens, xlmr_tokens], index=[\"BERT\", \"XLM-R\"])\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The SentencePiece Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\".join(xlmr_tokens).replace(u\"\\u2581\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Model for Token Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaForABSA(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
    "                labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, \n",
    "                                     hidden_states=outputs.hidden_states, \n",
    "                                     attentions=outputs.attentions)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Custom Model\n",
    "https://github.com/nlp-with-transformers/notebooks/blob/main/04_multilingual-ner.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-NEG', 'B-NEU', 'B-POS', 'I-NEG', 'I-NEU', 'I-POS', 'O'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = set(sum(ds['train']['tags'],[]))\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-POS': 0,\n",
       " 'B-NEU': 1,\n",
       " 'B-NEG': 2,\n",
       " 'I-NEG': 3,\n",
       " 'I-POS': 4,\n",
       " 'I-NEU': 5,\n",
       " 'O': 6}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags)}\n",
    "tag2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n",
    "                                         num_labels=len(index2tag), #tags.num_classes,\n",
    "                                         id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForABSA were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# hide_output\n",
    "import torch\n",
    "\n",
    "device = evice = torch.device('mps') # The current use is for Mac, the following here maybe needed for windows torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xlmr_model = (XLMRobertaForABSA\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# input_ids = xlmr_tokenizer.encode(text, is_split_into_words=True, return_tensors=\"pt\")\n",
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# outputs = xlmr_model(input_ids.to(device)).logits\n",
    "# predictions = torch.argmax(outputs, dim=-1)\n",
    "# print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "# print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = [index2tag[p] for p in predictions[0].cpu().numpy()]\n",
    "# pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tag_text(tokens, index2tag, model\n",
    "#              , tokenizer\n",
    "#              ):\n",
    "#     # Get tokens with special characters\n",
    "#     # tokens = tokenizer(text).tokens()\n",
    "#     # Encode the sequence into IDs\n",
    "#     input_ids = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\").input_ids.to(device)\n",
    "#     # Get predictions as distribution over 7 possible classes\n",
    "#     outputs = model(input_ids)[0]\n",
    "#     # Take argmax to get most likely class per token\n",
    "#     predictions = torch.argmax(outputs, dim=2)\n",
    "#     # Convert to DataFrame\n",
    "#     preds = [index2tag[p] for p in predictions[0].cpu().numpy()]\n",
    "#     return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Texts for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words, tags = df_example[\"tokens\"], df_example[\"tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_input = xlmr_tokenizer(df_example[\"tokens\"], is_split_into_words=True)\n",
    "# tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "# pd.DataFrame([tokens, tags], index=[\"Tokens\", 'labels']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# word_ids = tokenized_input.word_ids()\n",
    "# pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hide_output\n",
    "# previous_word_idx = None\n",
    "# labels = []\n",
    "\n",
    "# for word_idx in word_ids:       \n",
    "#     if word_idx is None or word_idx == previous_word_idx:\n",
    "#         labels.append('IGN')\n",
    "#     elif word_idx != previous_word_idx:\n",
    "#         labels.append(tags[word_idx])\n",
    "#     previous_word_idx = word_idx\n",
    "    \n",
    "# label_ids = [tag2index[l] if l != 'IGN' else -100 for l in labels]\n",
    "\n",
    "# index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "# pd.DataFrame([tokens, word_ids, label_ids, labels], index=index).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, \n",
    "                                      is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(tag2index[label[word_idx]])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True, \n",
    "                      remove_columns=['tags', 'tokens']\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f268d975a4443c2a251296b5856052a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2428 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e290d3c1254e418fc055e678e39957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/608 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02bb5ba2e724a1ebe9a37a26acf95d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "ds_encoded = encode_dataset(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "# y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "#           [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "# y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "#           [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "# print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 6\n",
    "batch_size = 24\n",
    "logging_steps = len(ds[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-absa\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs, \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\", \n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, \n",
    "    logging_steps=logging_steps, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de111c1c722b4f49aab1d32f6bb3ce70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#hide_output\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions, \n",
    "                                       eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred), \"f1_macro\": f1_score(y_true, y_pred, average='macro')}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 11:53:52.818357: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaForABSA\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args, \n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=ds_encoded[\"train\"],\n",
    "                  eval_dataset=ds_encoded[\"validation\"], \n",
    "                  tokenizer=xlmr_tokenizer)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.2.0 torchtext --index-url https://download.pytorch.org/whl/test/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf6d8183b844d7faae223668406debe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.271, 'learning_rate': 4.17483660130719e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b5820132874a7aa505dc461d8fb3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18413874506950378, 'eval_f1': 0.39865433137089995, 'eval_f1_macro': 0.30503972950546276, 'eval_runtime': 10.07, 'eval_samples_per_second': 60.377, 'eval_steps_per_second': 2.582, 'epoch': 1.0}\n",
      "{'loss': 0.1143, 'learning_rate': 3.349673202614379e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73509ad57c194e2a8b2b582873f0dc5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1321128010749817, 'eval_f1': 0.5432999088422972, 'eval_f1_macro': 0.4849103653393267, 'eval_runtime': 7.3116, 'eval_samples_per_second': 83.156, 'eval_steps_per_second': 3.556, 'epoch': 2.0}\n",
      "{'loss': 0.0704, 'learning_rate': 2.5245098039215685e-05, 'epoch': 2.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191bb478f61f488c9c5f4cc48d1f0507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14638599753379822, 'eval_f1': 0.5682242990654205, 'eval_f1_macro': 0.5350069148281666, 'eval_runtime': 5.5906, 'eval_samples_per_second': 108.755, 'eval_steps_per_second': 4.651, 'epoch': 3.0}\n",
      "{'loss': 0.0473, 'learning_rate': 1.6993464052287582e-05, 'epoch': 3.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b81a197fbc14d17bb02e42568b3cfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14634408056735992, 'eval_f1': 0.6021314387211367, 'eval_f1_macro': 0.5771830789949196, 'eval_runtime': 6.057, 'eval_samples_per_second': 100.381, 'eval_steps_per_second': 4.293, 'epoch': 4.0}\n",
      "{'loss': 0.0307, 'learning_rate': 8.741830065359477e-06, 'epoch': 4.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888f8902c9b74a559620acfd37976393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15711809694766998, 'eval_f1': 0.6277630415561449, 'eval_f1_macro': 0.6002964881651965, 'eval_runtime': 6.5738, 'eval_samples_per_second': 92.489, 'eval_steps_per_second': 3.955, 'epoch': 5.0}\n",
      "{'loss': 0.0192, 'learning_rate': 4.901960784313725e-07, 'epoch': 5.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3f2b449aa1400c92f2b24968b91639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1652992218732834, 'eval_f1': 0.6383731211317417, 'eval_f1_macro': 0.6187384358380648, 'eval_runtime': 7.2266, 'eval_samples_per_second': 84.134, 'eval_steps_per_second': 3.598, 'epoch': 6.0}\n",
      "{'train_runtime': 3051.2435, 'train_samples_per_second': 4.774, 'train_steps_per_second': 0.201, 'train_loss': 0.09143147991324951, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=612, training_loss=0.09143147991324951, metrics={'train_runtime': 3051.2435, 'train_samples_per_second': 4.774, 'train_steps_per_second': 0.201, 'train_loss': 0.09143147991324951, 'epoch': 6.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#hide_input\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d34e32a70d747c0827802aada88c95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1179f43cdc5843538aac637c1f838e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.73k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b403a6a9014d7ba3337bbd59a61bbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1706028839.PRODIGYMAC-C02D64MJMD6R.15056.0:   0%|          | 0.00/8.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f896abfff8498da7a1aa022379cd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/tnatvu/xlm-roberta-base-absa/commit/287181a14c225d7508e274c215c266865d0fe071', commit_message='Training completed!', commit_description='', oid='287181a14c225d7508e274c215c266865d0fe071', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.184139</td>\n",
       "      <td>0.398654</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>0.184139</td>\n",
       "      <td>0.398654</td>\n",
       "      <td>0.305040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.132113</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.132113</td>\n",
       "      <td>0.543300</td>\n",
       "      <td>0.484910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.146386</td>\n",
       "      <td>0.568224</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.146386</td>\n",
       "      <td>0.568224</td>\n",
       "      <td>0.535007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.146344</td>\n",
       "      <td>0.602131</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.146344</td>\n",
       "      <td>0.602131</td>\n",
       "      <td>0.577183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.157118</td>\n",
       "      <td>0.627763</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.157118</td>\n",
       "      <td>0.627763</td>\n",
       "      <td>0.600296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.165299</td>\n",
       "      <td>0.638373</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.165299</td>\n",
       "      <td>0.638373</td>\n",
       "      <td>0.618738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch  Training Loss  Validation Loss        F1  Macro F1\n",
       "0       1         0.2710         0.184139  0.398654       NaN\n",
       "1       1         0.2710         0.184139  0.398654  0.305040\n",
       "2       2         0.1143         0.132113  0.543300       NaN\n",
       "3       2         0.1143         0.132113  0.543300  0.484910\n",
       "4       3         0.0704         0.146386  0.568224       NaN\n",
       "5       3         0.0704         0.146386  0.568224  0.535007\n",
       "6       4         0.0473         0.146344  0.602131       NaN\n",
       "7       4         0.0473         0.146344  0.602131  0.577183\n",
       "8       5         0.0307         0.157118  0.627763       NaN\n",
       "9       5         0.0307         0.157118  0.627763  0.600296\n",
       "10      6         0.0192         0.165299  0.638373       NaN\n",
       "11      6         0.0192         0.165299  0.638373  0.618738"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/tnatvu/xlm-roberta-base-finetuned-panx-de/commit/392fb1439a34c700ee40c2b53da7b342f86aea5e\n",
    "# CommitInfo(commit_url='https://huggingface.co/tnatvu/xlm-roberta-base-absa/commit/287181a14c225d7508e274c215c266865d0fe071', commit_message='Training completed!', commit_description='', oid='287181a14c225d7508e274c215c266865d0fe071', pr_url=None, pr_revision=None, pr_num=None)\n",
    "df = pd.DataFrame(trainer.state.log_history)[['epoch','loss' ,'eval_loss', 'eval_f1','eval_f1_macro']]\n",
    "df = df.rename(columns={\"epoch\":\"Epoch\",\"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", \"eval_f1\":\"F1\",'eval_f1_macro':'Macro F1'})\n",
    "df['Epoch'] = df[\"Epoch\"].apply(lambda x: round(x))\n",
    "df['Training Loss'] = df[\"Training Loss\"].ffill()\n",
    "df[['Validation Loss', 'F1']] = df[['Validation Loss', 'F1']].bfill().ffill()\n",
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.3.0.dev20240121 # this does not work\n",
    "\n",
    "# pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu # run this in CLI before running the notebook\n",
    "\n",
    "# import torch\n",
    "# if torch.backends.mps.is_available():\n",
    "#     mps_device = torch.device(\"mps\")\n",
    "#     x = torch.ones(1, device=mps_device)\n",
    "#     print (x)\n",
    "# else:\n",
    "#     print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model  \n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # Logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7), \n",
    "                         labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-POS': 0,\n",
       " 'B-NEU': 1,\n",
       " 'B-NEG': 2,\n",
       " 'I-NEG': 3,\n",
       " 'I-POS': 4,\n",
       " 'I-NEU': 5,\n",
       " 'O': 6}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3c6e2c88944a2db04275c03dec1c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "valid_set = ds_encoded[\"test\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df_test = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "\n",
    "df_test[\"predicted_label\"] = df_test[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df_test[\"labels\"] = df_test[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df_test['loss'] = df_test.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df_test['predicted_label'] = df_test.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "\n",
    "# hide_output\n",
    "df_tokens = df_test.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "# df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "# df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69145189490994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "macro_f1 = f1_score(df_tokens['labels'], df_tokens['predicted_label'], average='macro')\n",
    "print(macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for model errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ed91cee4b5461d9a30719bae96fa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "valid_set = ds_encoded[\"test\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58800</td>\n",
       "      <td>1</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>0.01</td>\n",
       "      <td>B-POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1733</td>\n",
       "      <td>1</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1601</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4271</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10932</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label\n",
       "0     58800              1  B-POS  0.01           B-POS\n",
       "0      1733              1  I-POS  0.02           I-POS\n",
       "0        83              1      O  0.00               O\n",
       "0      1601              1      O  0.00               O\n",
       "0      4271              1      O  0.00               O\n",
       "0         6              1      O  0.00               O\n",
       "0     10932              1      O  0.00               O"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df['loss'] = df.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df['predicted_label'] = df.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "\n",
    "# hide_output\n",
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58800</td>\n",
       "      <td>1</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>0.01</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>▁Boot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1733</td>\n",
       "      <td>1</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>0.02</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>▁time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1601</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4271</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10932</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "      <td>O</td>\n",
       "      <td>▁around</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label input_tokens\n",
       "0     58800              1  B-POS  0.01           B-POS        ▁Boot\n",
       "0      1733              1  I-POS  0.02           I-POS        ▁time\n",
       "0        83              1      O  0.00               O          ▁is\n",
       "0      1601              1      O  0.00               O       ▁super\n",
       "0      4271              1      O  0.00               O        ▁fast\n",
       "0         6              1      O  0.00               O            ▁\n",
       "0     10932              1      O  0.00               O      ▁around"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by word token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁the</td>\n",
       "      <td>▁\"</td>\n",
       "      <td>▁price</td>\n",
       "      <td>▁i</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁OS</td>\n",
       "      <td>▁install</td>\n",
       "      <td>▁drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1188</td>\n",
       "      <td>405</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>83.23</td>\n",
       "      <td>68.67</td>\n",
       "      <td>52.35</td>\n",
       "      <td>34.03</td>\n",
       "      <td>26.85</td>\n",
       "      <td>25.74</td>\n",
       "      <td>25.36</td>\n",
       "      <td>22.41</td>\n",
       "      <td>20.59</td>\n",
       "      <td>19.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2       3      4      5      6      7  \\\n",
       "input_tokens      ▁   ▁the     ▁\"  ▁price     ▁i     ▁(     ▁)    ▁OS   \n",
       "count          1188    405     34      25     43     29     31     27   \n",
       "mean           0.07   0.17   1.54    1.36   0.62   0.89   0.82   0.83   \n",
       "sum           83.23  68.67  52.35   34.03  26.85  25.74  25.36  22.41   \n",
       "\n",
       "                     8       9  \n",
       "input_tokens  ▁install  ▁drive  \n",
       "count                9      14  \n",
       "mean              2.29     1.4  \n",
       "sum              20.59   19.59  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by label ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-NEU</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>B-NEU</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>203</td>\n",
       "      <td>170</td>\n",
       "      <td>169</td>\n",
       "      <td>97</td>\n",
       "      <td>144</td>\n",
       "      <td>341</td>\n",
       "      <td>11122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.24</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>455.2</td>\n",
       "      <td>366.93</td>\n",
       "      <td>331.28</td>\n",
       "      <td>174.45</td>\n",
       "      <td>161.58</td>\n",
       "      <td>335.71</td>\n",
       "      <td>157.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1       2       3       4       5       6\n",
       "labels  I-NEU   I-POS   B-NEU   I-NEG   B-NEG   B-POS       O\n",
       "count     203     170     169      97     144     341   11122\n",
       "mean     2.24    2.16    1.96     1.8    1.12    0.98    0.01\n",
       "sum     455.2  366.93  331.28  174.45  161.58  335.71  157.71"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]] \n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .sort_values(by=\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAIjCAYAAADC/VtFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACrDElEQVR4nOzdd1gUxxvA8e8dXSlKEwUUECmC2HsU7LHGqIkaTSzR2GLvRmONLUZNs/cSS2yxxdhLYmLH3hXFCtJROvf74/T04M6oQdj88n6e5x5l7t29mWF37r3Z2UOl0Wg0CCGEEEIolDqvKyCEEEII8TKSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCPEfEhISQkhIiO7nsLAwVCoVS5YsydV6dOzYEQ8Pj1x9zdeRmJhIly5dcHFxQaVS0a9fvxx/DQ8PDzp27Jjj+/23U/qxIfKGJCtCvGDJkiWoVCosLS25e/dutudDQkIIDAzMg5qJ3DRx4kSWLFlCjx49WL58OR9//HFeV+lf58mTJ4wZM4b9+/fndVXE/wHTvK6AEEqUkpLC5MmT+f777/O6Km9VsWLFSEpKwszMLK+roih79+6lSpUqjB49+q29xuXLl1Gr/38/Lz558oSxY8cC6M3m/Z358+eTmZn5lmol/q3+f88UIf6BMmXKMH/+fO7du/fWXkOj0ZCUlPTW9v8qns0imZiY5Gk9lCYiIoICBQq81dewsLCQJPEFjx8/BsDMzAwLC4s8ro1QGklWhDBgxIgRZGRkMHny5L+NTU9PZ/z48RQvXhwLCws8PDwYMWIEKSkpenEeHh40adKE3377jQoVKmBlZcXcuXPZv38/KpWKtWvXMnbsWFxdXbGxsaFVq1bExcWRkpJCv379cHZ2xtramk6dOmXb9+LFi6lduzbOzs5YWFhQsmRJZs+e/bd1z7pm5VldDD2yriP49ddfqVGjBvnz58fGxobGjRtz/vz5bK+xadMmAgMDsbS0JDAwkI0bN/5tvbK+TnBwMDY2Ntja2lKxYkV++uknvZiff/6Z8uXLY2VlhaOjI+3bt892Ga9jx45YW1tz9+5dmjdvjrW1NU5OTgwaNIiMjAy99t+8eZNt27bp2h4WFqa7RBgWFqa332fbvHi54+rVq7Rs2RIXFxcsLS1xc3OjTZs2xMXF6WIMrVm5ceMGH3zwAfb29uTLl48qVaqwbds2g6+3du1avvrqK9zc3LC0tKROnTpcu3btb/tzzJgxqFQqrly5Qvv27bGzs8PJyYlRo0ah0WgIDw/nvffew9bWFhcXF7755hu97VNTU/nyyy8pX748dnZ25M+fnxo1arBv3z5dTFhYGE5OTgCMHTtW149jxozR+11cv36dRo0aYWNjQ7t27XTPvXisjR49GrVazZ49e/Tq8dlnn2Fubs7p06f/ts3i308uAwlhgKenJ5988gnz589n2LBhFClSxGhsly5dWLp0Ka1atWLgwIEcOXKESZMmcfHixWxvzJcvX6Zt27Z069aNrl274uvrq3tu0qRJWFlZMWzYMK5du8b333+PmZkZarWamJgYxowZw19//cWSJUvw9PTkyy+/1G07e/ZsAgICaNasGaampmzZsoWePXuSmZlJr169Xrnd/v7+LF++XK8sNjaWAQMG4OzsrCtbvnw5HTp0oEGDBkyZMoUnT54we/Zs3nnnHU6dOqV7s9m5cyctW7akZMmSTJo0iaioKDp16oSbm9sr1WfJkiV07tyZgIAAhg8fToECBTh16hQ7duzgo48+0sV06tSJihUrMmnSJB4+fMi3337LH3/8walTp/RmSDIyMmjQoAGVK1dm2rRp7N69m2+++YbixYvTo0cPXfv79++Pm5sbAwcOBNC98b6K1NRUGjRoQEpKCr1798bFxYW7d++ydetWYmNjsbOzM7jdw4cPqVatGk+ePKFPnz44ODiwdOlSmjVrxrp163j//ff14idPnoxarWbQoEHExcUxdepU2rVrx5EjR16pnq1bt8bf35/Jkyezbds2JkyYgL29PXPnzqV27dpMmTKFlStXMmjQICpWrEjNmjUBiI+PZ8GCBbRt25auXbuSkJDAwoULadCgAUePHqVMmTI4OTkxe/ZsevTowfvvv0+LFi0ACAoK0r1+eno6DRo04J133mHatGnky5fPYD1HjhzJli1b+PTTTzl79iw2Njb89ttvzJ8/n/Hjx1O6dOlXaq/4l9MIIXQWL16sATTHjh3TXL9+XWNqaqrp06eP7vng4GBNQECA7ufQ0FANoOnSpYvefgYNGqQBNHv37tWVFStWTANoduzYoRe7b98+DaAJDAzUpKam6srbtm2rUalUmoYNG+rFV61aVVOsWDG9sidPnmRrS4MGDTReXl56ZcHBwZrg4GDdzzdv3tQAmsWLFxvsj8zMTE2TJk001tbWmvPnz2s0Go0mISFBU6BAAU3Xrl31Yh88eKCxs7PTKy9TpoymcOHCmtjYWF3Zzp07NUC2NmQVGxursbGx0VSuXFmTlJSUrV4ajUaTmpqqcXZ21gQGBurFbN26VQNovvzyS11Zhw4dNIBm3LhxevsqW7aspnz58nplxYoV0zRu3Fiv7NmxcfPmTb3yZ7+/ffv2aTQajebUqVMaQPPzzz+/tH3FihXTdOjQQfdzv379NIDm0KFDurKEhASNp6enxsPDQ5ORkaH3ev7+/pqUlBRd7LfffqsBNGfPnn3p644ePVoDaD777DNdWXp6usbNzU2jUqk0kydP1pXHxMRorKys9OqZnp6u97rP4goVKqTp3LmzriwyMlIDaEaPHp2tDs9+F8OGDTP4XNZj4+zZsxpzc3NNly5dNDExMRpXV1dNhQoVNGlpaS9tq/j/IZeBhDDCy8uLjz/+mHnz5nH//n2DMdu3bwdgwIABeuXPPpFnncL39PSkQYMGBvf1ySef6K1hqFy5MhqNhs6dO+vFVa5cmfDwcNLT03VlVlZWuv/HxcXx6NEjgoODuXHjht6lh9c1fvx4tm7dypIlSyhZsiQAu3btIjY2lrZt2/Lo0SPdw8TEhMqVK+suB9y/f5/Q0FA6dOigN5tQr1493b5eZteuXSQkJDBs2DAsLS31nlOpVAAcP36ciIgIevbsqRfTuHFj/Pz8svU/QPfu3fV+rlGjBjdu3HjFHvl7z9r622+/8eTJk1febvv27VSqVIl33nlHV2Ztbc1nn31GWFgYFy5c0Ivv1KkT5ubmup9r1KgB8Mpt6dKli+7/JiYmVKhQAY1Gw6effqorL1CgAL6+vnr7NDEx0b1uZmYm0dHRpKenU6FCBU6ePPnK7QXo0aPHK8UFBgYyduxYFixYQIMGDXj06BFLly7F1FQuDvxXSLIixEuMHDmS9PR0o2tXbt26hVqtxtvbW6/cxcWFAgUKcOvWLb1yT09Po69VtGhRvZ+fvem5u7tnK8/MzNRLQv744w/q1q1L/vz5KVCgAE5OTowYMQLgjZOVHTt2MHbsWIYPH07Lli115VevXgWgdu3aODk56T127txJREQEgK7tJUqUyLbvFy9/GXP9+nWAl94q/uw1DO3Pz88vW/9bWlpmu6RTsGBBYmJi/rY+r8rT05MBAwawYMECHB0dadCgAT/++OPf/h5u3bplsB3+/v6651+U9XgpWLAgwCu3xdDxZmlpiaOjY7byrPtcunQpQUFBWFpa4uDggJOTE9u2bXutY83U1PSVLwcCDB48mNKlS3P06FFGjx79Sgmv+P8haakQL+Hl5UX79u2ZN28ew4YNMxr37JP+33lxBiQrY3fkGCvXaDSA9k29Tp06+Pn5MX36dNzd3TE3N2f79u3MmDHjjW4DvXnzJu3ataNevXpMmDBB77ln+1u+fDkuLi7ZtlXyp91/cteTsd/xs8W5L/rmm2/o2LEjv/zyCzt37qRPnz5MmjSJv/7667XeoF/m746LN9n+Vfa5YsUKOnbsSPPmzRk8eDDOzs6YmJgwadIkXYL5KiwsLF7r1u0bN27oEuWzZ8++8nbi/4NyRxUhFGLkyJGsWLGCKVOmZHuuWLFiZGZmcvXqVd0nYNAuloyNjaVYsWJvvX5btmwhJSWFzZs3631afvHujNeRlJREixYtKFCgAKtWrcr2hlK8eHEAnJ2dqVu3rtH9PGv7szeYF12+fPlv6/Hsdc6dO5dt5irra1y+fJnatWtne42c7P9nMxexsbF65VlnPJ4pVaoUpUqVYuTIkRw+fJjq1aszZ86cbMnfM8WKFTPYL5cuXdI9rwTr1q3Dy8uLDRs26CVwWb+T5lUT+FeRmZlJx44dsbW1pV+/fkycOJFWrVrpFu6K/39yGUiIv1G8eHHat2/P3LlzefDggd5zjRo1AmDmzJl65dOnTwe0ayfetmefhl/89BsXF8fixYvfaH/du3fnypUrbNy4UfcG/aIGDRpga2vLxIkTSUtLy/Z8ZGQkAIULF6ZMmTIsXbpU7/LArl27sq2/MKR+/frY2NgwadIkkpOT9Z571tYKFSrg7OzMnDlz9G7n/vXXX7l48WKO9v+z5OngwYO6soyMDObNm6cXFx8fr7eeCLSJi1qtznbL+YsaNWrE0aNH+fPPP3Vljx8/Zt68eXh4eCjmsoeh4+3IkSN69QZ0d/dkTe7exPTp0zl8+DDz5s1j/PjxVKtWjR49evDo0aN/vG/x7yAzK0K8gi+++ILly5dz+fJlAgICdOWlS5emQ4cOzJs3j9jYWIKDgzl69ChLly6lefPm1KpV663XrX79+pibm9O0aVO6detGYmIi8+fPx9nZ2ejCYGO2bdvGsmXLaNmyJWfOnOHMmTO656ytrWnevDm2trbMnj2bjz/+mHLlytGmTRucnJy4ffs227Zto3r16vzwww+A9nbsxo0b884779C5c2eio6P5/vvvCQgIIDEx8aV1sbW1ZcaMGXTp0oWKFSvy0UcfUbBgQU6fPs2TJ09YunQpZmZmTJkyhU6dOhEcHEzbtm11ty57eHjQv3//1+9QIwICAqhSpQrDhw8nOjoae3t7Vq9enS0x2bt3L59//jkffPABPj4+pKens3z5ckxMTPTW/mQ1bNgwVq1aRcOGDenTpw/29vYsXbqUmzdvsn79esV8222TJk3YsGED77//Po0bN+bmzZvMmTOHkiVL6v1OraysKFmyJGvWrMHHxwd7e3sCAwNf+89VXLx4kVGjRtGxY0eaNm0KaG9XL1OmDD179mTt2rU52j6hUHl3I5IQyvPirctZPbvd8sVblzUajSYtLU0zduxYjaenp8bMzEzj7u6uGT58uCY5OVkvztDtsBrN81tRs97qaqwuz249jYyM1JVt3rxZExQUpLG0tNR4eHhopkyZolm0aFG2W23/7tblZ69p6JH1dtJ9+/ZpGjRooLGzs9NYWlpqihcvrunYsaPm+PHjenHr16/X+Pv7aywsLDQlS5bUbNiwweDtqcZs3rxZU61aNY2VlZXG1tZWU6lSJc2qVav0YtasWaMpW7asxsLCQmNvb69p166d5s6dO3oxHTp00OTPnz/b/p/154uM/a6uX7+uqVu3rsbCwkJTqFAhzYgRIzS7du3Su3X5xo0bms6dO2uKFy+usbS01Njb22tq1aql2b17d7bXePGW4Gf7b9WqlaZAgQIaS0tLTaVKlTRbt27VizF2vPzdbehZ2/vi8aPRGO+frLfrZ2ZmaiZOnKgpVqyYxsLCQlO2bFnN1q1bDf5ODx8+rClfvrzG3Nxc7zZmY6/17Lln+0lPT9dUrFhR4+bmpnf7u0bz/FbtNWvWvLS94v+DSqN5xdVYQgghhBB5QBnzikIIIYQQRkiyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0+VK4HJSZmcm9e/ewsbHJ0a+aFkIIIf4faTQaEhISKFKkyEu/+FCSlRx07969bH8hVwghhBAvFx4e/tI/8inJSg6ysbEBoNG07ZhZ5c/j2uStPtU88roKiuBqny+vq6AINlYy1ABkyldwAmBmIjPPzzxOTv/7oP9jCQkJlPH31L1/GiMjSA56dunHzCo/ZlbWeVybvJXfxjavq6AINraSrADYSrICSLLyjCQrz6nN/9vJyjN/t3RCFtgKIYQQQtEkWRFCCCGEokmyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0SVaEEEIIoWiSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFopnldAfFydX0caRRQCDsrM8Jjklh2NJwbUU8Mxtbwsuez6h56ZakZmXz6U6heWRFbS1qXK4JfIRtM1HA3NpnvDtwg6knaW2rFP7fx179Yvfl3omMT8S7mQp9Pm+Bfws1g7NZdx/jtQCg3wx8C4ONVhK4f1deLX7xmD3v/OEtkVBympib4eBWhS9t6lPRxz5X2vKnlG39n/pp9REYn4F+8CKP7vE9p/2JG47fvD2XGoh3ceRCNh5sjQz5rQq0qJXXPP4pOYMq8rfx+/DLxiUlUDPJidJ8WeLo55UZz3tjCdQf5ccVeIqLjCfB2ZdLAVpQLMN4Pv+w5xeR52wi/H42XuxOjejWjXrUAANLSM5g0Zyu7/7zArbtR2FhbElzRl1E9m+HiZJdbTXoji9YdZNZKbT+U9HZl4oCX98PmPaeYMm8b4Q+i8XTT9kPdp/0A8PWC7WzadZK7EbGYm5kQ5OvO8O5NKB/gkQuteXMLfj7I9yv2EBEVT0AJV6YMavXSOm/afYpJc7dy++nxMObz96hX/Xk/bNkXyuINf3D64m1i4p9wYMVQSvkYHm+UZOmG35m7eq9ufBjXtwVlSho/HrbuC+Wbhb9qxwdXJ4Z3b0Ltqs/Hh6I1+xvcbkSPpnRvWzvH6/8yMrOiYJWLFeSjCm5sPHOfUdsucTsmiSF1vLG1NJ5jPknN4POfz+ge/Tec03ve2dqcke/6cD8+hYk7rzBiy0U2nX1AWqbmbTfnje394yyzlv5Kxw9qMX9qT4p7uDB4whJi4hINxoeev0mdd4KYMeZTfpzYDWdHOwaNX0JkVLwuxr2II327NGHR9N58P6ErLs4FGTxhCbFxj3OrWa9t695TTJz9C306NGDzvAH4FS9CxyHzeBSTYDD+xLmb9Bu/gg8aVWLL/IHUe6cUPUYt5vLN+wBoNBq6j1pE+P0o5k7ozJZ5A3EtVJBPBs3hSVJKbjbttWzcdZIvv93IoC7vsmfpYAJKuPJhv1lERhvuh6NnbtDty6W0a1qVvUuH0LBmEB2GLODi9XsAJCWncubyHQZ0asCepYNZMvlTrt2KoP3gebnZrNe2afdJRn+3kYGfvsuuJdp+aNPfeD8cO3OD7qOX8lHTqux+2g8dhz7vBwAvd2cmDvyA/SuGsXlOP9wL29O67yyjx5gSbNh1gpEzNzKkS0P2LRtCYAlXWvUx3g9Hztyg66gltGtWlf3Lh9IoOIj2g+dz4YV+eJKUSpXSXoz+/L3casY/tnnPKcb/uIl+HRuwbcFA/L2L0H7QXKO/u+Nnb9J73HJaN67M9gWDaFAjkK5fLOLyjfvPYzaO1XtMG9YGlUpFw+Cg3GqWjiKSlY4dO6JSqXQPBwcH3n33Xc6cOWN0m7CwsGzb1K9fn1OnTunFnT9/ng8//BAnJycsLCzw8fHhyy+/5MkT/dmJ06dP06xZM5ydnbG0tMTDw4PWrVsTERHxVtr8KhqWdGb/1Uccuh7NvbhkFv91m5SMTGoWdzC6jQYNccnpukd8crre8x+ULcLpu3GsPnmXWzFJRCSmcupOXLY4Jfl5yx80rluBhrXL4+HuzIDPmmFpYcb2vScMxo/s9yHN361MCc/CFHN1YnD399FoNJw8e10XU7dGaSoEeVOkkD2e7oXo1aEhj5+kcP3Wg9xq1mtb9PMBWjeuQquGlSjh4cKEAa2wsjRj3a9HDcYvWX+ImpX8+KxNbbyLFWJA54YElHBl+cbfAQi7E8mpC7cY168VQX5F8SrqzPj+rUhOSWPL3lMG96kEc1bto/171fioSRV8PQszbeiHWFma89PWvwzGz1tzgNpV/Pm8fR18PF0Y3q0xQb5uLFx3CABbayvWfd+L5nXL4V2sEBUCPZk8qBWnL4Vz50F0bjbttcxZtY/2zarR9mk/fD3kQ6wszFllrB/WHqBWZX96ta+Dj4cLw7o1ppSvG4ue9gNAywYVCK7ki4erI35ehRnX930SHidz4do9g/tUglk/7eOT5lVp17QKfl6FmT6sNfkszVm55U+D8XNX76dOFX/6fFwXX08XvujehCA/dxasPaiLad2oEkO6NCSkkm9uNeMfW7B2P22bVOXDRpXx8XBh0sAPsLI0Z822IwbjF607SHAlP7q3rU0Jj0IM6tKIQB83lmx4fjw4O9jqPXb+fo6qZb0pVsQxt5qlo4hkBeDdd9/l/v373L9/nz179mBqakqTJk3+drvdu3dz//59fvvtNxITE2nYsCGxsbEA/PXXX1SuXJnU1FS2bdvGlStX+Oqrr1iyZAn16tUjNTUVgMjISOrUqYO9vT2//fYbFy9eZPHixRQpUoTHj/Pmk7aJWoWHfT7OP3ieFWuA8/cT8HbKb3Q7S1MTZrwfwMwWgfQL8cLVzlL3nAoo7WrHg/gUBtfx5scPSjGmoS/l3ZU71Z2Wls7lG/coH1RcV6ZWqylfqjgXLoe/0j5SUtNIz8jAxtrK6Gts2XWc/PksKe7hkiP1zmmpaemcu3KHauV9dGVqtZpq5Xw4dT7M4DanLoRRvXwJvbIaFf108alp2gTVwvz5TJ1arcbczJTjZ2/mbANySGpaOqcvhxNc8fmbiFqtpmZFX6N1Pn4ujJoVffTKalXxf2kb4xOTUalU2NkYPmbyWmpaOmcuh1PDUD+cM9yuE4b6obK/0fjUtHSWbzqMrbUVASVcc67yOSg1LZ3Tl7IfD8EVfTl2NszgNsfOhhGcJQmpXcWPYwo95l9Falo6Z6/c4Z0K+uPDO+VLcPL8LYPbnDwfxjvl9Y+HmpV8jcZHRiew988LtGlcOecq/hoUs2bFwsICFxftG4WLiwvDhg2jRo0aREZG4uRk/Pq5g4MDLi4uuLi4MG3aNKpXr86RI0eoX78+n376Kf7+/mzYsAG1WpuXFStWDB8fH8qWLcuMGTMYOnQof/zxB3FxcSxYsABTU22XeHp6UqtWrbffcCNsLEwxUauIS9Kf8YhPTqfICwnIi+7HpzD/z1uExySRz8yERgGF+PJdX4ZtuUDMkzRsLU2xMjOhaWAh1oXeZ83JuwQVsaVPsBeTdl7lUoThyyp5KS7hCZmZmdjbWeuVFyxgze27j15pH3NX/IZjQRu9hAfg8PFLjJu5lpSUNBwKWvPNlx0pYGs8EcxLMXGPycjMxLGgjV65Y0Ebbtw2PPv3KDoBBwPxkU+nhb2KFqJIoYJMm7+NCU8/hS1ed4AHkbF6l8yUJDr2MRkZmTjZ67fLuaAN18IeGtwmIioeZ3tbvTKngjZERBmeHk9OSWPcj7/Qol45bPIrM1kx1g9O9jZcvWW8H5yy9oN99n7Y+fs5un25hKTkNAo52LL22544FNA//5QiStcP2dt15SX94Jz1+LG3IcLIZaN/g+g4bT9kGx/sbbhuZHyIjE7IfvwUtCEy2vC5v27HUfLns+Tdmrl/CQgUNLPyosTERFasWIG3tzcODsYveWRlZaUdWFJTUwkNDeXChQsMGDBAl6g8U7p0aerWrcuqVasAbXKUnp7Oxo0b0Whefe1GSkoK8fHxeo+8dO3RY/64Ec3tmCQuRSTy7f7rJCSnUbuEdspOpVIBcCI8jh0XI7gdk8TW8w8JvRNHbZ/cn9bLDSs3HmDvH2cZP7gdFuZmes+VDfRiwde9+OGrz6hUpgRjpq82ug7m/5GZqQmzxnbk5p1IyjUbSeC7w/jz1DWCK/uhUqvyunp5Ii09gy5fLEajga+HfpjX1ckT1cuXYO/SoWyd149aVfzpOnKx0fUf4r9j7fajvF+vHJYWZn8f/BYoJlnZunUr1tbWWFtbY2Njw+bNm1mzZk22RMOY2NhYxo8fj7W1NZUqVeLKlSsA+Pv7G4z39/fXxVSpUoURI0bw0Ucf4ejoSMOGDfn66695+NBwZv7MpEmTsLOz0z3c3XPuTpKElHQyMjXYWelPftlamhKb9Gp37WRo4FZMEoVsLHT7TM/UcC8uWS/uXlwyDvnNc6biOczOJh9qtZroLElETGwi9n/zaW/1L7/z08ZDfD2yo8HLO1aW5rgVdiDAx50hPVtgojZh+x7D62DyWkG7/Jio1dkWyz2Kyf7p6BlHexuiDMW/8OmrlK87WxcMInTLV/y5fgxLpnYjNu4JRQu/+oeE3GRfID8mJupsb54RMQk4OxjuB2cHWyKyfFqMNBD/LFG58yCadd/3UuysChjvh8jol/dD1k/NhuLzW1ng6e5EhUBPZn7xEaYmJvxkZP1HXnPQ9UP2dhVysDW4jfZ4yHL8RCdkm235N7G30/ZDtvEhOiHbrNMzTvY22Y+fGMPxR05f5/rtCNo0qZJzlX5NiklWatWqRWhoKKGhoRw9epQGDRrQsGFDbt26RcOGDXWJTEBAgN521apVw9ramoIFC3L69GnWrFlDoUKFdM+/6kzJV199xYMHD5gzZw4BAQHMmTMHPz8/zp49a3Sb4cOHExcXp3uEh7/aGopXkZGpISz6CSVdnp9AKiDAxYZrka+2jkalArcCVrrkJiNTw81Hj3GxtdCLc7G15NHj1Byre04yMzPF16sIJ8/e0JVlZmZy4uwNSvoaTw5XbTrE8vX7mDqyA37er3a9XaPJ1K3jUBpzM1MCfdw4fPKqriwzM5M/T16lrJFbNMuW9NCLB/j9xBWD8TbWVjgUsObmnUjOXgmnbvXAnKx+jjE3M6W0rzsHj13RlWVmZnLo2GUqlPI0uE2FQA8OvRAPcODoJb34Z4nKjfBI1n3fC3s7ZV4OfMbczJQgX3cOHc/SD8cvUyHQcD+UD/TQi4en/WAkXrdfhZ8Xpf2yHw8Hjl+hYikPg9tULOWhFw+w/8hlKho5fv4NzM1MKeXjxh8n9Pvhj5NXjd7KXi7Agz9O6vfD78euGIxfs+0IpXzdKPmKY+nboJhkJX/+/Hh7e+Pt7U3FihVZsGABjx8/Zv78+SxYsECXyGzfvl1vuzVr1nD69GliYmK4fv06jRo1AsDHR7tw6OLFiwZf7+LFi7qYZxwcHPjggw+YNm0aFy9epEiRIkybNs1onS0sLLC1tdV75KRfL0QQUsKRd7zsKWJrScfK7liYqjl4PQqAbtWK8WHZIrr45qVcCCxsg5O1OcXsrehR3QPH/Obsvxali9l24SFVihUkxNsBZxsL6vo6UdbNjj2XI3O07jnpg6bV2br7ODv2n+TWnQhmzN9MckoqDWuVB2Did+uYt3KnLv6njQdZtHo3Q3q2wMWpAFExCUTFJOhux01KTmX+yp2cvxLOg8gYLl+/y5QfNxAZnUBINWW+SQN0/iCYNVv/Yv2OY1y79ZBRM9bxJDmVVu9WAmDgxJ/4ev5WXXzHljU4ePQSC9bu5/rth3y7ZAfnLofz8fvv6GK27w/lr9Br3L4Xxa7fz9Fh0BzqVQ/UW7ipNN3b1mLF5sOs3naEKzcfMHjqWp4kp9L26cK/XmOXM37WZl38Z62D2fvXRWat3MvVsIdMnb+d0IvhfNqqBqBNVDoPX0joxdvMHvsJGZkaHkbF8zAqXrFv0qDth5WbD7Nm2xGuhD1gyNN+aNNE2w+fj13OhBf74cNg9v11kdk/afvh6wXbOX0pnM5P++FxUgpfzd7C8XM3Cb8fzelLt+k7YSUPIuNoWrtsnrTxVfT8qBbLfjnMqq1HuHzzAQOnrOVJUgofPZ0F6DF6GeN+fN4P3dqEsOfPC/ywcg9Xwh4wed52Qi/epsuHNXUxMXGPOXvlDpdvau8OvHrrIWev3OHhI2Wu5QLo8mEIq7b+xc+/HuVq2ENGfLOOJ0mpfNhIezz0+2olk+c+Hx86t6rJgSOXmLd6H9duPWT6oh2cuRxOxxY19Pab8DiZbftP5+msCihogW1WKpUKtVpNUlISrq7Gszl3d3eKFy+erbxMmTL4+fkxY8YM2rRpo3c56fTp0+zevZtJkyYZ3a+5uTnFixfPs7uBAI7cisHG0pSWpQtjZ2XG7Zgkvt57TXebsUN+c16cN8pvYcKnVYpiZ2XG49QMwqKeMG7HZb3LPifC41h8JJymgYX4uKI79+O1Xwh35RVna/JC7eqliI1/zOLVe7RfCudRmKlfdNBdBnr4KFZvjcUvO4+Slp7B6Gmr9PbT4YNadGpdB7Vaxe27j/jtwE/ExT/B1iYffsVd+X58FzzdC6FUTWqXJToukZlLdvAoOh7/4q4snvIZjk+nr+9HxKB+oR/KB3oyY2R7pi/6lW8WbKOYqxOzx3fC17OwLiYiKp6vZm0mKiYBJwdb3q9fgc8/rpfrbXsd79crR1RsIlPmbyciKp7AEm6smdED56fT/ncexOjWZwFUCvJizrgOTJq7ja/mbMHL3ZmlU7vgX1yb6N+PiGXHIe33EdX6eIrea236sXe2O6qUonndckTFJDJ1wfanX4bmxqoZPXSLie8+1D8eKgZ5MXtsBybP28bEOVvwdHdmyZTn/WCiVnPt1kPWbj9KdFwiBe3yU8a/KL/M7oufV2GDdVCCFvXKExWTyKR524iISiDQx5Wfv+35/HjI0g+Vg7yYN74jE+dsZcKsrXi5O7Hi666ULP78g9+vh87y+biVup+7fLEEgCFdGjLss0a507DX1KxOWaJjE5m+aAeRT78kcPm0brrLxPcexqB+4byoUMqT7778mGkLtjN1/jY83JyY/1VnfLP8rjfvOYlGo+G9OuVytT1ZqTSvs6L0LenYsSMPHz5k8eLFAMTExPDDDz8we/Zs9u7dS0hISLZtwsLC8PT05NSpU5QpU8bgfg8fPky9evWoX78+w4cPx8XFhSNHjjBw4EDc3d3Zu3cvFhYWbN26ldWrV9OmTRt8fHzQaDRs2bKFYcOGsXjxYj7++ONXakd8fDx2dna89+MBzKyUuXo+twyq6ZXXVVAEd4d8eV0FRbC1Uuznolyl4O9ezFVmJv/NBdyGJCr4O65yQ0J8PMXdHImLi3vp1QnFjCA7duygcGFtRmdjY4Ofnx8///yzwUTlVVWrVo2//vqLsWPH0rBhQxISEihatCgdOnRg+PDhWFho126ULFmSfPnyMXDgQMLDw7GwsKBEiRIsWLDglRMVIYQQQrwdiphZ+X8hMyvPycyKlsysaMnMipbMrGjJzMpzMrPyajMrillgK4QQQghhiCQrQgghhFA0SVaEEEIIoWiSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFokqwIIYQQQtEkWRFCCCGEokmyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIommleV+D/0ddNS2Jja5vX1chTbRYfy+sqKMLKDhXyugpCQdLSM/O6Coqg0ajyugqKkZz23z4mXrX9MrMihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFokqwIIYQQQtEkWRFCCCGEokmyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0SVaEEEIIoWiSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUzTSvKyBebtnG35m3eh+R0Qn4exdhTJ/3KeNfzGj8tv2hTF+4gzsPovF0c2RotybUqlJS9/zjJylMmbeVXb+fIyb+Me6FHejYogbt3quWG815Y01LudCqrCsF85lz49FjZh28wZWIRKPx+c1N6FilGNWLO2BtaUpEQgpzD93k2K0YABoHutAk0AVnWwsAbkc/YeXRcI7fjs2N5ryx5Zt+Z8Ga/drjoXgRvuz9PqX9ixqN377/NDMX/8qdBzF4uDkypGsTQqr4655/FJ3A1Plb+f34FeITk6gY5MXo3u/j4eaUG815YwvXHeTHFXuJiI4nwNuVSQNbUS7A+Hnxy55TTJ63jfD70Xi5OzGqVzPqVQsAIC09g0lztrL7zwvcuhuFjbUlwRV9GdWzGS5OdrnVpDeyZMMh5qzaqzsexvdrSdmSxvth675Qvl6wnTsPovFwc2JE96bUqfp8fOj/1Up+3nFMb5vgSn6s/Kb7W2tDTli0/hCzVu4lMjqekt6ufDWgJeVe0g+b955i6rzthD+IxtPNiZE9m1L36fEA8PWCX/ll90nuRsRibmZCkK87w7s1plyARy605s2t2PQ7C9dqxwe/4kUY1ft9SvsZHh+uhj3g2yU7OH/lDncfxjCi53t0bFnzH+3zbZKZFQXbuvcUX836hb4dG7B1/gD8ixehw+B5PIpJMBh/4txN+o5bwYeNK7FtwUDqvVOKbiMXc/nGfV3MhFm/cPDoJWZ80Y7dS4fRqVVNRn+7gV1/nMutZr22mt6OdH3HkxXHwvl8TSg3oh7zVbMA7KzMDMabqlVMei+AQrYWTPj1El1XnOTbvdd4lJiii3mUmMKiP2/Re81p+qw9TeidOEY39qeYvVVuNeu1bdt3iomzN9P7k/r8Mrc/fsWL0GnoPKKMHA8nz92k/4QVfNCwMpvnDaBe9UB6fLmYKze1x4NGo6H7l4sJvxfNnPGd2Dx3AK6FCvLJoLk8SUoxuE8l2LjrJF9+u5FBXd5lz9LBBJRw5cN+s4iMNtwPR8/coNuXS2nXtCp7lw6hYc0gOgxZwMXr9wBISk7lzOU7DOjUgD1LB7Nk8qdcuxVB+8HzcrNZr23znpOM+2ET/Tu+y68LBlHS25X2A+cYHR+On71Jr7HLaNO4CjsWDuLdGqXoMmIhl14YHwBCKvtxctM43ePHMZ/kRnPe2KbdJxnz3UYGdm7AzsWDCfAuQtv+s40eD8fO3qTH6GW0bVqFXUsG07BmKToNW6g7HgCKF3Vi4sBW7F8+lF9m98W9sD2t+83mUYzxD0h5bdu+U0yas5nPP6nPpjna8eHTl4wPScmpuBd2YGCXxjjZ2+TIPt+mPE9WOnbsiEql0j0cHBx49913OXPmjNFtwsLCUKlUODs7k5Cg32llypRhzJgxup9DQkL09v/s0b17d719hYaGZnudkJAQ+vXrlxPNfCMLfj5A68ZV+KBhJUp4uPDVgFZYWZrx8/ajBuMXrz9EcCU/urWpjXexQgz8tCEBJVxZtvF3XczJc2G0eLciVcp641bYno+aVsXfuwinL97OrWa9thZlirDj/EN2XYzgdkwS3++7Tkp6Bg38nQ3G1/cvhLWlKWO3X+LCgwQeJqRw9l48N6Oe6GKOhMVw7FYM9+KSuRubzNK/bpOcloFfIcMnrRIs+vkgrRtVodXT42F8/5ZYWZjx86+Gj4clGw5Rs5IvXdvUwrtYIfp3bkjJEq4s3/QHAGF3HhF64RZj+7UkyK8oXkWdGdevJcmpaWzZeyo3m/Za5qzaR/v3qvFRkyr4ehZm2tAPsbI056etfxmMn7fmALWr+PN5+zr4eLowvFtjgnzdWLjuEAC21las+74XzeuWw7tYISoEejJ5UCtOXwrnzoPo3Gzaa5m3Zj9tm1aldePK+Hi6MHnQB1hamrN62xGD8QvXHSCkkh89PqpNCQ8XBndpRKCPG0s2HNKLszAzxdnBVvcoYJMvN5rzxuau3k+7ZtVo26QKvp4uTB3yIVYW5qw2cjzMX3uAWpX96NWuDj4eLgz9rDGlfN1YvP55P7SoX4GaFX0p5uqIn1dhxvZ5n4THyVy8fje3mvXaFq87yIeNqtDy3Up4e7gwrl9LLC3MWLfD8PgQ5FeUod2a0qR2WczNDF9ked19vk15nqwAvPvuu9y/f5/79++zZ88eTE1NadKkyd9ul5CQwLRp0/42rmvXrrr9P3tMnTo1J6r+1qSmpXPu8h3eKe+jK1Or1VQv78PJC2EGtzl1Pozq5UvoldWs5KcXXy7Qgz1/nOdBZCwajYY/T13lZngkNSr6vo1m/GOmahUlnK05FR6rK9MAp+7E4e9iOLGo4lmQSw8S6BXsxarOFZnTtgyty7uhVhl+DbUKgks4YmFmwsUHuf+J4VWkpqVz7sodvd+vWq2mWnkfTl24ZXCbUxduUa2cj15ZjYq+nDofptsngIX584FKrVZjbmbCiXM3c7gFOSM1LZ3Tl8MJfuF4VavV1Kzoy/Gzhut8/FwYNSvq90OtKv5G4wHiE5NRqVTY2Shzpi01LZ2zV+5QI8v4UKOCDyef/n6zOnEujBoV9PshuJIfJ87px/8Zeo3STUdS86OvGD5tLTFxj3O6+jkmNS2dM5fDqVkhSz9U9OF4lnY9c+LcTWpmGe9CKvsZjU9NS2f5L4extbaipLdrTlU9R6WmpXP+yh2qlcsyPpTzIdTI+JAX+/wnFLFmxcLCAhcXFwBcXFwYNmwYNWrUIDIyEicn49fOe/fuzfTp0+nVqxfOzoY/ZQPky5dPt/9/i5i4x2RkZuKYZXrOsaAN129HGNwmMjrBYPyL06Fj+rRgxDdrqfrBOExN1KjVKiYO+pDKpYvnfCNygK2VGSZqFbFJaXrlsU9ScS9geD1BYTtLCtlYsu9KJKO2XKCInRWfh3hhqlax8li4Ls7DIR8zWgZhbqomKS2D8dsvcTsm6a225009Ox4cCmb9/Vpzw8jx8Cg6AceC1lnibYh8OoXrVdSZIs4FmbZgOxMGtMLK0pzF6w7yIDKOiKj4t9OQfyg69jEZGZnZpq2dC9pwLeyhwW0iouJxtrfVK3MqaENElOHENDkljXE//kKLeuWwya/MZCU6znA/OBa04dotw/1gaHxwsrchMvr57zqksj8Ng0vjXtieW3cfMWXeNtoPnsvm2f0wMVHEZ1s9xo4HJ3sbrt0yfF5ERCXglOU80h4P+sf8zj/O0f3LpSQlp1HIwZY1M3vgUED/fFIK3fuFofEh3HA/5MU+/wlFJCsvSkxMZMWKFXh7e+Pg4PDS2LZt27Jr1y7GjRvHDz/8kEs1fC4lJYWUlOfX9uPjlTnAv2jphkOcunCL+RM/xbVQQY6evs7omRso5GDHO1k+df1bqVTa5ObbfdfI1MC1yMc4WpvTqqyrXrJyJyaJnmtCyW9uQg1vRwbWLcGQDWcVm7DkNDNTE2aN68Dwr9dS/r1RmKjVVCtfguBKfmjyunJ5JC09gy5fLEajga+HfpjX1cl179Utp/u/f/Ei+HsXoXrrCfx56tr/zfjwqqqXK8GepUOIjn3Mis2H+WzUErbPH2B0fYd4uxSRKm/duhVra2usra2xsbFh8+bNrFmzBrX65dVTqVRMnjyZefPmcf36daNxs2bN0u3/2WPlypX/uN6TJk3Czs5O93B3d//H+3ymoF1+TNRqHmVZJPYoJsHoyeJkb/PS+OSUVKYt2M7Inu9Rt1qAdsFuixo0rlWG+Wv25Vjdc1J8UhoZmRoKZFlMWyCfOTFPUg1uE/04lbuxSWS+8I57O/oJ9vnNMX3hWlB6pob7cclci3zM4j9vcfPRY5qXLvJW2vFPPTsesi5sexSTmO3T8jOO9jbZFgQ+itH/VBno486W+QM5tXkCh9eNZvGUz4iNf4J7Yfucb0QOsC+QHxMTdbbFkxExCTg7GO4HZwdbIqL1P0hEGoh/lqjceRDNuu97KXZWBcDeznA/PIpJwNnB1uA2hsaHyOgEnOwNxwMUK+KIvV1+wu5G/vNKvwXGjofI6AScjZwXzg7PZxd18Qb6Lb+VBZ5uTpQP9GDGiI8wNVGzysg6mLyme78wMD68aXL1Nvb5TygiWalVqxahoaGEhoZy9OhRGjRoQMOGDbl16xYNGzbUJRgBAQHZtm3QoAHvvPMOo0aNMrr/du3a6fb/7NGsWbN/XO/hw4cTFxene4SHh//9Rq/I3MyUQF83/jh5VVeWmZnJ4RNXKVfSw+A2ZQM89OIBfj9+RReflp5JWnoG6iyLN0xMVGRqlPlZOj1Tw9WIRMq4P7/kowLKuNkZXV9y4X48RewsebGVrgWsiHqcSnqm8XaqVGBmYmRhSx4zNzMl0MeNw1mPh5NXjd6qWrZkMb14gD+OX6GsgdsvbaytcChgTdidSM5eCadutcAcrX9OMTczpbSvOwePXdGVZWZmcujYZSqU8jS4TYVADw69EA9w4OglvfhnicqN8EjWfd8Le7v8b6cBOcTczJRSPm78fkL/ePj9xBWjt9eWD/TQiwc4dPwy5QMNxwPci4glJv4Jzg7KvIXb3MyUIF93Dp3QPx5+P36FCkbaVT7Qk0PH9Y+Hg0cvG41/vl8NKanp/7TKb4W5mSkBPm78eUr/ePjz1FXKvOQW7tze5z+hiMtA+fPnx9vbW/fzggULsLOzY/78+SxYsICkJO20vJmZ4VtVJ0+eTNWqVRk8eLDB5+3s7PT2/yJbW202HRcXl+252NhY7OyMn6QWFhZYWFgYff6f6vJBMAMnrSLI153S/kVZtO4AT5JTadWwEgADJv6Ei6MtQz7TLkbu1LIGbfr+yPw1+6ldxZ8te09x9nI4Ewd+AIBNfksqly7OpNlbsDQ3w9WlIEdCr7Pht+OM7PXeW2vHP7Uh9B6D6pbgakQilx8m8n7pIliamrDzova66aC6JYh6nMriP7WLvraee0DToMJ0r+nJ5jP3cbWzok0FN345/fwWzU5Vi3HsVgyRCSlYmZtQy8eJIFc7vth8Pk/a+Co6f1CTwZNXU8rXnSC/oixZf5Ck5FRavas9HgZN+olCjnYM7toYgI4tavBR/1ksWLufWlX82bo3lHNX7vDV0+MBtN/DYl8gP0WcC3L55n0m/LCJetUDFbvgGqB721r0Hr+CMv7ulCtZjLlr9vMkOZW2jSsD0Gvsclyc7BjVU/uB5LPWwbzX4ztmrdxLveoBbNx1gtCL4XwzrA2gTVQ6D1/Imct3WPlNNzIyNTx8un6hoG0+o3dK5LXPWofQf+JPlPZzp4x/URb8fICkpFRaN9L2Q98JK3BxtGN496YAfNoqmFa9v2fu6n3UqVqSX/ac5MylcKYMbg1ov4Np+uIdNAopjbO9DbfuRvHV7M14uDoSXMkvz9r5d7q1CaHvhJWU9itK2ZJFmb9GO062aaLth8/HraCwkx1f9ND2Q9cPg3m/53fM/mkvdasFsGn3SU5fCufroU/7ISmFb5fupME7pXB2sCU67jGL1x/iwaM4mtYuk1fN/FudWtVk6JTVBPpox4elT8eHlg2048PgydrxYVAX7fiQmpauW9+Ulp7Bw0dxXLh2l/xWFhRzdXylfeYmRZ6FKpUKtVpNUlISrq5/v/q6UqVKtGjRgmHDhr32a9nb2+Po6MiJEycIDg7WlcfHx3Pt2jV8fPLuOm2T2mWJik1k+uIdPIqOx9/blSVTP9NNwd17GINa9XwmoHygJzNHteebhb8ybcE2PFydmDuhE75ehXUx33/5MVPnb6PfVyuIjX+CayF7BnVpRLtmyv1SuIPXHmFnZcrHlYpSML85NyIfM3LLed2iW2cbCzQvzAw9Skxl5OYLfPaOJ7PbuPDocQqbTt/n55N3dDEFrMwYXLcEBfOb8yQlnZtRT/hi83lOhWdPWpWica2yRMU+Zubi34iMiadkcVcWTemquwx0LyJWb9asXKAn079oz4xFv/LNwu14uDoxe1wnfDyfHw+R0fFMnP0LUTGJONnb8n798vT6uF6ut+11vF+vHFGxiUyZv52IqHgCS7ixZkYP3TT+nQcxqF44LyoFeTFnXAcmzd3GV3O24OXuzNKpXfAvrr3kdz8ilh2HtN8zVOvjKXqvtenH3tnusFOKZnXKERX7mGkLf9V9Gdryad1048PdLONDhVKe/DD6E6bO38aUeVvxdHNiwcRP8Xs6PqhNVFy6fo91O44Rn5hEIUdbalb0Y3CXRnp3jClN87ra42Hq/O1ERscTUMKNVdO76y5v3X0Yo3deVCzlyayxnzBl3nYmzdX2w+LJn+qOBxO1mmu3Ili7fRHRcYkUtMtPGb+ibJrVR9dXStS4Vlmi4x7z3RLt+OBf3JWFk5+PD/cjYvWOh4ioeJp3m677eeHa/Sxcu59KpYuzYnrPV9pnblJpNHk7/9+xY0cePnzI4sWLAYiJieGHH35g9uzZ7N27l5CQkGzbhIWF4enpyalTpyhTpgwAV65cISAgAFNTU4YOHar7rpWQkBB8fHwYN26c3j4sLCwoWLAgoF178s033/Dtt99SpUoVoqKiGD9+POfOnePChQtYWb3atev4+Hjs7Oy4cjsSG1vj14H/C9osPvb3Qf8BKztUyOsqKIJdPsOzov81KWmZeV0FRTBV6OXWvBCfpMxLS7klIT6eAE9n4uLidFc6DFFEurxjxw4KF9ZmrDY2Nvj5+fHzzz8bTFSM8fHxoXPnzsybl/1bJ+fPn8/8+fP1yho0aMCOHTsAGDJkCNbW1kyZMoXr169jb29P9erV2bdv3ysnKkIIIYR4O/J8ZuX/icysPCczK1oys6IlMytaMrOiJTMrz8nMyqvNrCjibiAhhBBCCGMkWRFCCCGEokmyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0SVaEEEIIoWiSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFokqwIIYQQQtFM87oC/4+sLEzJZ/Hf7to1nSvldRUUwf/zn/O6Copwb9FHeV0FRTBRq/K6CoqQmp6Z11VQDGvL//Z7RWbqq7VfZlaEEEIIoWiSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFokqwIIYQQQtEkWRFCCCGEokmyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0SVaEEEIIoWiSrAghhBBC0SRZEUIIIYSimeZ1BcTLLVp3kFkr9xIRHU9Jb1cmDmhFuYBiRuM37znFlHnbCH8QjaebE6N6NaNutQDd818v2M6mXSe5GxGLuZkJQb7uDO/ehPIBHrnQmje3bOPvzF29l8joBPyLF2Fs3xaU8TfeD9v2hfLNol+58yAaT1cnhnVvQq0qJXXPewT3N7jd8O5N6da2do7XP6d0rF2CHu/642RnxYXwGEauPEHozSij8V3q+dKhVgmK2OcjJjGFrcfDmbQulJT0TAA+b1SSRuXd8S5sS3JqBsevRfLVulCuP0jIrSa9kflrD/D9ij1ERMUTWMKVKYM/eOkxvGn3SSbO2cbt+1F4uTsxpndz6ld/fl5oNBomzd3Gsk2HiUtMonKQF98Ma03xos650Jo3t+Dng7p+CCjhypRBrf6mH04xae5Wbt+P1vbD5+9R74V+2LIvlMUb/uD0xdvExD/hwIqhlPJxy4WW/DOL1h9i1sq9RD4dJ78a0JJyJV8yTu49xdR523Xj5MieTbOMk7/yy+4s42S3xpRT+Di5eP0hZv/0vB8m9G9J2Zf0w5a9p5g6f7t2nHRz4oseTanzQj+8aOjUNSz/5TBj+7xP19Yhb6kFxsnMioJt2n2S0d9tZOCn77JryWACSrjSpv8sIqMNv5EcO3OD7qOX8lHTquxeOoSGNYPoOHQBF6/f08V4uTszceAH7F8xjM1z+uFe2J7WfWfxKEa5b05b9p5iwo+b6NuhAdvmD6Rk8SJ8Mmiu0TqfOHeTPuOX07pRZbbPH0T9GoF89sUiLt+4r4s5umGs3mPq0DaoVCoaBgflVrNeW7OKRRnduhzTN5+jwdhfuRAey08DauFgY2Ew/v3KxRjRqgzTfzlL8BfbGLj4CM0qFWVYyzK6mKq+zizZe4UmE3bS5pu9mJqoWTWgNlbmJrnUqte3YecJRs7cyNAuDdm/fCiBJVxp2ftHo+fFkdM36DJyCe3fq8qBFcNoHFya9oPmceHa8/Pi22W7mbvmANOHt2HX4kHkszKnZe8fSU5Jy61mvbYNu7T9MKRLQ/YtG0JgCVda9TE+Phw5c4Ouo5bQrllV9i8fSqPgINoPns+FF8aHJ0mpVCntxejP38utZvxjm3afZMx3GxnYuQE7Fw8mwLsIbfvPNj5Onr1Jj9HLaNu0CruWDKZhzVJ0GrZQb5wsXtSJiQNbsX/5UH6Z3Vc7TvabzaOYxNxq1mv7ZfdJxn6/kQGdG/DbosGU9C7CRwNmGx0nj529Sc8xy2jbpAo7Fw/m3Rql6Dx8IZdu3MsW++uB05w4fwsXR7u33Qyj8jRZ6dixIyqVSvdwcHDg3Xff5cyZM0a3CQsLQ6VS4ezsTEKC/i+hTJkyjBkzRvdzSEiI3v6fPbp376633b59+2jSpAlOTk5YWlpSvHhxWrduzcGDB3O0va9rzqp9tG9WjbZNquDrWZivh3yIlYU5q7b+ZTB+3toD1KrsT6/2dfDxcGFYt8aU8nVj0bpDupiWDSoQXMkXD1dH/LwKM67v+yQ8TtYbuJVmwdr9tGlSlQ8bVaaEhwtfDfwAK0tz1m4/YjB+0bqDBFfyo1vb2nh7FGLgp40I8HFj6cbn/eDsYKv32PXHOaqW9aZoEcfcatZr+6yBHz8dvM6a329w9V48Q5cdJSk1nbY1ihuMr+DtxLGrkWw8cos7UY85cP4Bm47coqyXvS6m3Yz9rP3jJlfuxXEhPJZ+i/7CzTE/QR72BvepBLN+2ssnzavRrllV/LwKM314G/JZmrNi858G4+eu3k+dqv70+bguvp4ufNGjCaX93Jn/8wFAO6syZ9U+BnVuQKPgIAJLuDJ77Cc8eBTHtgOnc7Npr2XWT/v4pHlV2jWtou2HYa3JZ2nOyi0v6YcqL/RD9yYE+bmzYO3zca51o0oM6dKQkEq+udWMf2zu6v20042TLkx9Ok6uNjJOzl97gFqV/ejVTjtODv1MO04uXv98fGhRvwI1K/pS7Ok4ObaPdpy8eP1ubjXrtc1bs5+PmlajTeMq+Hi6MGXwy98vFjzth57t6lDCw4UhnzWmlI8bi194vwC4HxnLyBnr+XH0x5ia5t2HmDyfWXn33Xe5f/8+9+/fZ8+ePZiamtKkSZO/3S4hIYFp06b9bVzXrl11+3/2mDp1qu75WbNmUadOHRwcHFizZg2XL19m48aNVKtWjf79DV8qyA2paemcuRxOjYrPBw21Wk3Nir4cP3fT4DYnzoVRs6KPXlmtyv5G41PT0lm+6TC21lYElHDNucrnoNS0dM5duUP18s/bpVarqV6+BCfP3zK4zanzYXrxADUr+hqNj4xOYN+fF2jdqHLOVTyHmZmoCSpmz6ELD3RlGg0cuvCA8sUNJ1jHr0US5GFPGU8HAIo65adOqSLsOWM8MbW1MgMg9nFqDtY+56SmpRN6KVzvzVStVhNcyZdjZw0f50fP3iSkop9eWe0q/hw7GwbArbtRPIyKJ6TS8xg7ayvKB3hw7ExYjrchJ6SmpXP6UjjBWcaH4Iq+unZldexsGMFZkpDaVfyM9tu/wbNxsmYF/fGhRkUfjp8LM7jNiXM3qVlRvx9CKvsZjU9NS2f5L9pxsqS3csdJ7ftFln6o4MMJY/1w/iY1Kuj3Q3BlP06cfx6fmZlJn3Er6PFRbXy9Cr+Nqr+yPF+zYmFhgYuLCwAuLi4MGzaMGjVqEBkZiZOTk9HtevfuzfTp0+nVqxfOzsavK+fLl0+3/6xu375Nv3796NevH9OnT9d7LigoiD59+rxBi3JGdOxjMjIycbK30St3srfh6q2HBreJiIrHyd42W3xElP4M1M7fz9HtyyUkJadRyMGWtd/2xKGAdc42IIfExGn7wbFgln4oaMP12xEGt4mMTjAY/yg63mD8+h1HyZ/PkgY1lXsJyN7GAlMTNZHxyXrlj+KT8S5sa3CbjUduYW9jwabhdVGhwsxUzdJ9V/l+2wWD8SoVjG1bnqNXI7h8Ny7H25ATomITjZwXtlwNe8l54ZD9PIqI0h4PD5/+mzXG2eF5jNJE6caH7Of7lZeMD85Z+s3Z3oYII5dL/g1eNk5eu2V4fIiISsDJwPiQ9Xe9849zdP9yqW6cXDOzh2LHSWP94GhvwzVj42RUAo4G+u3FfvhxxR5MTNR8+kFwzlf6NeX5zMqLEhMTWbFiBd7e3jg4OLw0tm3btnh7ezNu3Lg3fr3169eTlpbGkCFDDD6vUqleun1KSgrx8fF6j3+D6uVLsHfpULbO60etKv50HbnY6PXd/4K1vx6led1yWFqY5XVVclRVX2d6Nw5gxPLjNBj7K51/OEjdoCL0axpoMH5i+4r4udrRY84fuVxTIZSnerkS7Fk6hK1z+1Grih+fjVrynxonz1wKZ8HPB5j5Rbu/fS/MDXmerGzduhVra2usra2xsbFh8+bNrFmzBrX65VVTqVRMnjyZefPmcf36daNxs2bN0u3/2WPlypUAXLlyBVtbW72Zl/Xr1+vFnj171ui+J02ahJ2dne7h7u7+mq03zr5AfkxM1NlOjsjoBJyzfAJ8xtnBlsgssweG4vNbWeDp7kSFQE9mfvERpiYm/GTkOndeK2in7Yesi8QiYxKyfap8xsnexmC8o4H4o6evc+N2BK2bVMm5Sr8F0QkppGdk4mRrqVfuaGtJZFyywW2GvB/E+sM3+enQdS7djWPHyTtMWn+a3o1KknXs+apdBeqVLkKrqXu4H5P0tprxjzkUsDZyXsTj7GD4eHB2sCUyytB5pI0v9PTfrDERUQlG95nXHHTjQ/bzvdBL+iHrLEpEdEK22ZZ/k5eOk0ba5exgQ6SB8SHr7zq/lQWebk6UD/RgxoiPtIvPjaz/yGvG+uFRdEK22ZZnnBxseGTw/UXbD0dOX+dRTCIVW47BvWZ/3Gv2586DaMb+sIlKLce+nYa8RJ4nK7Vq1SI0NJTQ0FCOHj1KgwYNaNiwIbdu3aJhw4a6pCEgIPvtVA0aNOCdd95h1KhRRvffrl073f6fPZo1a6Z7PmvG2KBBA0JDQ9m2bRuPHz8mIyPD6L6HDx9OXFyc7hEeHv4GPWCYuZkpQb7uHDp+RVeWmZnJoeOXqRDoaXCb8oEeevEAB45eMhqv268mk9S09H9e6bfA3MyUQB83Dp/Q74fDJ68avYW7bICHXjzA78evGIxfs/0IpXzdFHst+pm0jEzO3IrmHf9CujKVCt7xd+HE9UcGt7EyNyVTo1+WqdEWqHh+3H/VrgLvlnPjg6l7CX/0OOcrn4PMzUwp4+fOgWOXdWWZmZkcPHaFiqUMH+eVSnnqxQPsO3KJiqU8ACjm6kAhB1u9mPjEJE6cD6NikEeOtyEnmJuZUtrPnYPH9M+LA8ev6NqVVcVSHnrxAPuPXDbab/8GunEyy/jw+/ErVAj0MLhN+UDPbOPkwaOXjcY/36+GlFTljpNBvu78nuX94vcTVyhvrB8CPPX6DeDgscu6W99bvluRPcuGsGvJYN3DxdGOHh/V5qfp3Q3s8e3K8zUr+fPnx9vbW/fzggULsLOzY/78+SxYsICkJO2nPDMzw1P0kydPpmrVqgwePNjg83Z2dnr7f1GJEiWIi4vjwYMHutkVa2trvL29MTX9+66xsLDAwsLwbaM5oXvbWvQZv4Iyfu6UDSjGvNX7eZKcSpsm2oWgn49djouTHSN7apOvzz4MpnnP75j9017qVgtg0+4TnL4UzrRhbQB4nJTCzCU7aVAjkEIOdkTHJbJo3SEeRMbRtHbZt9aOf6rLhyEMnPQTpfzcKeNXjIXrDvAkKZUPGmr7YcBXKynkZMfQz7QLszu3qknrPj8wf80+alUpyZa9pzh7OZxJgz7U22/C42S27z/NFz2bZXtNJZr32yVmdqnK6bBoTt2Moms9X/JZmLL69xsAfNulKg9injBpvfYOll2n7/JZfT/O3Y7h5I1HeDrbMLh5ELtO39UlLRPbV+D9Kh50+u4giclpupmbhKQ0ktOMJ+p5qedHtek5djll/YtSLsCD2av28TgphXZNtbNj3Ucvo7CTne72225tQmjSbSY/rNhD/XcC2LDzBKEXbzNzRFtA+4Gle9taTFu0Ay93J4q5OjBxzjZcHO1oHFw6z9r5d3p+VIteY1dQxr8o5QKKMWf1fp4kpfDR01nCHqOXUdi5AF/20h7f3dqE0LTbt/ywcg/1qwewYedJQi/eZsaINrp9xsQ95s7DGB5EatcsPVsf52xvSyFHZc4ydWsTQt8JKyntV5SyJYsyf80B/XFy3AoKO9nxRY+mAHT9MJj39cbJk5y+FM7XQ1sD2nHy26U7afBOKZwdbImOe8zi9Yd48CiOprXL5FUz/9ZnrUPo99UL/bD2aT801vZDn/ErcHG0Y8TTfujyYTAte33HnFV7qVMtgF92n+TMC/1gb5cfe7v8eq9hamqCs70t3sUKkdvyPFnJSqVSoVarSUpKwtX17z/tVqpUiRYtWjBs2LDXfq1WrVoxbNgwpkyZwowZM96kum9V87rliIpJZOqC7U+/9MmNVTN64Pz0csbdhzGo1c8/IVcM8mL22A5MnreNiXO24OnuzJIpXfAvXgQAE7Waa7cesnb7UaLjEilol58y/kX5ZXZf/PJ4pffLNK1dlujYRGYs2kFkdDz+3q4s/bqbbnrzbkQMqhf6oXygJ9+O+phvFm7n6/nb8HBzYt5XnbOtZt+y5yQajYZmdcrlanve1OZjt3GwsWRw8yCc7Cw5Hx5Duxn7ePR00a2rfT4yX5hKmbnlHBqNhiHvB+FS0IrohBR2nb7L5PXPb8ftWFt798CGYXX1Xqvfwj9Z+4cy7xJpUb88j2ITmTh3GxFRCZTycWXdd71009d3HkSjfmHGtHJpL+ZP6MhXs7cyftYWvNydWDHtM0p6F9HF9P2kLk+SUug/cRVxiUlUKV2cdd/1VPQ6phb1yhMVk8ikedp+CPRx5edvez7vhyzjQ+UgL+aN78jEOVuZMGurth++7krJ4s/74ddDZ/l83Erdz12+WALAkC4NGfZZo9xp2GtqXrccUbGJTJ2/ncjop+Pk9O66y8TZxslSnswa+wlT5m1n0tyteLo5sXjyp1nGyQjWbl/0fJz0K8qmWX0UPU6+97Qfvl7wvB9WfpOlH1T6/fDjGG0/TH7aD4smfYqfVxFjL5GnVBqNRvP3YW9Hx44defjwIYsXLwYgJiaGH374gdmzZ7N3715CQkKybRMWFoanpyenTp2iTJkygHbtSUBAAKampgwdOlT3XSshISH4+PhkW4RrYWFBwYIFAfj+++/p27cvH3/8MR07dsTT05Po6GhWrFjBjBkzOHPmDKVKlXql9sTHx2NnZ0f4wxhsbZX5KSS3JKUq81N5bvP//Oe8roIi3Fv0UV5XQRHycLhVlNSn36AsyHap9r8mPj4ej8L2xMXFvfR9M8/XrOzYsYPChQtTuHBhKleuzLFjx/j5558NJirG+Pj40LlzZ5KTsy80nD9/vm7/zx5t27bVPd+7d2927txJZGQkrVq1okSJEjRq1IibN2+yY8eOV05UhBBCCPF25OnMyv8bmVl5TmZWtGRmRUtmVrRkuNWSmZXnZGblXzKzIoQQQgjxMpKsCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFokqwIIYQQQtEkWRFCCCGEokmyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0SVaEEEIIoWiSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaKZ5XYH/R+amasxN/9t54H+9/c/cW/RRXldBEfpuPJ/XVVCEcu7587oKitDUr0heV0ExbCz/22/DpmrVK8XJO4oQQgghFO2VUrrNmze/8g6bNWv2xpURQgghhMjqlZKV5s2bv9LOVCoVGRkZ/6Q+QgghhBB6XilZyczMfNv1EEIIIYQw6B+tWUlOTs6pegghhBBCGPTayUpGRgbjx4/H1dUVa2trbty4AcCoUaNYuHBhjldQCCGEEP9tr52sfPXVVyxZsoSpU6dibm6uKw8MDGTBggU5WjkhhBBCiNdOVpYtW8a8efNo164dJiYmuvLSpUtz6dKlHK2cEEIIIcRrJyt3797F29s7W3lmZiZpaWk5UikhhBBCiGdeO1kpWbIkhw4dyla+bt06ypYtmyOVEkIIIYR45rW/5/fLL7+kQ4cO3L17l8zMTDZs2MDly5dZtmwZW7dufRt1FEIIIcR/2GvPrLz33nts2bKF3bt3kz9/fr788ksuXrzIli1bqFev3tuooxBCCCH+w97oLyjVqFGDXbt25XRdhBBCCCGyeeM/93j8+HEuXrwIaNexlC9fPscqJYQQQgjxzGsnK3fu3KFt27b88ccfFChQAIDY2FiqVavG6tWrcXNzy+k6CiGEEOI/7LXXrHTp0oW0tDQuXrxIdHQ00dHRXLx4kczMTLp06fI26iiEEEKI/7DXnlk5cOAAhw8fxtfXV1fm6+vL999/T40aNXK0ckIIIYQQrz2z4u7ubvDL3zIyMihSpEiOVEoIIYQQ4pnXTla+/vprevfuzfHjx3Vlx48fp2/fvkybNi1HKyeEEEII8UqXgQoWLIhKpdL9/PjxYypXroypqXbz9PR0TE1N6dy5M82bN38rFRVCCCHEf9MrJSszZ858y9UQQgghhDDslZKVDh06vO16CCGEEEIY9MZfCgeQnJxMamqqXpmtre0/qpAQQgghxItee4Ht48eP+fzzz3F2diZ//vwULFhQ7yGEEEIIkZNeO1kZMmQIe/fuZfbs2VhYWLBgwQLGjh1LkSJFWLZs2duooxBCCCH+w177MtCWLVtYtmwZISEhdOrUiRo1auDt7U2xYsVYuXIl7dq1exv1FEIIIcR/1GvPrERHR+Pl5QVo16dER0cD8M4773Dw4MGcrZ0QQggh/vNee2bFy8uLmzdvUrRoUfz8/Fi7di2VKlViy5Ytuj9sKHLO/LUH+H7FHiKi4gks4cqUwR9QPsDDaPym3SeZOGcbt+9H4eXuxJjezalfPUD3vEajYdLcbSzbdJi4xCQqB3nxzbDWFC/qnAuteXPSD1rSD1rveNpTu4QDtpam3I1LZv2ZB9yOSTIYW6loAdqVd9UrS8vIZNDmi7qfg4rYUN3DHveCluQ3N2Xq3uvcjUt+q23ICYf2n2LvrmMkxD+miJsTLVvXoZhHYYOxp09dYfeOI0RGxpKZkYGjc0Fq1a1AxcrPj4eU5FS2bDrI2dPXePI4GXsHW2rWKkf1mmVyqUVvZvnG35m/Zh+R0Qn4Fy/C6D7vU9q/mNH47ftDmbFoB3ceROPh5siQz5pQq0pJ3fOPohOYMm8rvx+/THxiEhWDvBjdpwWebk650Zw3tnDdQWat3EtEdDwB3q5MHNCKcgHG+2HznlNMnreN8AfReLk5MapXM+pW0x4PaekZTJq7lT2HL3DrXhQ21pbUrODLqJ7NcHGyy60m6bz2zEqnTp04ffo0AMOGDePHH3/E0tKS/v37M3jw4Byv4H/Zhp0nGDlzI0O7NGT/8qEElnClZe8fiYxOMBh/5PQNuoxcQvv3qnJgxTAaB5em/aB5XLh2Txfz7bLdzF1zgOnD27Br8SDyWZnTsvePJKdk/xMKSiH9oCX9oFXW1Zb3SxXit0uRfL3vBvfikulRrRjW5iZGt0lKy2Dk9su6x9jfrug9b26i5kbUEzafe/i2q59jTh6/xKb1+3m3cVUGjfgYVzdn5ny3joT4xwbj8+W3pF7DKvQb/BFDRnakctVAVi3bwcULN3Uxm9bv59KFMNp3asSw0Z0Irl2e9Wv2cO70tdxq1mvbuvcUE2f/Qp8ODdg8bwB+xYvQccg8HsUYPi9OnLtJv/Er+KBRJbbMH0i9d0rRY9RiLt+8D2gT+O6jFhF+P4q5EzqzZd5AXAsV5JNBc3iSlJKbTXstm3afZPR3Gxn06bvsXjKYgBKutO4/y+j4cPTMDbqNXspHTauyZ+kQGtYMosPQBVy8rh0fkpJTOXP5DgM6NWD3ksEsnvQp129H8PGQebnZLJ3XTlb69+9Pnz59AKhbty6XLl3ip59+4tSpU/Tt2zdHKtWxY8eXfhNuSEgIKpWK1atX65XPnDkTDw8P3c9LlixBpVJle1haWupt9+DBA/r27Yu3tzeWlpYUKlSI6tWrM3v2bJ48eZIjbXoTs37ayyfNq9GuWVX8vAozfXgb8lmas2Lznwbj567eT52q/vT5uC6+ni580aMJpf3cmf/zAUB7Es5ZtY9BnRvQKDiIwBKuzB77CQ8exbHtwOncbNprkX7Qkn7QCvF24HBYDEdux/IwIYW1ofdJzcikiofxuxE1GkhISX/hkaH3/PHwOH67HMmVSMNv9Eq0f89xqlYvReVqpXAp7MgHbethbm7GkT/PGYwv4VOUoDIlcCnsgKNTAYJrl6eIqxM3r93Vxdy8fpeKVQIo4VMUBwc7qtUoTRFXZ26FPcitZr22RT8foHXjKrRqWIkSHi5MGNAKK0sz1v161GD8kvWHqFnJj8/a1Ma7WCEGdG5IQAlXlm/8HYCwO5GcunCLcf1aEeRXFK+izozv34rklDS27D2Vm017LXNW7aN9s2q0bVIFX8/CfD3kQ6wszFm19S+D8fPXHqB2ZX8+b18HHw8XhnVrTJCvGwvXHQLA1tqKdd/14r265fAuVogKgZ5MGtiK05fCufMgOjebBrxBspJVsWLFaNGiBUFBQTlRn1dmaWnJyJEjDf5RxRfZ2tpy//59vcetW7d0z9+4cYOyZcuyc+dOJk6cyKlTp/jzzz8ZMmQIW7duZffu3W+7KQalpqUTeimckErP/7q1Wq0muJIvx87eNLjN0bM3Canop1dWu4o/x86GAXDrbhQPo+IJqfQ8xs7aivIBHhw7E5bjbcgJ0g9a0g9aJioV7gWs9JIKDXAl8jEe9lZGt7MwVTO6QQnGNPChSxV3XGwscqG2b096egZ3bj/Ex+/5FL9arcLHryhhN+69ZEstjUbDlUu3iHgYTfESbrpyz+KunDtzjdjYBDQaDVcv3yYyIhq/ksYvJeSl1LR0zl25Q7XyProytVpNtXI+nDofZnCbUxfCqF6+hF5ZjYp+uvjUtHQALMyfr5JQq9WYm5ly3Mi5ltdS09I5fTmcmhX1x4eaFX05fs5wnY+fC6NmRR+9spDK/kbjAeITk1GpVNjZGD/X3pZXWrPy3XffvfIOn826vG1t27Zl8+bNzJ8/n549exqNU6lUuLi4GH2+Z8+emJqacvz4cfLnz68r9/Ly4r333kOj0eRovV9VVGwiGRmZONnb6JU72dtyNczwVHVEVDxODlnjbYiIigfg4dN/s8Y4OzyPURrpBy3pB638FiaYqFUkpKTrlSckp+Nsnc/gNhGJKaw6eZd78SlYmqqpXcKRfsGeTNp9jbjkdIPbKN3jxCQyMzXY2ObXK7exzc/Dh8Y/9SYlpTB6+BzS0zJQq1W0alsXX38P3fMtP6zNmpU7GTN8Lmq1GpVaRet29Slewv1tNeUfiYl7TEZmJo4F9Y9hx4I23LgdYXCbR9EJOBiIj3x62ciraCGKFCrItPnbmDDwA6wszVm87gAPImOJVOh5ER372Mj4YMO1Wy8ZH+xts8VHRBm+bJScksb4Wb/wfr1y2ORXaLIyY8aMV9qZSqXKtWTF1taWL774gnHjxtGhQwe9RONVRUVF6WZUjG3/4h9wzColJYWUlOfXMOPjlXkgC/FfFhadRFj088W3N6NvM6KuN9U97dl+0fAb2v8rCwtzBo/4hJSUNK5evsWmdftxcLSjhE9RAA7uP0XYzft06fE+9va2XL8WzvrVu7Gzs8b3JQtW/5+YmZowa2xHhn+9hnLNRmKiVlOtfAmCK/uRR59d81xaegZdRy5Go4Gvh3yYJ3V4pWTl5k1lTn317NmTb7/9lunTpzNq1CiDMXFxcVhbW+uV1ahRg19//ZVr166h0Wjw9fXVe97R0ZHkZO2dAL169WLKlCkG9z1p0iTGjh2bAy3JzqGANSYm6myLoyKj43F2MPwnDZwdbImMyhqfoIsv9PTfyKgEXByfr+aOiEqglI8bSiT9oCX9oPU4JYOMTA02FvpDl42labbZFmMyNXAnLhnH/OZvo4q5Ir+1FWq1Ktti2oT4x9jaGv/gplarcHLWru1xc3fm4f1odu84SgmfoqSmprHtl0N07vYeAaWKA1DEzYm74ZHs231MkclKQbv8mKjV2RbTPopJyDbL8IyjvQ1RhuJfmG0p5evO1gWDSEhMIjU9A4cC1rToMZNSvsqcYbIvkN/I+JCAs4PhfnB2sCUyOv5v49PSM+jyxWLCH0Sz4YfeeTKrAjmwZuVtWrlyJdbW1rrHoUOH9J63sLBg3LhxTJs2jUePHhnch42NDaGhoXqPBQsWvPR1jx49SmhoKAEBAXozJ1kNHz6cuLg43SM8PPz1G2mEuZkpZfzcOXDssq4sMzOTg8euULGUp8FtKpXy1IsH2HfkEhVLeQBQzNWBQg62ejHxiUmcOB9GxSCPHKt7TpJ+0JJ+0MrQaAiPTcLH6fkbsgrwccqvN3vyMiqgiK0l8Qq+4+nvmJqa4Fa0EFcv39aVZWZquHL5Nh5eRV55P5kaDenp2iQvMyOTjIzMbLPJKrUqzy6H/x1zM1MCfdw4fPKqriwzM5M/T16lrJFb+suW9NCLB/j9xBWD8TbWVjgUsObmnUjOXgmnbvXAnKx+jjE3M6W0rzuHjj+/yy0zM5NDxy9TIdDw+FAh0EMvHuDA0Ut68c8SlZt3Iln3XS/s7V7/CkZO+Ud/yPBta9asGZUrV9b97Orqmi2mffv2TJs2jQkTJujdCfSMWq3G29vb4P69vb1RqVRcvqw/oD/70jsrq5dnkBYWFlhYvL2Fej0/qk3Pscsp61+UcgEezF61j8dJKbRrWgWA7qOXUdjJjtGfvwdAtzYhNOk2kx9W7KH+OwFs2HmC0Iu3mTmiLaC9pNW9bS2mLdqBl7sTxVwdmDhnGy6OdjQOLv3W2vFPST9oST9o7b8WRbvyrtyOTeJ2TBLBxR0wN1Fz5FYMAO3KuxKXlMbWC9pLPA18nQiLecKjxFSszEyoXcKRgvnM+DMsVrfPfGYmFMxnhp2ldkh0ttbOusQnp7/yjE1uC6lTgZ+W/op70UIU9SjMgb0nSE1Jo3JV7RvqiiXbsStgTdPmNQHYteMIRYsVwsGxAOnpGVw8f4PjRy7wQdu6AFhaWVC8hBubNxzAzNwUe3tbrl29w/EjF3ivZUheNfNvdf4gmMGTV1HKx53S/kVZvO4AT5JTafVuJQAGTvwJFydbBndtAkDHljX4qN+PLFi7n1pV/Nm69xTnLofz1cAPdPvcvj8U+wLWFHEuyOUb9xn/w0bqVQ+kRkVfg3VQgu5ta9F7/ApK+7lTLqAYc1fv50lyKm2aaN9De41dTmEnO0b2bAZA1w+Dad7zO2b9tJd61QLYuPsEpy+F882wNoA2Ufl0xELOXL7DimndyMjU6Na5FbTNh7lZ7qYPik5WbGxssLExPIX1jFqtZtKkSbRo0YIePXq81v4dHByoV68eP/zwA717936jdS9vU4v65XkUm8jEudueTs27su67Xrpp/DsPolG/8Cmocmkv5k/oyFeztzJ+1ha83J1YMe0zSno//6TV95O6PElKof/EVcQlJlGldHHWfdcTSwuzXG/fq5J+0JJ+0Dp1Nx5rC1Ma+Ttja2HKnbhk5hy+pbsduaCVmd5MQD5zE9qULYKthSlP0jIIj01m5oGbPEx4PmsaWNhG74vjOlbSTvf/ejGCHZcic6llr6dcBT8eJz7h161/EB//BFc3J7r1bqVbdBsTHa83S5KaksbPq3YTF5uImZkpzi72tO/UiHIVnt8N1uHTpmz95SArFm3nyZNkCtrb0qjZO1SvqdzktUntskTHJTJzyQ4eRcfjX9yVxVM+w/HpZaD7ETGo1c/7oXygJzNGtmf6ol/5ZsE2irk6MXt8J3w9n3+ZXkRUPF/N2kxUTAJODra8X78Cn39cL9fb9jqa1y1HVEwiUxdsf/qlkW6sntED56eLaO8+1O+HSkFezBnbgUnztjFxzha83J1ZOqUL/sW148P9yFh2HNLeBl/7E/2lEBt/7E31cvp3VL1tKo0C5/c6duxIbGwsmzZtMvh8SEgIZcqUYebMmbqymjVrcuzYMQoVKkRYWBig/Z6Vvn37Zps5AXB2dkatVnP9+nWqV69OwYIFGTNmDEFBQajVao4dO8agQYNo164d33zzzSvVOz4+Hjs7Ox5GxWFra3gdgRD/RX03ns/rKihCOXdlfSDKK039Xv1S1f87G0tFzxm8dfHx8bgVKkhc3MvfN/9vemnKlClUq1YtW3l8fDyFC2f/+un79+/j4uJC8eLFOXXqFBMnTmT48OHcuXMHCwsLSpYsyaBBg156W7QQQggh3r43mlk5dOgQc+fO5fr166xbtw5XV1eWL1+Op6cn77zzztuo57+CzKwIYZjMrGjJzIqWzKw8JzMrrzaz8tp3A61fv54GDRpgZWXFqVOndHfLxMXFMXHixDevsRBCCCGEAa+drEyYMIE5c+Ywf/58zMyeL8KrXr06J0+ezNHKCSGEEEK8drJy+fJlatasma3czs6O2NjYnKiTEEIIIYTOaycrLi4uXLuW/c+F//7777rvJxFCCCGEyCmvnax07dqVvn37cuTIEVQqFffu3WPlypUMGjTotb/nRAghhBDi77z2MuRhw4aRmZlJnTp1ePLkCTVr1sTCwoJBgwbRu3fvt1FHIYQQQvyHvXayolKp+OKLLxg8eDDXrl0jMTGRkiVLZvtjgUIIIYQQOeGNb/A2NzenZMmSOVkXIYQQQohsXjtZqVWrVra/yvmivXv3/qMKCSGEEEK86LWTlTJlyuj9nJaWRmhoKOfOnaNDhw45VS8hhBBCCOANkpUZM2YYLB8zZgyJiYn/uEJCCCGEEC967VuXjWnfvj2LFi3Kqd0JIYQQQgA5mKz8+eefWFpa5tTuhBBCCCGAN7gM1KJFC72fNRoN9+/f5/jx44waNSrHKiaEEEIIAW+QrNjZ2en9rFar8fX1Zdy4cdSvXz/HKiaEEEIIAa+ZrGRkZNCpUydKlSpFwYIF31adhBBCCCF0XmvNiomJCfXr15e/riyEEEKIXPPaC2wDAwO5cePG26iLEEIIIUQ2r52sTJgwgUGDBrF161bu379PfHy83kMIIYQQIie98pqVcePGMXDgQBo1agRAs2bN9L52X6PRoFKpyMjIyPlaCiGEEOI/65WTlbFjx9K9e3f27dv3NusjhBBCCKHnlZMVjUYDQHBw8FurjBBCCCFEVq+1ZuVlf21ZCCGEEOJteK3vWfHx8fnbhCU6OvofVUgIIYQQ4kWvlayMHTs22zfYCiGEEEK8TSrNs8Uof0OtVvPgwQOcnZ3fdp3+teLj47Gzs+NhVBy2trZ5XR0hFONJSnpeV0ERfHuvz+sqKMKRKc3yugqK4WRjkddVyFPx8fG4FSpIXNzL3zdfec2KrFcRQgghRF545WTlFSdghBBCCCFy1CuvWcnMzHyb9RBCCCGEMOi1v25fCCGEECI3SbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFokqwIIYQQQtEkWRFCCCGEokmyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0SVaEEEIIoWiSrAghhBBC0UzzugLi5eavPcD3K/YQERVPYAlXpgz+gPIBHkbjN+0+ycQ527h9PwovdyfG9G5O/eoBuuc1Gg2T5m5j2abDxCUmUTnIi2+GtaZ4UedcaM2bk37Qkn7QWrL+ELNX7SUyOoGSxYswvn9LypYsZjR+y95Qvl6wnTsPovF0c2JEj6bUqVpS93y/r1by86/H9LYJqeTHyund31obckKHEG+61ffDyc6Si3di+XLVSULDoo3Gf1rHh4+Di+Nqn4/oxFS2nwxn8oYzpKRnvvE+leCnzX+w+OcDPIpOwNerMCN6NSfIr6jB2GthD/h+2W9cuHqXew9jGNq9GZ+0qKEXs3rLYdZs/ZO7D2MA8C5WiB7t6lGjkt9bb8s/sXDdQWat3EtEdDwB3q5MHNCKcgHGz4vNe04xed42wh9E4+XmxKhezahbTTs+pKVnMGnuVvYcvsCte1HYWFtSs4Ivo3o2w8XJLreapCMzKwq2YecJRs7cyNAuDdm/fCiBJVxp2ftHIqMTDMYfOX2DLiOX0P69qhxYMYzGwaVpP2geF67d08V8u2w3c9ccYPrwNuxaPIh8Vua07P0jySlpudWs1yb9oCX9oPXLnpOM/WETAzq9y46Fgyjp7Uq7AXN4FGO4H46dvUmvscto26QKvy0aRIMapfh0+EIu3bivF1ersh+nfhmne/w45pPcaM4ba1rBnVEflGHm1vM0mrCTC+GxLO8bjIONhcH45pWKMqxFEDO3nqfW6F8ZvOwoTSsUZej7QW+8TyX4dX8oU+duoWf7evw8qx++XkXoNmIBUTGJBuOTUtJwd3Ggf+dGONrbGIwp5FiA/p824ucf+7L2h75ULuPN52OWcC3swdtsyj+yafdJRn+3kUGfvsvuJYMJKOFK6/6zjI4PR8/coNvopXzUtCp7lg6hYc0gOgxdwMXr2vEhKTmVM5fvMKBTA3YvGcziSZ9y/XYEHw+Zl5vN0lFsstKxY0eaN29u9PmQkBBUKhUqlQpLS0tKlizJrFmz9GKSkpIYPXo0Pj4+WFhY4OjoyAcffMD58+f14p48ecLw4cMpXrw4lpaWODk5ERwczC+//PI2mvbKZv20l0+aV6Nds6r4eRVm+vA25LM0Z8XmPw3Gz129nzpV/enzcV18PV34okcTSvu5M//nA4D2U/ScVfsY1LkBjYKDCCzhyuyxn/DgURzbDpzOzaa9FukHLekHrfmr9/NR06q0blwZH08XJg/+ACtLc1ZvPWIwfuHPBwip7EePj2pTwsOFIV0bEejjxuL1h/TizM1NcXaw1T0K2ObLjea8sa71fFn1+w3WHr7J1fvxDF95nOTUdFpX9zQYX764I8evPWLT0dvciXrCwQsP+eXobUp72r/xPpVg6fqDtGpYmfcbVMS7WCFG922BpYUZG347ajC+lK87gz5rQqNaZTA3M3xxoVbVktSs5E8xVyc83Jzo26kh+azMOX3x9ttsyj8yZ9U+2jerRtsmVfD1LMzXQz7EysKcVVv/Mhg/f+0Balf25/P2dfDxcGFYt8YE+bqxcJ32vLC1tmLdd714r245vIsVokKgJ5MGtuL0pXDuPMj9mTbFJiuvomvXrty/f58LFy7w4Ycf0qtXL1atWgVASkoKdevWZdGiRUyYMIErV66wfft20tPTqVy5Mn/99fwX2L17dzZs2MD333/PpUuX2LFjB61atSIqKiqvmkZqWjqhl8IJqeSrK1Or1QRX8uXY2ZsGtzl69iYhFfWnKWtX8efY2TAAbt2N4mFUPCEvTGXaWVtRPsCDY2fCcrwNOUH6QUv6QSs1LZ0zV+5Qo4KPrkytVvNOBR9OnA8zuM2Jc2F68QAhlf04cU4//s9T1whqMpIabb9i2LS1RMc9zunq5xgzEzWlihbk94sPdWUaDRy6+JDyXo4Gtzlx/RGlihWkjIc2OSnqmJ9apQqz7+z9N95nXktNS+fC1btULVtCV6ZWq6lStgSnL97KkdfIyMhk+75QkpJTKf2SS415KTUtndOXw6lZUX98qFnRl+PnDI8Px8+FUbNi1vPC32g8QHxiMiqVCjsbq5yp+Gv4V69ZyZcvHy4uLgCMGTOGn376ic2bN9O2bVtmzpzJn3/+yalTpyhdujQAxYoVY/369VSuXJlPP/2Uc+fOoVKp2Lx5M99++y2NGjUCwMPDg/Lly+dZuwCiYhPJyMjEKcs0pZO9LVfDHhrcJiIqHieHrPE2RETFA/Dw6b9ZY5wdnscojfSDlvSDVnTcYzIyMrNN3zvZ23D9luF+iIxOwKmgfrxjQRsio5+3sVZlfxoFl8a9sD237j5i8rxtfDxoLpvn9MPERHmf6eytzTE1URMZn6xX/ighGe/Ctga32XT0NgWtLVg/pDYqlQozEzXL91/jh18vvvE+81ps/GMyMjNxKGitV+5Q0Jqb4RH/aN9Xbt7no74/kJqaTj4rc74b3QHvYoX+0T7flujYx0bGBxuuGTkvIqLicbK3zRYfEWX4slFyShrjZ/3C+/XKYZM/95MV5Z2F/4CVlRWpqakA/PTTT9SrV0+XqDyjVqvp378/Fy5c4PRp7VS3i4sL27dvJyHB8C/JmJSUFOLj4/UeQoh/n/fqlqP+O4H4Fy/CuzWDWDqlK6EXb3P41LW8rlqOqeLjxOcN/fnip5M0mrCTrrN+p3ZQYfo2Lvn3G/8Hebg5sX52f1Z915vWTaoy4us1Rt/4/9+lpWfQdeRiNBr4esiHeVKH/4tkJSMjgxUrVnDmzBlq164NwJUrV/D39zcY/6z8ypUrAMybN4/Dhw/j4OBAxYoV6d+/P3/88cffvu6kSZOws7PTPdzd3XOoReBQwBoTE3W2xVGR0fE4Oxj+lOPsYEtkVNb4BF18oaf/Zo2JiEowus+8Jv2gJf2gZW+XHxMTNY+y9UMCTkbq7GRvQ2SWxbePYhKyfap8UTFXR+wL5CfsTuQ/r/RbEJ2YSnpGJk62lnrljjaWRMYlG9xm8Hul2PDXLVb/foNLd+PYEXqXKRvP0quhPyrVm+0zrxWwzY+JWp1tMW1UTKLRxbOvytzMlGKujgT4uNH/00b4ehVmxcZDf79hHrAvkN/I+JCAs4PhfnB2sNWbXTQWn5aeQZcvFhP+IJqfv+uVJ7Mq8C9IVlauXIm1tbXucejQ84Nl1qxZWFtbY2VlRdeuXenfvz89evTQPa/RaF7pNWrWrMmNGzfYs2cPrVq14vz589SoUYPx48e/dLvhw4cTFxene4SHh79ZIw0wNzOljJ87B45d1pVlZmZy8NgVKpYyvNitUilPvXiAfUcuUbGUBwDFXB0o5GCrFxOfmMSJ82FUDPLIsbrnJOkHLekHLXMzU4J83Pj9xFVdWWZmJr+fuGL0Fu7ygR78fvyqXtnBY5cpH2g4HuBeRCwxcU8o5Jj7t2i+irSMTM7ejqG63/PLEioVvONfiBM3HhncxtLchMwsY2JmpvZnFao32mdeMzczpWQJV/4KfT4DlpmZyZHQa5T2z9n1JZmZGlLT0nN0nznF3MyU0r7uHDp+RVeWmZnJoeOXqRBoeHyoEOihFw9w4OglvfhnicrNO5Gs+64X9nb5304DXoHik5VmzZoRGhqqe1SoUEH3XLt27QgNDeXmzZs8fvyY6dOno1Zrm+Tj48PFixcN7vNZuY/P88VFZmZm1KhRg6FDh7Jz507GjRvH+PHjdZeVDLGwsMDW1lbvkZN6flSbZZsOs2rrX1y++YABk9fwOCmFdk2rANB99DLG/vD8jqVubULY8+cFflixhythD5g8bxuhF2/T9YNgAFQqFd3b1mLaoh1sP3CG89fu0mPMclwc7WgcXNpgHZRA+kFL+kGra5sQftryJ2t/PcrVsAcMm/YzSUmptG5cGYA+41cwac4WXfynHwSz/8hF5qzax7VbD/lm4a+cuRROp5ba79Z4/CSF8T/+wolzYYTfj+LQ8St0HrYAD1dHghX8vRrzd12mbQ0vWlX1wNvFhontKmBlbsraP7QLJGd0qszQ90vp4nefucfHwd40q+iOu0N+avgXYtB7gew+fU+XxPzdPpWoQ8uarNt+hE07j3P99kPGfbeBpORU3m9QEYDhU1cxY+F2XXxqWjoXr9/l4vW7pKVlEPEojovX73Lr7vOEbMbC7Rw/c4O7D6K5cvM+MxZu59iZGzSpXS7X2/equretxYrNh1m97QhXwh4weOpaniSn0qaJ9rzoNXY5E2Zt1sV3/TCYvX9dZNZPe7ka9pCpC7Zz+lI4n7bSnhdp6Rl8OmIhpy/dZtaYT8jI1PAwKp6HUfF5krQpfoGtjY0NNjaGp7Hs7Ozw9vY2+FybNm344osvOH36tN66lczMTGbMmEHJkiWzrWd5UcmSJUlPTyc5ORlzc/N/1og31KJ+eR7FJjJx7jYiohIo5ePKuu966abo7zyIRq1S6eIrl/Zi/oSOfDV7K+NnbcHL3YkV0z6jpHcRXUzfT+ryJCmF/hNXEZeYRJXSxVn3XU8sLcxyvX2vSvpBS/pB67065YiOfcy0Bb8S+fTLr1Z80023uPDewxjU6uf9ULGUJz+M/oSp87cxZd5WPN2cWDjpU/y8CgOgNlFx8fo9fv71GPGJSRRytCW4oh+DuzbCwly5Q+SW4+HY21gwsFkgTraWXLgTy8ffHeBRQgoArvb59GaXv9t2AY1GeznIpYAVUYkp7D59j6mbzr7yPpWoYUgZouMe88Oy33gUk4CfVxHmftUFx6eLqu9HxKJ64byIjIqnVY+Zup8XrzvA4nUHqBjkxZJp2pn56NhEhn+9msjoeGzyWeLjVZh5E7tQrbz+3TNK0rxuOaJiEpm6YPvTL410Y/WMHjg/vdx5N8t5USnIizljOzBp3jYmztmCl7szS6d0wb+4dny4HxnLjkPnAKj9yRS919r4Y2+qlytBblJpXvVaSS7r2LEjsbGxbNq0yeDzISEhlClThpkzZxp8Pjk5mZCQEO7du8c333xD5cqVefjwIRMnTmTXrl3s3r2bKlWq6PbVtm1bKlSogIODAxcuXGDAgAG4urqyZ8+eV65zfHw8dnZ2PIyKy/FZFiH+zZ6kKHP6PLf59l6f11VQhCNTmuV1FRTDScFfuJcb4uPjcStUkLi4l79vKvdjwz9kaWnJ3r17mThxIiNGjODWrVvY2NhQq1Yt/vrrLwIDA3WxDRo0YOnSpYwYMYInT55QpEgRmjRpwpdffpmHLRBCCCEEKHhm5d9IZlaEMExmVrRkZkVLZlaek5mVV5tZUfwCWyGEEEL8t0myIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0SVaEEEIIoWiSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFokqwIIYQQQtEkWRFCCCGEokmyIoQQQghFM83rCgjx/yw9IzOvq6AIJmpVXldBEU5Oa57XVVCEoL7r8roKinF7ftu8rsK/gsysCCGEEELRJFkRQgghhKJJsiKEEEIIRZNkRQghhBCKJsmKEEIIIRRNkhUhhBBCKJokK0IIIYRQNElWhBBCCKFokqwIIYQQQtEkWRFCCCGEokmyIoQQQghFk2RFCCGEEIomyYoQQgghFE2SFSGEEEIomiQrQgghhFA0SVaEEEIIoWiSrAghhBBC0SRZEUIIIYSiSbIihBBCCEWTZEUIIYQQiibJihBCCCEUTZIVIYQQQiiaJCtCCCGEUDRJVoQQQgihaJKsCCGEEELRJFkRQgghhKKZ5nUFxMvNX3uA71fsISIqnsASrkwZ/AHlAzyMxm/afZKJc7Zx+34UXu5OjOndnPrVA3TPazQaJs3dxrJNh4lLTKJykBffDGtN8aLOudCaNyf9oLVw3UF+XLGXiOh4ArxdmTSwFeUCihmN/2XPKSbP20b4/Wi83J0Y1asZ9app+yEtPYNJc7ay+88L3LobhY21JcEVfRnVsxkuTna51aQ3smj9IWat3EtkdDwlvV35akBLypU03g+b955i6rzthD+IxtPNiZE9m1K32vPj4esFv/LL7pPcjYjF3MyEIF93hndrTLmXHGNKsGLT7yxcu5/I6AT8ihdhVO/3Ke1X1GDs1bAHfLtkB+ev3OHuwxhG9HyPji1r/qN9KkXH2j70bOiPk50VF27H8MXK44TejDIa37WeL5/U8sHVIR/RiSlsO3abietCSUnPBKB34wAalXfH28WW5LQMjl+LZMLPp7j+ICG3mvRGFq47yKyVz8eHiQNePj5sfjY+PIjGy007Prx4XkxdsJ1Nu05yLyIWs6fnxYjuTV469r4tMrOiYBt2nmDkzI0M7dKQ/cuHEljClZa9fyQy2vAJc+T0DbqMXEL796pyYMUwGgeXpv2geVy4dk8X8+2y3cxdc4Dpw9uwa/Eg8lmZ07L3jySnpOVWs16b9IPWxl0n+fLbjQzq8i57lg4moIQrH/abZbQfjp65Qbcvl9KuaVX2Lh1Cw5pBdBiygIvXtf2QlJzKmct3GNCpAXuWDmbJ5E+5diuC9oPn5WazXtum3ScZ891GBnZuwM7FgwnwLkLb/rON9sOxszfpMXoZbZtWYdeSwTSsWYpOwxbq+gGgeFEnJg5sxf7lQ/lldl/cC9vTut9sHsUk5lazXtu2faeYNGczn39Sn01z+uNXvAifDp1HVIzhfkhKTsW9sAMDuzTGyd4mR/apBM0qFWNMm3J888tZGozZzoXwGFYNrIWDjYXB+PereDDig7JM33yWmiO2MnDRXzSrVIzhrcroYqr6OrN4zxUaT/iN1tP2YGqiZvXAOliZm+RSq17fpt0nGf3dRgZ9+i67l2jHh9b9/2Z8GL2Uj5pWZc+z8WHoAv3zwt2ZSQM/YP+KYWyZ04+ihe35sO8sHuXB8aDIZKVjx440b97c6PMhISGoVCpWr16tVz5z5kw8PDx0Py9ZsgSVSpXtYWlpqbevfv36ZXuNJUuWUKBAgX/Ykn9m1k97+aR5Ndo1q4qfV2GmD29DPktzVmz+02D83NX7qVPVnz4f18XX04UvejShtJ87838+AGhnE+as2segzg1oFBxEYAlXZo/9hAeP4th24HRuNu21SD9ozVm1j/bvVeOjJlXw9SzMtKEfYmVpzk9b/zIYP2/NAWpX8efz9nXw8XRheLfGBPm6sXDdIQBsra1Y930vmtcth3exQlQI9GTyoFacvhTOnQfRudm01zJ39X7aNatG2yZV8PV0YeqQD7GyMGe1kX6Yv/YAtSr70atdHXw8XBj6WWNK+bqxeP0hXUyL+hWoWdGXYq6O+HkVZmyf90l4nMzF63dzq1mvbfG6g3zYqAot362Et4cL4/q1xNLCjHU7jhqMD/IrytBuTWlSuyzmZoYn1V93n0rQrb4fKw9eY83vN7hyL54hy46SlJpB2xrFDcZX8Hbk2NVINv4Vxp2oxxw4/4BNR25R1tNBF/PR9H2s/eMGV+7FcSE8ln4L/8TNMT+lPRwM7lMJ5qzaR3vdeVGYr5+eF6tecl7Urvx0fPBwYViW8QGgZYMKBFfyxePpeTGur/a8ePGDX25RZLLyKiwtLRk5ciRpaS//JGxra8v9+/f1Hrdu3cqlWr651LR0Qi+FE1LJV1emVqsJruTLsbM3DW5z9OxNQir66ZXVruLPsbNhANy6G8XDqHhCKj2PsbO2onyAB8fOhOV4G3KC9INWalo6py+HE1xRvx9qVvTluJF+OH4ujJoVffTKalXxNxoPEJ+YjEqlws7GKmcqnsNS09I5czmcmhWet0utVlOjog/Hz4UZ3ObEuZvUfKHfAEIq+xmNT01LZ/kvh7G1tqKkt2tOVT1Hpaalc/7KHaqVK6ErU6vVVCvnQ+iFNxvf3sY+3zYzEzVBHvYcOv9AV6bRwKELDyjv7Whwm+PXHhHkYU+Zp8lJUSdr6gQVYc8Z42/ANlZmAMQ8TsnB2uecZ+NDTUPjw7lXHx9CKvsbjU9NS2fZJu15EVAi98+Lf+2albZt27J582bmz59Pz549jcapVCpcXFxysWY5Iyo2kYyMzGzTtU72tlwNe2hwm4ioeJwcssbbEBEVD8DDp/9mjXF2eB6jNNIPWtGxjw32g3NBG669pB+c7W31ypwK2hARZXgKNzkljXE//kKLeuWwya/MZMVYPzjZ23DtVoTBbSKiEnAqmCW+YPbf9c4/ztH9y6UkJadRyMGWNTN74FDAOmcbkENi4h6TkZmJY5Z2ORa05ka44X7Ii32+bfY2FpiaqImMT9Yrj4xLxtvF1uA2G/8Kw97agl9G1EOFCjNTNUv3XuG7becNxqtUMK5tBY5eieDy3bgcb0NOePl58ZJxMuv4YJ99fNj5+zk++3KJ7rz4+dueeXJe/GtnVmxtbfniiy8YN24cjx8/zpM6pKSkEB8fr/cQ4t8oLT2DLl8sRqOBr4d+mNfVyRPVy5Vgz9IhbJ3bj1pV/Phs1BKj1/vFv1dVX2f6NAlg+PJj1B/7K52/P0Dd0q70bxpoMH5S+4r4udnRfc7vuVxTZahevgR7lw5l27x+1K7iT9eRi/PkvPjXJisAPXv2xNLSkunTpxuNiYuLw9raWu/RsGHDHHn9SZMmYWdnp3u4u7vnyH4BHApYY2KiznZQREbH4+xg+BODs4MtkVFZ4xN08YWe/ps1JiIqweg+85r0g5Z9gfwG+yEiJgFnB8OLJZ0dbImI1k+gIw3EP0tU7jyIZt33vRQ7qwLG+yEyOgFnI4tGnR1siMyyIFDbD/q/6/xWFni6OVE+0IMZIz7C1ERt9Hp/Xitolx8TtTrbQsdHMYlGF8/mxT7ftuiEFNIzMnGytdQrd7KzJCI+yeA2Q1uUZt3hm/x08DqX7sTy68k7TFofSu/GAahU+rFfta9A3TKutJyym/sxhvenBC89L14yPkRmHR8MxOe3ssDL3YkKgZ7M/OIjTExM+GmL4fWCb5Oik5WVK1fqJRmHDh3Se97CwoJx48Yxbdo0Hj16ZHAfNjY2hIaG6j0WLFiQI/UbPnw4cXFxukd4eHiO7BfA3MyUMn7uHDh2WVeWmZnJwWNXqFjK0+A2lUp56sUD7DtyiYqlPAAo5upAIQdbvZj4xCRO/K+9Ow+Lqnz7AP6dYRlQFmUXRARGBEzBFdEUMBEt992w5E0tBZOwDM3MHbRcyR9qWmC5UW6pWKKWSy5pKmiIKCJqBi4gIIpsc94/JkZHFkFH5mTfz3XN5TXn3Oec57k9c+bmOc/MJGegfaumGmu7JjEPSvp6uvBobo9DJy+qlikUChw+mYp2VeSh3StNcfixeAA4eOKCWnx5oZJ+/TY2fxkCM9P6L6YDGqKvp4tWze1x+JR6Hn774yLavdK00m3avuKIw3+o5+HQidQq4x/tV0BRcenzNvmF0NfTRQuXxjh25pJqmUKhwLEzl+BZzUe463qfL1pJmQJnM3LwqvujW/0SCfCqmw1OpVX+nmCorwOFIKgtK1Mon0vwqFqZN7IderWxx5DP9+P6He2M3tdU+fXh8fNcoVDg8B+paPdKNdeHPyq5PlQRr9qvoEBRSd2/LkQ9Z6Vv377w8vJSPbezqzipZ+TIkVi4cCHmzp2r9kmgclKpFHK5vMpjmJiYIC+v4n3I3NxcmJpW/10TMpkMMlnlH4/ThOA3uyF41ndo7dYEbVo0xYqNv+J+YREC+3QEAIyb8S0aWZpixoR+AID3hvui93tLsXzdfvR4tQW2JpxCYso1LP1kBADl/J1xI/yw8Juf4WRvCQc7c0SsjIeNhSne8PF4Yf14XsyD0rgRfnh/zjp4utmjjbsDVsUdwIOHxRjxhvI1EjLrO9hYmmJ6cF8AwLvDfNBvfBSi1/8C/84tsG3vKSSmXMeiKcMBKAuVd6Z+jbOpf2H9ovdQphBU83kamtSr8hMj2vbecF+Ezl0PD9cmaO3eBKvjDuLBw2IM763Mw4TZ69DI0hTTxvcBAIwd6oMBwVFYseEXdO/UAtv3nUbShev4InwYAOB+YRGWrU1AwKstYWVugpy8+4jZchhZd/LQp5untrr5VP83uCvCF2zCKy72aOXaBGu3HELhw2IMCugAAJg8fwOsLUzx0Zg3ACgnSJbPXygpLcPNO3k4n3YD9Q1lcLCzqNE+xWhVwgUsG+ONpIxsJKZnY2wPV9ST6WDTb+kAgKgx3sjKLUTE5kQAQELiDbwX4IY/r97F6fQ7cLQyxscDPJCQdENVxES+1R4DOjbF/0UdREFhiWrk5l5hCR6WlGmln09Tfn3wcLVHmxYOWLXpgNrrImTWd2hkaYpP/7k+jB3qg/7BUYje8Av8O7XAtn2nkHTh0fXhfmERlsYmIKDLK7A2N0VOXgG+2XwYWbfz0Ldb6zrvnzivRv8wNjaGsXH1w49SqRSRkZEYOHAgxo8fX+tjNG/eHAkJCRWWnz59Gi4uLpVsUXcG9miLO7kFiFgVj1vZ99DSxQ6bo0JUw9d/ZeVA+ti4pZeHE1bPDcK8FbswJ3onnOwtsW7hu3CX26piQt/ujgeFRQiL2Ii8gkJ09HDG5qhgGMj06rx/NcU8KA3wb4Ps3AIsWL37ny/Ha4y4JeMfy8NdSB7LQ4dWTlg5exQiV8Vj3sqdcLK3wtrPx8DNWZmHzFu5+PnwnwAAv7cWqB1r+//eR+e2zSBG/bsr8/D56t24nZOPFs0aY+PicarJgjdu3oVU+igP7Vs6InrW21jw1W5ErtoFx8aWiJk/WpUHHakUaVdv4fvd3yAnrwANTevD07UJtkdPhKtTI630sSbe8GuNnLz7iIrdg9t38+HmbIev54+FxT+3bDJv5aq9Lm5l56P/e49umX/9/QF8/f0BdPBwxrrFwTXapxjtOHEV5sYyfNzfA5amBki+dhdvLv4Vd/6ZdGtnXl9tJGXpzj8hQHk7yKahIXLuFSEh8Qbmb0lUxQR1U177t07xVztW6Jpj+P5I+gvv07Po370Nsu8W4PM1j64Pm5aMV02yf/J10aGVE1bOGoXIr+IRUX59WDBG7XVx6epNxO0+oXpdtHZrgh0rQrXyupAIwhPjYSIQFBSE3NxcbN++vdL1vr6+8PT0xNKlS1XLunbtipMnT8La2hoZGRkAlN+VEhoaitTU1Ar7sLKyglQqRXp6Olq0aIGxY8dizJgxkMlkiI+PR3h4OHbu3ImePXvWuN35+fkwNTXFzew8mJiIc+4D1a3SMoW2myAK5cPs/3X5heK8rVTXWoVu1nYTROPa6hHaboJW5efno7F1Q+TlVf++KeqRldpYsGABOnXqVGF5fn4+GjWqWAVmZmbCxsYGTk5OOHToEKZNm4bu3bujuLgYrq6u+OGHH2pVqBAREdGLIcqRlX8rjqzQkziyosSRFSWOrChxZOURjqzUbGRF1J8GIiIiImKxQkRERKLGYoWIiIhEjcUKERERiRqLFSIiIhI1FitEREQkaixWiIiISNRYrBAREZGosVghIiIiUWOxQkRERKLGYoWIiIhEjcUKERERiRqLFSIiIhI1FitEREQkaixWiIiISNRYrBAREZGosVghIiIiUWOxQkRERKLGYoWIiIhEjcUKERERiRqLFSIiIhI1FitEREQkaixWiIiISNRYrBAREZGosVghIiIiUWOxQkRERKKmq+0GEL3MdHX49wAA6OpouwXiYKnHRABAZkygtpsgGg3bT9B2E7RKKCuuURyvpERERCRqLFaIiIhI1FisEBERkaixWCEiIiJRY7FCREREosZihYiIiESNxQoRERGJGosVIiIiEjUWK0RERCRqLFaIiIhI1FisEBERkaixWCEiIiJRY7FCREREosZihYiIiESNxQoRERGJGosVIiIiEjUWK0RERCRqLFaIiIhI1FisEBERkaixWCEiIiJRY7FCREREosZihYiIiESNxQoRERGJGosVIiIiEjUWK0RERCRqLFaIiIhI1FisiNzq7w+iVd/PYNP5A3QP+gKnkjOqjd++7zQ6DJ4Dm84foNPweUg4kqy2XhAERKzcBdeen6DRq2HoH/wlLl+79QJ7oBnMgxLzoMQ8KDEPSsyD0pghXZH04yxk/rYEe2M+Qht3hypjdXWkmDymJ05vm4HM35bg8PopeM3bTS3GqJ4MEZMG4eyO2fj78GLs+XoSWrs3edHdqBSLFRHbmnAKny7dhvAxvXDgu3C80swOg97/H27n3Ks0/vekdIz5NBYj+3nj4LopeMPHAyM/+grn0/5WxSz7dh9WxR3E4qnDsTfmI9Qz1Meg9/+Hh0UlddWtWmMelJgHJeZBiXlQYh6UBvi3wdwPBmDBmp/g+9YC/HnpBrZ8GQKLhkaVxn86vg+CBryK8C9+QMdhcxGz9Td89/lYtHRprIpZ9umb8PVyxbgZa9F5RAR+OX4B2//3PhpZmtZVt1RYrPzj+vXreOedd2Brawt9fX04ODggNDQU2dnZWmtT9IZf8Hb/Tgjs6w1Xp0ZYPHU46hnoY92OY5XGr9p0AK95u2HiW93R3NEG08b3hoerPVb/cBCA8q+FlRt/xUfvBOB1n1Z4pZkdVsx6G1l38hB/MKkuu1YrzIMS86DEPCgxD0rMg1Lwm93w7faj2LDzOFKvZGFS5CY8eFiMkX29K40f+noHLIlNwN6j53H1Rja+2fIb9h49jwkjuwEADGR66OvniZlR23H0zGVc+esOFqzejfTrt/HOoC512TUALFYAAOnp6WjXrh0uXbqEjRs3Ii0tDStXrsT+/fvh7e2NnJycOm9TcUkpEi9ch2+H5qplUqkUPh2a4+S5K5Vuc+LcFfi2d1Vb1q2jG06eywAAXL2RjZvZ+fDt8CjG1MgQbVs0xcmzGRrvgyYwD0rMgxLzoMQ8KDEPSnq6OvB0tceBE6mqZYIg4OCJVLRv6VjpNjI93QojRQ+LitHRwxmA8jaRrq4OHhY/GVOCjp7OGu7B07FYARASEgJ9fX0kJCTAx8cHTZo0Qa9evbBv3z7cuHED06ZNq/M2ZecWoKxMAUszY7XllmYmuJWdX+k2t7LzYWn+ZLyxKv7mP/8+GWNlblzlPrWNeVBiHpSYByXmQYl5UDJvYARdXZ0Kt75u5+TDytyk0m1+OZ6C4MBucLK3hEQigW8HV/T284S1hTK+4EERTpxNx+TRvWBjYQqpVIKhvdqjfUtHVUxd+s8XKzk5OdizZw+Cg4NhaGiots7GxgaBgYGIi4uDIAgVti0qKkJ+fr7ag4iISOymLNqM9Gu3cOKH6bh1dCk+/3gINuw8DoXi0Xvde599C4kESPlpHm4eWYp3h/lgS8IfajF15T9frFy6dAmCIMDNza3S9W5ubrh79y5u375dYV1kZCRMTU1VD3t7e421y7yBEXR0pLWqlK3MTXA7+8n4e6p463/+fTLmVva9KvepbcyDEvOgxDwoMQ9KzINSdm4BSkvLajXClJ1bgJGTV8Ou6yS06vsZOgyeg/sPipDx96N5mhk37qD3e8tg12USXuk9Hd2DFkJXVwdXb9x5of2pzH++WClX2cjJ00ydOhV5eXmqx/Xr1zXWHn09XXi62uPgyUf3IBUKBQ6dvFjlPcgOLR3V4gHg198voH3LpgAABztzWJubqMXkFxTiVHIG2rdqqrG2axLzoMQ8KDEPSsyDEvOgVFJahsQL1+HT/tHcHYlEgq7tXaqcu1OuqLgUmbfzoKsjRZ9unvjp4NkKMQ8eFuNmdj5MjQ3xWkc37D50TuN9eJr/fLEil8shkUiQkpJS6fqUlBQ0bNgQlpaWFdbJZDKYmJioPTSpfHb3xl3/zO6eH4f7hUUI7NMRADBuxreYtfxHVfx7w32x/9h5LF+3HxczsjD/q3gkplzD2CE+AJQn77gRflj4zc/YffAsktNuYPzM72BjYYo3fDw02nZNYh6UmAcl5kGJeVBiHpTKPxU1/A0vuDS1xuIpw1DfUIb1O48DAFbMfAufhfRVxbdt4YDefh5wsDOHt6czNn8ZAqlUgmXf7lPFdOvohte83dDE1hy+HVyxc2UoLmbcxPoqPmn1IunW+RFFxtzcHP7+/oiOjkZYWJjavJWsrCysX78eb7/9NiQSSZ23bWCPtriTW4CIVfG4lX0PLV3ssDkqRDUU+VdWDqSPtcvLwwmr5wZh3opdmBO9E072lli38F24y21VMaFvd8eDwiKERWxEXkEhOno4Y3NUMAxkenXev5piHpSYByXmQYl5UGIelLbtPQ2LBkb45L03YGVujHMXb2DwxEffN9PYxgyKx+4gyGR6mDauN5raWeB+YRH2HknGuM++RX5BoSrGxMgAn4X0ha1VA9zNf4CdvyRibvROlJYp6rx/EuFZ7n+8ZC5duoROnTrBzc0Nc+fOhaOjI5KTkzF58mQUFRXh+PHjMDMze+p+8vPzYWpqipvZeRofZSEiopdPw/YTtN0ErRLKilF0bjXy8qp/3/zP3wYCgGbNmuGPP/6Ak5MThg4dCmdnZ7z77rvw8/PDsWPHalSoEBER0Yvxn78NVM7BwQGxsbHabgYRERE9gSMrREREJGosVoiIiEjUWKwQERGRqLFYISIiIlFjsUJERESixmKFiIiIRI3FChEREYkaixUiIiISNRYrREREJGosVoiIiEjUWKwQERGRqLFYISIiIlFjsUJERESixmKFiIiIRI3FChEREYkaixUiIiISNRYrREREJGosVoiIiEjUWKwQERGRqLFYISIiIlFjsUJERESixmKFiIiIRI3FChEREYkaixUiIiISNRYrREREJGq62m7Ay0QQBADAvfx8LbeEiIj+DYSyYm03QavK+1/+/lkVFisadO/ePQCA3NFeyy0hIiL697h37x5MTU2rXC8RnlbOUI0pFAr8/fffMDY2hkQi0Uob8vPzYW9vj+vXr8PExEQrbRAD5kGJeVBiHpSYByXmQUkMeRAEAffu3YOtrS2k0qpnpnBkRYOkUikaN26s7WYAAExMTP7TL8JyzIMS86DEPCgxD0rMg5K281DdiEo5TrAlIiIiUWOxQkRERKLGYuUlI5PJMGPGDMhkMm03RauYByXmQYl5UGIelJgHpX9THjjBloiIiESNIytEREQkaixWiIiISNRYrBAREZGosVghIiIiUWOxIgJBQUGQSCSqh7m5OXr27ImzZ89WuU1GRkaFbXr06IEzZ86oxSUnJ2Po0KGwtLSETCaDi4sLPvvsMzx48EAtLikpCX379oWVlRUMDAzQtGlTDBs2DLdu3XohfX7S8+TAyspK9VMH5Tw9PTFz5kzVc19fX7X9lz/GjRuntq/ExMQKx/H19cUHH3ygiW4+lbbzUO7XX39F7969YWlpCQMDAzg7O2PYsGE4dOiQRvtbE0FBQejfv3+V68v7tGnTJrXlS5cuRdOmTVXPY2NjK+27gYGB2nZZWVkIDQ2FXC6HgYEBrK2t0blzZ6xYsaLC66au1TQX5f1yd3dHdHS0WkxhYSFmzJgBFxcXyGQyWFhYYMiQIUhOTlaLe/DgAaZOnQpnZ2cYGBjA0tISPj4++PHHH19E12qsLs+Hql77sbGxaNCgwXP2RHuuX7+Od955B7a2ttDX14eDgwNCQ0ORnZ2t7aZVicWKSPTs2ROZmZnIzMzE/v37oauri969ez91u3379iEzMxN79uxBQUEBevXqhdzcXADA8ePH4eXlheLiYsTHx+PixYuYN28eYmNj4e/vj+Ji5Q9I3b59G6+99hrMzMywZ88epKSkICYmBra2trh///6L7LaaZ83BvXv3sHDhwqfGjR07VrX/8sfnn3+uiaZrlLbzEB0djddeew3m5uaIi4tDamoqtm3bhk6dOiEsLOy5+vaiGBgY4NNPP0VJSUm1cSYmJhX6fvXqVdX69PR0tG7dGgkJCYiIiMCZM2dw7NgxfPzxx9i1axf27dv3orvy3Mr/f8+fP4+hQ4ciJCQEGzduBAAUFRWhe/fu+OabbzB37lxcvHgRu3fvRmlpKby8vHD8+HHVfsaNG4etW7fiyy+/xIULF/Dzzz9j8ODBon5DK6ep8+FllJ6ejnbt2uHSpUvYuHEj0tLSsHLlSuzfvx/e3t7IycnRdhMrxa/bFwmZTAYbGxsAgI2NDaZMmYIuXbrg9u3bsLS0rHI7c3Nz2NjYwMbGBgsXLkTnzp3x+++/o0ePHhg9ejTc3NywdetW1W8uODg4wMXFBa1bt8aSJUsQHh6OI0eOIC8vD2vWrIGurvKUcHR0hJ+f34vv+GOeNQfvv/8+Fi9ejJCQEFhZWVUZV69ePdX+xUybebh27Ro++OADfPDBB1i8eLHaulatWmHixInP0KMXb8SIEdixYwdWr16N4ODgKuMkEkm150BwcDB0dXXxxx9/oH79+qrlTk5O6Nev31N/GVYMHv//nTlzJjZs2IAdO3ZgxIgRWLp0KY4dO4YzZ87Aw8MDgPKasGXLFnh5eWH06NH4888/IZFIsGPHDixbtgyvv/46AKBp06Zo27at1vpVG5o6H15GISEh0NfXR0JCAgwNDQEATZo0QevWreHs7Ixp06ZhxYoVWm5lRRxZEaGCggKsW7cOcrkc5ubmNd6u/MQrLi5GYmIizp8/j0mTJlX4cSgPDw90795d9deWjY0NSktLsW3bNtFcjGuTgxEjRkAul2P27Nl11Lq6U9d52LJlC0pKSvDxxx9Xul5bP9D5NCYmJpg2bRpmz579zKOB2dnZSEhIQEhIiFqh8jix9r86hoaGqlHUDRs2wN/fX1WolJNKpQgLC8P58+eRlJQEQHld2L17d4Vbi/8GmjgfXkY5OTnYs2cPgoODVe8X5WxsbBAYGIi4uDjRvA88jsWKSOzatQtGRkYwMjKCsbExduzYgbi4uGp/hfJxubm5mDNnDoyMjNChQwdcvHgRAODm5lZpvJubmyqmY8eO+OSTT/Dmm2/CwsICvXr1whdffIGbN29qpnM19Kw5kEgkmD9/Pr766itcvny5yrjo6GjV/ssf69ev13Q3nps283Dx4kWYmJio/bW5ZcsWtdhz585ppqMaFhwcDAMDgwojQo/Ly8ur0PdevXoBANLS0iAIApo3b662jYWFhSo2PDz8hfZBk8rKyrBu3TqcPXsW3bp1A6D8/63umlAeAwBfffUVjh49CnNzc7Rv3x5hYWE4cuRI3TReA573fHgZXbp0CYIgVHsO3L17F7dv367jlj0dixWR8PPzQ2JiIhITE3HixAkEBASgV69euHr1Knr16qV6IbVo0UJtu06dOsHIyAgNGzZEUlIS4uLiYG1trVpf0wp53rx5yMrKwsqVK9GiRQusXLkSrq6udfrG9Kw5AICAgAC8+uqrmD59epX7DwwMVO2//NG3b98X2aVnou08PDl6EBAQgMTERMTHx+P+/fsoKyvTXGdrYf369WpvKocPH1ZbL5PJMHv2bCxcuBB37typdB/GxsYV+r5mzZpqj3vixAkkJiaiRYsWKCoq0lh/nkd1uSgvRg0NDTF27FiEhYVh/PjxqvU1vSZ07doV6enp2L9/PwYPHozk5GR06dIFc+bM0Xh/noW2zoeXgRhHTp6Gc1ZEon79+pDL5arna9asgampKVavXo01a9agsLAQAKCnp6e2XVxcHNzd3WFubq42O93FxQUAkJKSgtatW1c4XkpKiiqmnLm5OYYMGYIhQ4YgIiICrVu3xsKFC7F27VpNdbNaz5qDcvPnz4e3tzcmT55c6XpTU1O1/T+u/OfR8/LyKqzLzc2t0U+Ya4o289CsWTPk5eUhKytLNbpiZGQEuVyums+kLX379oWXl5fquZ2dXYWYkSNHYuHChZg7d67aJz/KSaXSKvsul8shkUiQmpqqttzJyQkAKgyba1N1uQgMDMS0adNgaGiIRo0aqY3Iubi4ICUlpdJ9li9//Lqgp6eHLl26oEuXLggPD8fcuXMxe/ZshIeHQ19fX9PdqpUXfT4AyuuCGK4JmlJ+jqekpGDAgAEV1qekpKBhw4bVzo3TFo6siJREIoFUKkVhYSHs7Owgl8shl8vh4OCgFmdvbw9nZ+cKH6Pz9PSEq6srlixZAoVCobYuKSkJ+/btw4gRI6o8vr6+PpydnbV6v7emOSjXoUMHDBw4EFOmTKn1sczMzGBhYYFTp06pLc/Pz0daWlqFwq4u1WUeBg8eDD09PSxYsOB5m61xxsbGqr7L5fJKiwepVIrIyEisWLECGRkZtdq/ubk5/P39sXz5ctHPc6guF+XFqJ2dXYVbh8OHD8e+fftU81LKKRQKLFmyBO7u7hXmszzO3d0dpaWlePjwoWY79Axe9PkAAM2bN8fp06crLD99+rRWrwnPqvwcj46OVv3RUy4rKwvr16/HsGHDRDk3iyMrIlFUVISsrCwAwN27d7F8+XIUFBSgT58+z7Q/iUSCr7/+Gv7+/hg0aBCmTp0KGxsb/P777/jwww/h7e2t+v6AXbt2YdOmTRg+fDhcXFwgCAJ27tyJ3bt3IyYmRlNdfCpN5GDevHlo0aJFpaMADx48UO2/nEwmQ8OGDQEAkyZNQkREBKytrdGxY0dkZ2djzpw5sLS0xMCBA5+jZ7WjzTw0adIEixYtQmhoKHJychAUFARHR0fk5ORg3bp1AAAdHZ3n6N2L98Ybb8DLywurVq1SuyUKKIe/n+w7AFhZWUEqlSI6OhqdO3dGu3btMHPmTLRq1QpSqRQnT57EhQsX/jWfhqlKWFgYfvzxR/Tp0weLFi2Cl5cXbt68iYiICKSkpGDfvn2qNypfX1+MGDEC7dq1g7m5Oc6fP49PPvkEfn5+qpHIf4PnOR/Gjx+P5cuXY+LEiRgzZgxkMhni4+OxceNG7Ny5s666oFHLly9Hp06dEBAQgLlz58LR0RHJycmYPHky7OzsMG/ePG03sXICad2oUaMEAKqHsbGx0L59e2Hz5s1VbnPlyhUBgHDmzJlq93327Flh0KBBgpmZmaCnpyc4OzsLn376qXD//n1VzOXLl4WxY8cKLi4ugqGhodCgQQOhffv2QkxMjIZ6+HSazMG7774rABBmzJihWubj46O2//JHQECAKqa0tFSIiooSWrZsKdSrV09o3LixMGzYMOHKlSsa7m3VxJAHQRCEvXv3Cr169RLMzMwEXV1dwdraWujfv7/w888/a7K7NTJq1CihX79+Va738fERQkND1ZYdPXpUACA4ODiolsXExFTadwBCZmamKu7vv/8WJkyYIDg6Ogp6enqCkZGR0KFDB+GLL75Qe91ow7Pk4kn3798Xpk2bJsjlckFPT08wMzMTBg0aJJw7d04tLiIiQvD29hbMzMwEAwMDwcnJSZg4caJw584dDfTk2dX1+XDixAnB399fsLS0FExNTQUvLy9h27Ztmu1UHcvIyBBGjRolWFtbC3p6eoK9vb3w/vvva/3/tjoSQfgXzrQhIiKi/wzOWSEiIiJRY7FCREREosZihYiIiESNxQoRERGJGosVIiIiEjUWK0RERCRqLFaIiIhI1FisEBERkaixWCEiUQgKCkL//v1Vz319fVU/CVGXDhw4AIlEgtzc3CpjJBIJtm/fXuN9zpw5E56ens/VroyMDEgkEiQmJj7Xfoj+jVisEFGVgoKCIJFIIJFIoK+vD7lcjtmzZ6O0tPSFH3vr1q2YM2dOjWJrUmAQ0b8Xf8iQiKrVs2dPxMTEoKioCLt370ZISAj09PQwderUCrHFxcXQ19fXyHHNzMw0sh8i+vfjyAoRVUsmk8HGxgYODg4YP348unfvjh07dgB4dOtm3rx5sLW1RfPmzQEA169fx9ChQ9GgQQOYmZmhX79+yMjIUO2zrKwMkyZNQoMGDWBubo6PP/4YT/5M2ZO3gYqKihAeHg57e3vIZDLI5XJ8/fXXyMjIgJ+fHwCgYcOGkEgkCAoKAgAoFApERkbC0dERhoaG8PDwwObNm9WOs3v3bri4uMDQ0BB+fn5q7ayp8PBwuLi4oF69enBycsL06dNRUlJSIW7VqlWwt7dHvXr1MHToUOTl5amtX7NmDdzc3GBgYABXV1dER0fXui1ELyMWK0RUK4aGhiguLlY9379/P1JTU7F3717s2rULJSUlCAgIgLGxMQ4fPowjR47AyMgIPXv2VG23aNEixMbG4ptvvsFvv/2GnJwcbNu2rdrjvv3229i4cSOioqKQkpKCVatWwcjICPb29tiyZQsAIDU1FZmZmVi2bBkAIDIyEt9++y1WrlyJ5ORkhIWFYeTIkTh48CAAZVE1cOBA9OnTB4mJiRgzZgymTJlS65wYGxsjNjYW58+fx7Jly7B69WosWbJELSYtLQ3ff/89du7ciZ9//hlnzpxBcHCwav369evx2WefYd68eUhJSUFERASmT5+OtWvX1ro9RC8dLf/qMxGJ2KhRo4R+/foJgiAICoVC2Lt3ryCTyYSPPvpItd7a2looKipSbfPdd98JzZs3FxQKhWpZUVGRYGhoKOzZs0cQBEFo1KiR8Pnnn6vWl5SUCI0bN1YdSxAEwcfHRwgNDRUEQRBSU1MFAMLevXsrbeevv/4qABDu3r2rWvbw4UOhXr16wtGjR9ViR48eLYwYMUIQBEGYOnWq4O7urrY+PDy8wr6eBEDYtm1bleu/+OILoW3btqrnM2bMEHR0dIS//vpLteynn34SpFKpkJmZKQiCIDg7OwsbNmxQ28+cOXMEb29vQRAE4cqVKwIA4cyZM1Uel+hlxTkrRFStXbt2wcjICCUlJVAoFHjzzTcxc+ZM1fqWLVuqzVNJSkpCWloajI2N1fbz8OFDXL58GXl5ecjMzISXl5dqna6uLtq1a1fhVlC5xMRE6OjowMfHp8btTktLw4MHD+Dv76+2vLi4GK1btwYApKSkqLUDALy9vWt8jHJxcXGIiorC5cuXUVBQgNLSUpiYmKjFNGnSBHZ2dmrHUSgUSE1NhbGxMS5fvozRo0dj7NixqpjS0lKYmprWuj1ELxsWK0RULT8/P6xYsQL6+vqwtbWFrq76ZaN+/fpqzwsKCtC2bVusX7++wr4sLS2fqQ2Ghoa13qagoAAAEB8fr1YkAMp5OJpy7NgxBAYGYtasWQgICICpqSk2bdqERYsW1bqtq1evrlA86ejoaKytRP9WLFaIqFr169eHXC6vcXybNm0QFxcHKyurCqML5Ro1aoTff/8dXbt2BaAcQTh16hTatGlTaXzLli2hUChw8OBBdO/evcL68pGdsrIy1TJ3d3fIZDJcu3atyhEZNzc31WThcsePH396Jx9z9OhRODg4YNq0aaplV69erRB37do1/P3337C1tVUdRyqVonnz5rC2toatrS3S09MRGBhYq+MT/Rdwgi0RaVRgYCAsLCzQr18/HD58GFeuXMGBAwcwceJE/PXXXwCA0NBQzJ8/H9u3b8eFCxcQHBxc7XekNG3aFKNGjcI777yD7du3q/b5/fffAwAcHBwgkUiwa9cu3L59GwUFBTA2NsZHH32EsLAwrF27FpcvX8bp06fx5Zdfqiatjhs3DpcuXcLkyZORmpqKDRs2IDY2tlb9bdasGa5du4ZNmzbh8uXLiIqKqnSysIGBAUaNGoWkpCQcPnwYEydOxNChQ2FjYwMAmDVrFiIjIxEVFYWLFy/i3LlziImJweLFi2vVHqKXEYsVItKoevXq4dChQ2jSpAkGDhwINzc3jB49Gg8fPlSNtHz44Yd46623MGrUKHh7e8PY2BgDBgyodr8rVqzA4MGDERwcDFdXV4wdOxb3798HANjZ2WHWrFmYMmUKrK2tMWHCBADAnDlzMH36dERGRsLNzQ09e/ZEfHw8HB0dASjnkWzZsgXbt2+Hh4cHVq5ciYiIiFr1t2/fvggLC8OECRPg6emJo0ePYvr06RXi5HI5Bg4ciNdffx09evRAq1at1D6aPGbMGKxZswYxMTFo2bIlfHx8EBsbq2or0X+ZRKhqRhsRERGRCHBkhYiIiESNxQoRERGJGosVIiIiEjUWK0RERCRqLFaIiIhI1FisEBERkaixWCEiIiJRY7FCREREosZihYiIiESNxQoRERGJGosVIiIiErX/B67vfNZe6NumAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"],\n",
    "                      list(tag2index.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁This</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁version</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁MacBook</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁Pro</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁runs</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁on</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁a</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>▁third</td>\n",
       "      <td>B-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>▁-</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>▁generation</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>▁CPU</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>▁(</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>10.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>▁\"</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>9.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>▁I</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>B-NEU</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vy</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>▁Bridge</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>▁\"</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>▁)</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>10.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>,</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>▁not</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>▁the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>▁latest</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>▁four</td>\n",
       "      <td>B-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>th</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>▁-</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>▁generation</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>▁Has</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>well</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>▁CPU</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>▁the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>▁2013</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>▁version</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>▁has</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>.</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tokens labels  preds losses\n",
       "0         ▁This      O      O   0.00\n",
       "1      ▁version      O      O   0.00\n",
       "2           ▁of      O      O   0.00\n",
       "3      ▁MacBook      O      O   0.00\n",
       "4          ▁Pro      O      O   0.00\n",
       "5         ▁runs      O      O   0.00\n",
       "6           ▁on      O      O   0.00\n",
       "7            ▁a      O      O   0.00\n",
       "8        ▁third  B-NEU      O   2.51\n",
       "9            ▁-  I-NEU  I-NEU   0.13\n",
       "10  ▁generation  I-NEU  I-NEU   0.32\n",
       "11         ▁CPU  I-NEU  I-NEU   0.19\n",
       "12           ▁(  I-NEU      O  10.10\n",
       "13           ▁\"  I-NEU      O   9.54\n",
       "14           ▁I  I-NEU  B-NEU   3.00\n",
       "15           vy    IGN  I-NEU  -0.00\n",
       "16      ▁Bridge  I-NEU  I-NEU   0.03\n",
       "17           ▁\"  I-NEU      O   8.90\n",
       "18           ▁)  I-NEU      O  10.89\n",
       "19            ▁      O      O   0.00\n",
       "20            ,    IGN      O  -0.00\n",
       "21         ▁not      O      O   0.00\n",
       "22         ▁the      O      O   0.00\n",
       "23      ▁latest      O      O   0.00\n",
       "24        ▁four  B-NEU      O   5.47\n",
       "25           th    IGN      O  -0.00\n",
       "26           ▁-  I-NEU      O   1.36\n",
       "27  ▁generation  I-NEU      O   1.95\n",
       "28         ▁Has  I-NEU  I-NEU   0.48\n",
       "29         well    IGN  I-NEU  -0.00\n",
       "30         ▁CPU  I-NEU  I-NEU   0.26\n",
       "31         ▁the      O      O   0.00\n",
       "32        ▁2013      O      O   0.00\n",
       "33     ▁version      O      O   0.00\n",
       "34         ▁has      O      O   0.00\n",
       "35            ▁      O      O   0.00\n",
       "36            .    IGN      O  -0.00\n",
       "37         </s>    IGN      O  -0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁The</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁Like</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁New</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁condition</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>▁nice</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>▁package</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>O</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>.</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tokens labels preds losses\n",
       "0         ▁The      O     O   0.00\n",
       "1        ▁Like      O     O   0.00\n",
       "2         ▁New      O     O   0.00\n",
       "3   ▁condition      O     O   0.00\n",
       "4          ▁of      O     O   0.00\n",
       "..         ...    ...   ...    ...\n",
       "90       ▁nice      O     O   0.00\n",
       "91    ▁package  B-POS     O   1.88\n",
       "92           ▁      O     O   0.00\n",
       "93           .    IGN     O  -0.00\n",
       "94        </s>    IGN     O  -0.00\n",
       "\n",
       "[95 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁also</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>▁excellent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>▁operating</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>▁system</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>▁-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>▁size</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>▁and</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>▁weight</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>▁for</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>▁optimal</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>▁mobil</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ity</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>▁-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>▁excellent</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>▁dur</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ability</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>▁of</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>O</td>\n",
       "      <td>2.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>▁the</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>O</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>▁battery</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>▁-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>▁the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>▁function</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>▁provided</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>O</td>\n",
       "      <td>7.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>▁by</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>O</td>\n",
       "      <td>9.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>▁the</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>O</td>\n",
       "      <td>7.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>▁track</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pad</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>▁is</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>▁un</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>match</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ed</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>▁by</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>▁any</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>▁other</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>▁brand</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>▁-</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tokens labels  preds losses\n",
       "0        ▁also      O      O   0.00\n",
       "1            ▁      O      O   0.00\n",
       "2            .    IGN      O  -0.00\n",
       "3            ▁      O      O   0.00\n",
       "4            .    IGN      O  -0.00\n",
       "5            ▁      O      O   0.00\n",
       "6            .    IGN      O  -0.00\n",
       "7           ▁-      O      O   0.00\n",
       "8   ▁excellent      O      O   0.00\n",
       "9   ▁operating  B-POS  B-POS   0.01\n",
       "10     ▁system  I-POS  I-POS   0.01\n",
       "11          ▁-      O      O   0.00\n",
       "12       ▁size  B-POS  B-POS   0.01\n",
       "13        ▁and      O      O   0.00\n",
       "14     ▁weight  B-POS  B-POS   0.01\n",
       "15        ▁for      O      O   0.00\n",
       "16    ▁optimal      O      O   0.00\n",
       "17      ▁mobil  B-POS  B-POS   0.35\n",
       "18         ity    IGN      O  -0.00\n",
       "19          ▁-      O      O   0.00\n",
       "20  ▁excellent      O      O   0.00\n",
       "21        ▁dur  B-POS  B-POS   0.01\n",
       "22     ability    IGN  I-POS  -0.00\n",
       "23         ▁of  I-POS      O   2.87\n",
       "24        ▁the  I-POS      O   3.04\n",
       "25    ▁battery  I-POS  B-POS   4.50\n",
       "26          ▁-      O      O   0.00\n",
       "27        ▁the      O      O   0.00\n",
       "28   ▁function  B-POS  B-POS   0.02\n",
       "29           s    IGN      O  -0.00\n",
       "30   ▁provided  I-POS      O   7.64\n",
       "31         ▁by  I-POS      O   9.01\n",
       "32        ▁the  I-POS      O   7.94\n",
       "33      ▁track  I-POS  B-POS   6.18\n",
       "34         pad    IGN  I-POS  -0.00\n",
       "35         ▁is      O      O   0.00\n",
       "36         ▁un      O      O   0.00\n",
       "37       match    IGN      O  -0.00\n",
       "38          ed    IGN      O  -0.00\n",
       "39         ▁by      O      O   0.00\n",
       "40        ▁any      O      O   0.00\n",
       "41      ▁other      O      O   0.00\n",
       "42      ▁brand      O      O   0.00\n",
       "43          ▁-      O      O   0.00\n",
       "44        </s>    IGN      O  -0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_output\n",
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \n",
    "                               \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp\n",
    "\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample.T)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors could be from human / annotation errors: United Nations is ORG, not PER, similar to Central African Republic. This can happen as data was annotated using rule based, it is better with human annotations, but mistakes can always occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Other</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁than</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁not</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁being</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁a</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁fan</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁of</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁click</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>▁pad</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>▁(</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>▁industry</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>▁standard</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>▁these</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>▁days</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>▁)</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>▁and</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>▁the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>▁lo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>us</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>y</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>▁internal</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>▁speaker</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>s</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>,</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>▁it</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>▁'</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>▁s</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>▁hard</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>▁for</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>▁me</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>▁to</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>▁find</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>▁things</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>▁about</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>▁this</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>▁notebook</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>▁I</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>▁do</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>▁n</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>▁'</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>▁t</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>▁like</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>,</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>▁especially</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>▁considering</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>▁the</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>▁$</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>▁350</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>▁price</td>\n",
       "      <td>B-POS</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>▁tag</td>\n",
       "      <td>I-POS</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>.</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tokens labels  preds losses\n",
       "0         ▁Other      O      O   0.00\n",
       "1          ▁than      O      O   0.00\n",
       "2           ▁not      O      O   0.00\n",
       "3         ▁being      O      O   0.00\n",
       "4             ▁a      O      O   0.00\n",
       "5           ▁fan      O      O   0.00\n",
       "6            ▁of      O      O   0.00\n",
       "7         ▁click  B-NEG  B-NEG   0.01\n",
       "8           ▁pad  I-NEG  I-NEG   0.01\n",
       "9              s    IGN  I-NEG  -0.00\n",
       "10            ▁(      O      O   0.00\n",
       "11     ▁industry      O      O   0.00\n",
       "12     ▁standard      O      O   0.00\n",
       "13        ▁these      O      O   0.00\n",
       "14         ▁days      O      O   0.00\n",
       "15            ▁)      O      O   0.00\n",
       "16          ▁and      O      O   0.00\n",
       "17          ▁the      O      O   0.00\n",
       "18           ▁lo      O      O   0.00\n",
       "19            us    IGN      O  -0.00\n",
       "20             y    IGN      O  -0.00\n",
       "21     ▁internal  B-NEG  B-NEG   0.01\n",
       "22      ▁speaker  I-NEG  I-NEG   0.01\n",
       "23             s    IGN  I-NEG  -0.00\n",
       "24             ▁      O      O   0.00\n",
       "25             ,    IGN      O  -0.00\n",
       "26           ▁it      O      O   0.00\n",
       "27            ▁'      O      O   0.00\n",
       "28            ▁s      O      O   0.00\n",
       "29         ▁hard      O      O   0.00\n",
       "30          ▁for      O      O   0.00\n",
       "31           ▁me      O      O   0.00\n",
       "32           ▁to      O      O   0.00\n",
       "33         ▁find      O      O   0.00\n",
       "34       ▁things      O      O   0.00\n",
       "35        ▁about      O      O   0.00\n",
       "36         ▁this      O      O   0.00\n",
       "37     ▁notebook      O      O   0.00\n",
       "38            ▁I      O      O   0.00\n",
       "39           ▁do      O      O   0.00\n",
       "40            ▁n      O      O   0.00\n",
       "41            ▁'      O      O   0.00\n",
       "42            ▁t      O      O   0.00\n",
       "43         ▁like      O      O   0.00\n",
       "44             ▁      O      O   0.00\n",
       "45             ,    IGN      O  -0.00\n",
       "46   ▁especially      O      O   0.00\n",
       "47  ▁considering      O      O   0.00\n",
       "48          ▁the      O      O   0.00\n",
       "49            ▁$      O      O   0.01\n",
       "50          ▁350      O      O   0.03\n",
       "51        ▁price  B-POS  B-NEG   4.93\n",
       "52          ▁tag  I-POS  I-NEG   4.43\n",
       "53             ▁      O      O   0.00\n",
       "54             .    IGN      O  -0.00\n",
       "55          </s>    IGN      O  -0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁No</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁installation</td>\n",
       "      <td>B-NEU</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>▁disk</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>I-NEG</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁(</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>8.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>▁DVD</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>B-NEG</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁)</td>\n",
       "      <td>I-NEU</td>\n",
       "      <td>O</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁is</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁included</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>▁</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tokens labels  preds losses\n",
       "0             ▁No      O      O   0.00\n",
       "1   ▁installation  B-NEU  B-NEG   3.71\n",
       "2           ▁disk  I-NEU  I-NEG   3.00\n",
       "3              ▁(  I-NEU      O   8.43\n",
       "4            ▁DVD  I-NEU  B-NEG   6.25\n",
       "5              ▁)  I-NEU      O   9.25\n",
       "6             ▁is      O      O   0.00\n",
       "7       ▁included      O      O   0.00\n",
       "8               ▁      O      O   0.00\n",
       "9               .    IGN      O  -0.00\n",
       "10           </s>    IGN      O  -0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# hide_output\n",
    "df_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmr_tokenizer.save_pretrained('xlmr_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Reload the model\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(model_name) #output_model_dir\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained('xlmr_tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[     0,  14804, 107730,   2053,   3688,      2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m loaded_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# predictions = outputs.logits  # Adjust this based on the model's output\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Use predictions as needed\u001b[39;00m\n\u001b[1;32m     12\u001b[0m predicted_label\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 7)"
     ]
    }
   ],
   "source": [
    "# Assuming you have some input data\n",
    "input_data = \"Your input data here\"\n",
    "# Tokenize and get predictions\n",
    "inputs = loaded_tokenizer(input_data, is_split_into_words=False, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "outputs = loaded_model(**inputs)\n",
    "# predictions = outputs.logits  # Adjust this based on the model's output\n",
    "\n",
    "predicted_label = torch.argmax(outputs.logits, axis=-1).cpu().numpy()\n",
    "\n",
    "# Use predictions as needed\n",
    "predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hide_output\n",
    "# valid_set = ds_encoded[\"test\"]\n",
    "# valid_set = valid_set.map(forward_pass_with_label_from_saved, batched=True, batch_size=32)\n",
    "# df_test = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "\n",
    "df_test[\"predicted_label\"] = df_test[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df_test[\"labels\"] = df_test[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df_test['loss'] = df_test.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df_test['predicted_label'] = df_test.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "\n",
    "# hide_output\n",
    "df_tokens = df_test.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "# df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "# df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "macro_f1 = f1_score(df_tokens['labels'], df_tokens['predicted_label'], average='macro')\n",
    "print(macro_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentilens_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
