{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nltk.org/api/nltk.tokenize.treebank.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "\n",
    "# # Replace 'path/to/word2vec/model.bin' with the path to your pretrained Word2Vec model\n",
    "# model_path = 'path/to/word2vec/model.bin'\n",
    "# word2vec_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "# # Access the vector for a specific word\n",
    "# vector_for_word = word2vec_model['example']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from highlight_text import HighlightText, ax_text, fig_text\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "# from sklearn_crfsuite import CRF\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize sentence and aspect BIO encoding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceToken:\n",
    "  '''\n",
    "    SentenceToken\n",
    "\n",
    "  '''\n",
    "  def __init__(self, sentence, aspect_type=None, aspects=None, sentence_id=None):\n",
    "    \n",
    "    if sentence_id is not None:\n",
    "      print(sentence_id)\n",
    "\n",
    "    self.sentence_id = sentence_id\n",
    "    self.sentence = sentence.replace(u\"\\u00A0\", \" \")\n",
    "                            \n",
    "    self.aspect_bio_tags = None\n",
    "    self.unified_aspect_bio_tags = None\n",
    "    self.token_span = None\n",
    "    self.space_pre_token = None\n",
    "\n",
    "    # Tokenize sentence\n",
    "    self.__tokenize_sentence(self.sentence)\n",
    "\n",
    "    if aspect_type == 'dict':\n",
    "      self.set_aspect_tagging_from_dict(aspects)\n",
    "    elif aspect_type == 'bio':\n",
    "      self.set_aspect_bio_tags(aspects)\n",
    "    elif aspect_type == 'unified bio':\n",
    "      self.set_aspect_unified_bio_tags(aspects)\n",
    "  \n",
    "  def __tokenize_sentence(self, sentence):\n",
    "    # self.sentence = sentence\n",
    "    \n",
    "    token_span = list(TreebankWordTokenizer().span_tokenize(sentence))\n",
    "\n",
    "    new_token_span = []\n",
    "    \n",
    "    for k in token_span:\n",
    "      token_start = k[0]\n",
    "      token_end = k[1]\n",
    "\n",
    "      token = sentence[token_start:token_end]\n",
    "      sub_tokens = re.split(r'([^\\w,\\d])', token)\n",
    "      \n",
    "      sub_token_start = token_start\n",
    "      for sub_token in sub_tokens:\n",
    "        if len(sub_token) != 0:\n",
    "          sub_token_end = sub_token_start + len(sub_token)\n",
    "          new_token_span.append((sub_token_start, sub_token_end))\n",
    "          sub_token_start = sub_token_end\n",
    "    \n",
    "    self.token_span = new_token_span\n",
    "    self.space_pre_token = [True if sentence[k[0]-1:k[0]] == ' ' else False for i,k in enumerate(new_token_span)]\n",
    "\n",
    "\n",
    "  def set_aspect_tagging_from_dict(self, aspects):\n",
    "    polarity_map = {'positive':'POS'\n",
    "              ,'negative': 'NEG'\n",
    "              ,'conflict': 'CON'\n",
    "              ,'neutral': 'NEU'}\n",
    "    \n",
    "    bio_tags = ['O'] * len(self.token_span)\n",
    "    unified_bio_tags = bio_tags\n",
    "\n",
    "    for x in aspects:\n",
    "      if x['term'] != '':\n",
    "        aspect_from = int(x['from'])\n",
    "        aspect_to = int(x['to'])\n",
    "        polarity = '-' + polarity_map[x['polarity']]\n",
    "        aspect_token_ids =  [i for i, v in enumerate(self.token_span) if (v[0] >= aspect_from) & (v[1] <= aspect_to)]\n",
    "        aspect_from_index = min(aspect_token_ids)\n",
    "        aspect_to_index = max(aspect_token_ids)\n",
    "        aspect_length = aspect_to_index - aspect_from_index\n",
    "        bio_tags = bio_tags[:aspect_from_index] + ['B'] + ['I'] * (aspect_length) + bio_tags[aspect_to_index+1:]\n",
    "        unified_bio_tags = unified_bio_tags[:aspect_from_index] + ['B' + polarity] + ['I'+ polarity] * (aspect_length) + unified_bio_tags[aspect_to_index+1:]\n",
    "    \n",
    "    self.set_aspect_bio_tags(bio_tags)\n",
    "    self.set_aspect_unified_bio_tags(unified_bio_tags)\n",
    "\n",
    "  def rebuild_sentence_from_token(self):\n",
    "    return ''.join([(' ' if self.space_pre_token[i] else '') + self.sentence[k[0]:k[1]] for i, k in enumerate(self.token_span)])\n",
    "  \n",
    "  def get_sentence_token_with_aspect_bio_tag(self, unified_bio_tag=False):\n",
    "    if (unified_bio_tag == False) & (self.aspect_bio_tags is None):\n",
    "      raise Exception('No BIO tags provided. Use \"SentenceToken.set_aspect_bio_tags()\" method to add bio_tags')\n",
    "    elif (unified_bio_tag == True) & (self.aspect_unified_bio_tags is None):\n",
    "      raise Exception('No Unified BIO tags provided. Use \"SentenceToken.set_aspect_unified_bio_tags()\" method to add unified_bio_tags')\n",
    "    else:\n",
    "      return [(self.sentence[k[0]:k[1]], self.aspect_unified_bio_tags[i] if unified_bio_tag else self.aspect_bio_tags[i]) for i, k in enumerate(self.token_span)]\n",
    "\n",
    "  def set_aspect_bio_tags(self, aspect_bio_tags):\n",
    "    self.aspect_bio_tags = aspect_bio_tags\n",
    "    self.aspect_unified_bio_tags = aspect_bio_tags\n",
    "\n",
    "  def set_aspect_unified_bio_tags(self, aspect_unified_bio_tags):\n",
    "    self.aspect_unified_bio_tags = aspect_unified_bio_tags\n",
    "    self.aspect_bio_tags = [k[0:1] for k in aspect_unified_bio_tags]\n",
    "\n",
    "  def check_rebuild_sentence_from_token(self):\n",
    "    return re.sub(r'\\s+', ' ',self.sentence.strip()) == self.rebuild_sentence_from_token().strip()\n",
    "  \n",
    "  def get_tokens(self):\n",
    "    return [self.sentence[k[0]:k[1]] for k in self.token_span]\n",
    "\n",
    "  def check_rebuild_aspect_terms(self, aspect_dict):\n",
    "    aspect_dict = sorted(aspect_dict, key=lambda d: int(d['from']))\n",
    "    aspect_input = ', '.join([k['term'] for k in aspect_dict])\n",
    "    aspect_computed = ''.join([(', ' if k == 'B' else '') + self.sentence[self.token_span[i][0]:self.token_span[i][1]] for i,k in enumerate(self.aspect_bio_tags) if k in ['B','I'] ])[2:]\n",
    "    \n",
    "    return (aspect_input == aspect_computed, aspect_input, aspect_computed)\n",
    "\n",
    "  def __str__(self):\n",
    "    return self.rebuild_sentence_from_token()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape:  (3048, 3)\n",
      "df_val shape:  (800, 3)\n",
      "(3036, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_json('data/laptop/train.json')\n",
    "# df_train.set_index('id', inplace=True).reset_index()\n",
    "print('df_train shape: ', df_train.shape)\n",
    "\n",
    "df_val = pd.read_json('data/laptop/validate.json') # This will only be used for the very last step to evaluate how well the model is, but is input now for validating the BIO tagging to ensure the function works properly\n",
    "# df_val.set_index('id', inplace=True).reset_index()\n",
    "print('df_val shape: ', df_val.shape)\n",
    "\n",
    "# First, I will need to drop some duplicated data in our training dataset, as identified in the EDA process.\n",
    "df_train.drop_duplicates(subset='text', inplace=True)\n",
    "\n",
    "# We have removed 12 duplicated records in our training dataset\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sentence_token'] = df_train.apply(lambda x: SentenceToken(x['text'], 'dict', x['aspects']), axis=1)\n",
    "df_train['sentence_check'] = df_train.apply(lambda x: x['sentence_token'].check_rebuild_sentence_from_token(), axis=1)\n",
    "df_train['aspect_check'] = df_train.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects']), axis=1)\n",
    "\n",
    "df_val['sentence_token'] = df_val.apply(lambda x: SentenceToken(x['text'], 'dict', x['aspects']), axis=1)\n",
    "df_val['sentence_check'] = df_val.apply(lambda x: x['sentence_token'].check_rebuild_sentence_from_token(), axis=1)\n",
    "df_val['aspect_check'] = df_val.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of df_train records having tokenizing issues:  0\n",
      "# of df_train records having aspect bio tagging issues:  0\n",
      "# of df_val records having tokenizing issues:  0\n",
      "# of df_val records having  aspect bio tagging issues:  0\n"
     ]
    }
   ],
   "source": [
    "print('# of df_train records having tokenizing issues: ', len(df_train[df_train['sentence_check']==False]))\n",
    "print('# of df_train records having aspect bio tagging issues: ', len(df_train[df_train['aspect_check']==False]))\n",
    "print('# of df_val records having tokenizing issues: ', len(df_val[df_val['sentence_check']==False]))\n",
    "print('# of df_val records having  aspect bio tagging issues: ', len(df_val[df_val['aspect_check']==False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sentence_length'] = df_train.apply(lambda x: len(x['sentence_token'].get_tokens()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.ecdf(df_train['sentence_length'], marginal=\"histogram\", title='90% reviews have <= 30 words')\n",
    "fig. update_layout(showlegend=False,\n",
    "                   xaxis_title=\"# of words in reviews\",\n",
    "                   yaxis_title=\"Review counts\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF with FastText embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embeddings_to_dict (sentence_embeddings, window = 5):\n",
    "  sentence_features = []\n",
    "  for i in range(0, len(sentence_embeddings)):\n",
    "    word_features = {}\n",
    "    word_embeddings = sentence_embeddings[i]\n",
    "    word_features.update(word_embeddings_to_dict(word_embeddings,f'word'))\n",
    "    \n",
    "    if i > 0:\n",
    "      for k in range(1, min(window, i)+1):\n",
    "          # prev_word = tokens[i - k]\n",
    "          prev_word_embeddings = sentence_embeddings[i-k]\n",
    "          # print('prev_word: ', prev_word)\n",
    "          word_features.update(word_embeddings_to_dict(prev_word_embeddings,f'-{k}:word'))\n",
    "    else:\n",
    "        word_features['BOS'] = True  # Beginning of sentence\n",
    "\n",
    "    if i < len(sentence_embeddings) - 1:\n",
    "      for k in range(1, min(window, len(sentence_embeddings) - i - 1)+1):\n",
    "        # next_word = tokens[i + k]\n",
    "        next_word_embeddings = sentence_embeddings[i+k]\n",
    "        # print('next_word: ', next_word)\n",
    "        # print(next_word_embeddings)\n",
    "        word_features.update(word_embeddings_to_dict(next_word_embeddings,f'+{k}:word'))\n",
    "    else:\n",
    "        word_features['EOS'] = True  # End of sentence\n",
    "\n",
    "    sentence_features.append(word_features)\n",
    "    \n",
    "  return sentence_features\n",
    "\n",
    "def word_embeddings_to_dict(embeddings, feature_prefix='word'):\n",
    "  \n",
    "  \n",
    "  word_features = {}\n",
    "  for iv,value in enumerate(embeddings):\n",
    "    word_features[f'{feature_prefix}:v_{iv}'] = value\n",
    "  \n",
    "  return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = fasttext.load_model('cc.en.300.bin')\n",
    "X_train_word_embeddings = [[fasttext_model.get_word_vector(token) for token in sentence_token.get_tokens()] for sentence_token in df_train['sentence_token']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dict = [sentence_embeddings_to_dict(sentence_embeddings, 5) for sentence_embeddings in X_train_word_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['sentence_token'].apply(lambda x: x.aspect_unified_bio_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_crf, X_test_crf, y_train, y_test = train_test_split(X_train_dict, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train CRF model\n",
    "crf_model = CRF(algorithm='lbfgs',\n",
    "                max_iterations=100,\n",
    "                c1=0.5,\n",
    "                c2=0.05)\n",
    "\n",
    "# There is this error existing with this library: 'CRF' object has no attribute 'keep_tempfiles'\n",
    "# which has not been resolved and we can bypass it using this trick.\n",
    "try:\n",
    "  crf_model.fit(X_train_crf, y_train)\n",
    "except AttributeError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_crf_pred = crf_model.predict(X_train_crf)\n",
    "\n",
    "y_train_flat = [tag for sentence in y_train for tag in sentence]\n",
    "y_train_crf_pred_flat = [tag for sentence in y_train_crf_pred for tag in sentence]\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_train_flat, y_train_crf_pred_flat)\n",
    "classification_rep = classification_report(y_train_flat, y_train_crf_pred_flat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_train_flat, y_train_crf_pred_flat, labels=crf_model.classes_)\n",
    "\n",
    "# Plot the confusion matrix with seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=crf_model.classes_, yticklabels=crf_model.classes_, vmax=100, vmin=1)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_crf_pred = crf_model.predict(X_test_crf)\n",
    "\n",
    "y_test_flat = [tag for sentence in y_test for tag in sentence]\n",
    "y_test_crf_pred_flat = [tag for sentence in y_test_crf_pred for tag in sentence]\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_flat, y_test_crf_pred_flat)\n",
    "classification_rep = classification_report(y_test_flat, y_test_crf_pred_flat)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_test_crf_pred_flat, labels=crf_model.classes_)\n",
    "\n",
    "# Plot the confusion matrix with seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=crf_model.classes_, yticklabels=crf_model.classes_, vmax=100, vmin=1)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words = set(token  for sentence_token in df_train['sentence_token'] for token in sentence_token.get_tokens() if token not in fasttext_model.words)\n",
    "len(missing_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 22:37:22.537588: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tf2CRF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf2CRF\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CRF\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Embedding, Bidirectional, GRU, Dense\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tf2CRF'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tf2CRF import CRF\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, GRU, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tf2crf import CRF, ModelWithCRFLoss\n",
    "\n",
    "inputs = Input(shape=(None,), dtype='int32')\n",
    "output = Embedding(100, 40, trainable=True, mask_zero=True)(inputs)\n",
    "output = Bidirectional(GRU(64, return_sequences=True))(output)\n",
    "crf = CRF(units=9, type='float32')\n",
    "output = crf(output)\n",
    "base_model = Model(inputs, output)\n",
    "model = ModelWithCRFLoss(base_model, sparse_target=True)\n",
    "model.compile(optimizer='adam')\n",
    "\n",
    "x = [[5, 2, 3] * 3] * 10\n",
    "y = [[1, 2, 3] * 3] * 10\n",
    "\n",
    "model.fit(x=x, y=y, epochs=2, batch_size=2)\n",
    "model.save('tests/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_words = df_train['sentence_token'].apply(lambda x: x.get_tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer(char_level=False, lower=True)\n",
    "# Fit on your list of words\n",
    "tokenizer.fit_on_texts(X_words)\n",
    "\n",
    "word_to_number = tokenizer.word_index\n",
    "number_to_word = tokenizer.index_word\n",
    "fasttext_model = fasttext.load_model('cc.en.300.bin')\n",
    "word_to_features = dict((word_to_number[token], fasttext_model.get_word_vector(token)) for token in word_to_number.keys())\n",
    "all_words = list(word_to_number.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_words = df_train['sentence_token'].apply(lambda x: x.aspect_unified_bio_tags)\n",
    "# Create a tokenizer\n",
    "y_tokenizer = Tokenizer(char_level=False, lower=False)\n",
    "# Fit on your list of words\n",
    "y_tokenizer.fit_on_texts(y_words)\n",
    "\n",
    "\n",
    "tag_to_number = y_tokenizer.word_index\n",
    "number_to_tag = y_tokenizer.index_word\n",
    "\n",
    "all_tags = list(tag_to_number.keys())\n",
    "\n",
    "print(f\"Tags size: {len(all_tags)}\")\n",
    "\n",
    "y_id = y_tokenizer.texts_to_sequences(y_words)\n",
    "y = sequence.pad_sequences(y_id, maxlen=max_review_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_words, X_test_words, y_train, y_test = train_test_split(X_words, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_review_length = 30\n",
    "word_to_features[0] = [0]*300\n",
    "X_train = tokenizer.texts_to_sequences(X_train_words)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length, padding='post')\n",
    "X_train = np.array([[word_to_features[word] for word in sentence] for sentence in X_train])\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(X_test_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post')\n",
    "X_test = np.array([[word_to_features[word] for word in sentence] for sentence in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(all_words) + 1 #Important adjustment\n",
    "number_of_tags = len(all_tags) + 1\n",
    "\n",
    "print(number_of_classes)\n",
    "RNN_wordlevel = Sequential([\n",
    "    layers.InputLayer(input_shape=( max_review_length,300,)),\n",
    "    # # embedding layer, 8-dimensional\n",
    "    # layers.Embedding(number_of_classes, 8),\n",
    "    layers.Bidirectional(layers.LSTM(units=100, return_sequences=True, recurrent_dropout=0.1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.15),\n",
    "    # # the intermediate recurrent layers should return full sequences\n",
    "    # layers.GRU(64, activation='relu', return_sequences=True),\n",
    "    # layers.BatchNormalization(),\n",
    "    # layers.Dropout(0.15),\n",
    "\n",
    "    # # the last recurrent layer only returns the final output\n",
    "    # layers.GRU(32, activation='relu', return_sequences=False),\n",
    "    # layers.BatchNormalization(),\n",
    "    # layers.Dropout(0.15),\n",
    "\n",
    "    # output layer\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.15),\n",
    "    layers.Dense(number_of_tags, activation='softmax')], name=\"RNN_wordlevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "RNN_wordlevel.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = RNN_wordlevel.fit(X_train, y_train,\n",
    "        batch_size=1024,\n",
    "        epochs=25,\n",
    "        validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 26)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history[\"accuracy\"], label=\"training\", marker=\"o\")\n",
    "plt.plot(epochs, history.history[\"val_accuracy\"], label=\"validation\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(epochs[::5])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history[\"loss\"], label=\"training\", marker=\"o\")\n",
    "plt.plot(epochs, history.history[\"val_loss\"], label=\"validation\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(epochs[::5])\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Evaluate on test data\")\n",
    "# results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "# print(\"test loss: {} \".format(results[0]))\n",
    "# print(\"test accuracy: {} \".format(results[1]))\n",
    "\n",
    "i = np.random.randint(0, X_test.shape[0])\n",
    "print(\"This is sentence:\",i)\n",
    "p = model.predict(np.array([X_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "number_to_word[0] = ''\n",
    "number_to_tag[0] = ''\n",
    "\n",
    "print(\"{:15}{:5}\\t {}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(\"-\" *30)\n",
    "for w, true, pred in zip(X_test_words.iloc[i], y_test[i], p[0]):\n",
    "    print(\"{:15}{}\\t{}\".format(w, number_to_tag[true], number_to_tag[pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_raw = RNN_wordlevel.predict(X_test)\n",
    "y_test_pred = np.argmax(y_test_pred_raw, axis=-1)\n",
    "y_test_flat = [tag for sentence in y_test for tag in sentence]\n",
    "y_test_pred_flat = [tag for sentence in y_test_pred for tag in sentence]\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_flat, y_test_pred_flat)\n",
    "classification_rep = classification_report(y_test_flat, y_test_pred_flat)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_test_pred_flat)\n",
    "conf_matrix\n",
    "\n",
    "# Plot the confusion matrix with seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['None'] + list(tag_to_number.keys()), yticklabels=['None']+list(tag_to_number.keys()), vmax=100, vmin=1)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tag_to_number.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "X_train_words = [sentence_token.get_tokens() for sentence_token in df_train['sentence_token']]\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer(char_level=False, lower=True)\n",
    "# Fit on your list of words\n",
    "tokenizer.fit_on_texts(X_train_words)\n",
    "\n",
    "word_to_number = tokenizer.word_index\n",
    "number_to_word = tokenizer.index_word\n",
    "\n",
    "all_words = list(word_to_number.keys())\n",
    "\n",
    "print(f\"Vocabulary size: {len(all_words)}\")\n",
    "\n",
    "dataset = tokenizer.texts_to_sequences(X_train_words)\n",
    "\n",
    "print(dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency = pd.DataFrame(data=tokenizer.word_counts.items(), columns=[\"word\", \"count\"])\n",
    "word_frequency = word_frequency.sort_values(\"count\", ascending=False)[:25]\n",
    "word_frequency.set_index(\"word\").plot(kind=\"bar\", rot=90, title=\"Word count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_words = df_train['sentence_token'].apply(lambda x: x.aspect_unified_bio_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a tokenizer\n",
    "y_tokenizer = Tokenizer(char_level=False, lower=False)\n",
    "# Fit on your list of words\n",
    "y_tokenizer.fit_on_texts(y_train_words)\n",
    "\n",
    "\n",
    "tag_to_number = y_tokenizer.word_index\n",
    "number_to_tag = y_tokenizer.index_word\n",
    "\n",
    "all_tags = list(tag_to_number.keys())\n",
    "\n",
    "print(f\"Tags size: {len(all_tags)}\")\n",
    "\n",
    "y_train = y_tokenizer.texts_to_sequences(y_train_words)\n",
    "\n",
    "\n",
    "word_frequency = pd.DataFrame(data=y_tokenizer.word_counts.items(), columns=[\"word\", \"count\"])\n",
    "word_frequency = word_frequency.sort_values(\"count\", ascending=False)[:25]\n",
    "word_frequency.set_index(\"word\").plot(kind=\"bar\", rot=90, title=\"Word count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN?!?! From study material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### THIS NEEDS REVISE LOGIC - CURRENTLY IS JUST TO SAMPLE ########\n",
    "X = []\n",
    "y = []\n",
    "SEQUENCE_LENGTH = 5\n",
    "for nth_sentence, sentence in enumerate(dataset):\n",
    "    for window_start_idx in range(len(sentence)-SEQUENCE_LENGTH):\n",
    "        window_end_idx = window_start_idx + SEQUENCE_LENGTH\n",
    "        X.append(sentence[window_start_idx: window_end_idx])\n",
    "        y.append(y_train[nth_sentence][window_start_idx])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Let's look at the shapes\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    print(\"X:\", [number_to_word[num] for num in X[i]])\n",
    "    print(\"y:\", number_to_tag[y[i]])\n",
    "    print(\"*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and validation set\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_validation.shape, y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GRU, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(all_words) + 1 #Important adjustment\n",
    "number_of_tags = len(all_tags) + 1\n",
    "print(number_of_classes)\n",
    "RNN_wordlevel = Sequential([\n",
    "\n",
    "    # embedding layer, 8-dimensional\n",
    "    Embedding(number_of_classes, 8),\n",
    "\n",
    "    # the intermediate recurrent layers should return full sequences\n",
    "    GRU(64, activation='relu', return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.15),\n",
    "\n",
    "    # the last recurrent layer only returns the final output\n",
    "    GRU(32, activation='relu', return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.15),\n",
    "\n",
    "    # output layer\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.15),\n",
    "    Dense(number_of_tags, activation='softmax')], name=\"RNN_wordlevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "RNN_wordlevel.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = RNN_wordlevel.fit(X_train, y_train,\n",
    "        batch_size=1024,\n",
    "        epochs=25,\n",
    "        validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 26)\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history.history[\"accuracy\"], label=\"training\", marker=\"o\")\n",
    "plt.plot(epochs, history.history[\"val_accuracy\"], label=\"validation\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(epochs[::5])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history.history[\"loss\"], label=\"training\", marker=\"o\")\n",
    "plt.plot(epochs, history.history[\"val_loss\"], label=\"validation\", marker=\"o\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(epochs[::5])\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = RNN_wordlevel.evaluate(X_train,  y_train, verbose=2)\n",
    "val_loss, val_acc = RNN_wordlevel.evaluate(X_validation,  y_validation, verbose=2)\n",
    "print('\\nTrain accuracy:', train_acc)\n",
    "print('\\nVal accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_phrase = ['I', 'charge', 'it', 'at', 'night', 'and', 'skip', 'taking', 'the', 'cord', 'with', 'me', 'because', 'of', 'the'] # good battery life.'\n",
    "\n",
    "# process for the model\n",
    "processed_phrase = tokenizer.texts_to_sequences([input_phrase])[0]\n",
    "\n",
    "\n",
    "# extract last 5 words\n",
    "network_input = np.array(processed_phrase[-SEQUENCE_LENGTH:], dtype=np.float32)\n",
    "network_input = network_input.reshape((1, SEQUENCE_LENGTH)) # shape: 1 x 5\n",
    "\n",
    "# the RNN gives the probability of each word as the next one\n",
    "predict_proba = RNN_wordlevel.predict(network_input, verbose=0)[0] # shape (4855,)\n",
    "predict_label = number_to_tag[np.argmax(predict_proba)]\n",
    "# # sample one word using these chances\n",
    "# predicted_index = np.random.choice(number_of_classes, 1, p=predict_proba)[0]\n",
    "\n",
    "# # add new index at the end of our list\n",
    "# processed_phrase.append(predicted_index)\n",
    "\n",
    "# # progress indicator\n",
    "# print(i, end=\"\\r\")\n",
    "\n",
    "# indices mapped to words - the method expects a list of lists so we need the extra bracket\n",
    "output_phrase = tokenizer.sequences_to_texts([processed_phrase])[0]\n",
    "\n",
    "print(output_phrase)\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_image(i, predictions_array, true_label, img):\n",
    "#   # true_label, img = true_label[i], img[i]\n",
    "#   # plt.grid(False)\n",
    "#   # plt.xticks([])\n",
    "#   # plt.yticks([])\n",
    "\n",
    "#   # plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "#   predicted_label = np.argmax(predictions_array)\n",
    "#   if predicted_label == true_label:\n",
    "#     color = 'blue'\n",
    "#   else:\n",
    "#     color = 'red'\n",
    "\n",
    "#   plt.xlabel(\"{} {:2.0f}% ({})\".format(number_to_tag[predicted_label],\n",
    "#                                 100*np.max(predictions_array),\n",
    "#                                 number_to_tag[true_label]),\n",
    "#                                 color=color)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance on the test data\n",
    "score = RNN_wordlevel.evaluate(X_validation, y_validation, verbose=1)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentilens_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
