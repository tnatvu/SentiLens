{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Data preparation](#toc1_)    \n",
    "  - 1.1. [Tokenize sentence and aspect BIO encoding class](#toc1_1_)    \n",
    "  - 1.2. [Load data](#toc1_2_)    \n",
    "  - 1.3. [Inspect tagging issues](#toc1_3_)    \n",
    "  - 1.4. [Merge conflict to negative & remove neutral](#toc1_4_)    \n",
    "  - 1.5. [Convert df to HuggingFace datasets](#toc1_5_)    \n",
    "  - 1.6. [Word features](#toc1_6_)    \n",
    "- 2. [EDA](#toc2_)    \n",
    "- 3. [Model performance class](#toc3_)    \n",
    "- 4. [Random forest](#toc4_)    \n",
    "- 5. [CRF](#toc5_)    \n",
    "- 6. [Bi-LSTM](#toc6_)    \n",
    "- 7. [BERT](#toc7_)    \n",
    "  - 7.1. [Model](#toc7_1_)    \n",
    "  - 7.2. [Data preparation](#toc7_2_)    \n",
    "  - 7.3. [Upsampling / downsampling](#toc7_3_)    \n",
    "  - 7.4. [Model tuning](#toc7_4_)    \n",
    "  - 7.5. [Error analysis](#toc7_5_)    \n",
    "    - 7.5.1. [Group by word token](#toc7_5_1_)    \n",
    "    - 7.5.2. [Group by Tag ID](#toc7_5_2_)    \n",
    "  - 7.6. [Load saved model](#toc7_6_)    \n",
    "    - 7.6.1. [Load model manually](#toc7_6_1_)    \n",
    "    - 7.6.2. [Pipeline](#toc7_6_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0' # this setting is needed to run NN on my Mac\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from highlight_text import HighlightText, ax_text, fig_text\n",
    "\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "from sklearn.metrics import f1_score as sklearn_f1_score\n",
    "\n",
    "# pip install torch==2.2.0 torchtext --index-url https://download.pytorch.org/whl/test/cpu\n",
    "# pip install torch==2.3.0.dev20240121 # this does not work\n",
    "\n",
    "# pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu # run this in CLI before running the notebook\n",
    "\n",
    "# import torch\n",
    "# if torch.backends.mps.is_available():\n",
    "#     mps_device = torch.device(\"mps\")\n",
    "#     x = torch.ones(1, device=mps_device)\n",
    "#     print (x)\n",
    "# else:\n",
    "#     print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Data preparation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. <a id='toc1_1_'></a>[Tokenize sentence and aspect BIO encoding class](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceToken:\n",
    "  '''\n",
    "    SentenceToken\n",
    "\n",
    "    This class takes care of word tokenize and tagging aspect entities\n",
    "  '''\n",
    "  def __init__(self, sentence, aspect_type=None, aspects=None, sentence_id=None):\n",
    "    \n",
    "    if sentence_id is not None:\n",
    "      print(sentence_id)\n",
    "\n",
    "    self.sentence_id = sentence_id\n",
    "    self.sentence = sentence.replace(u\"\\u00A0\", \" \").replace(u'\\xa0',' ') # replace unicode space character\n",
    "                            \n",
    "    self.aspect_bio_tags = None\n",
    "    self.unified_aspect_bio_tags = None\n",
    "    self.token_span = None\n",
    "    self.space_pre_token = None\n",
    "\n",
    "    # Tokenize sentence\n",
    "    self.__tokenize_sentence(self.sentence)\n",
    "\n",
    "    if aspect_type == 'dict':\n",
    "      self.set_aspect_tagging_from_dict(aspects)\n",
    "    elif aspect_type == 'bio':\n",
    "      self.set_aspect_bio_tags(aspects)\n",
    "    elif aspect_type == 'unified bio':\n",
    "      self.set_aspect_unified_bio_tags(aspects)\n",
    "  \n",
    "  def __tokenize_sentence(self, sentence):\n",
    "    '''\n",
    "    __tokenize_sentence\n",
    "\n",
    "    Break sentence into word token span\n",
    "    '''\n",
    "    token_span = list(TreebankWordTokenizer().span_tokenize(sentence))\n",
    "    \n",
    "    self.token_span = token_span\n",
    "    self.space_pre_token = [True if sentence[k[0]-1:k[0]] == ' ' else False for i,k in enumerate(token_span)]\n",
    "\n",
    "  def set_aspect_tagging_from_dict(self, aspects):\n",
    "    '''\n",
    "    set_aspect_tagging_from_dict\n",
    "\n",
    "    Calculate & assign aspect entities to token given an array of aspects (term, start_index, to_index, and polarity)\n",
    "    '''\n",
    "    polarity_map = {'positive':'POS'\n",
    "              ,'negative': 'NEG'\n",
    "              ,'conflict': 'CON'\n",
    "              ,'neutral': 'NEU'}\n",
    "    \n",
    "    bio_tags = ['O'] * len(self.token_span)\n",
    "    unified_bio_tags = bio_tags\n",
    "\n",
    "    for x in aspects:\n",
    "      if x['term'] != '':\n",
    "        aspect_from = int(x['from'])\n",
    "        aspect_to = int(x['to'])\n",
    "        polarity = '-' + polarity_map[x['polarity']]\n",
    "\n",
    "        aspect_from_index = [i for i, v in enumerate(self.token_span) if (v[0] <= aspect_from) & (v[1] >= aspect_from)][0]\n",
    "        aspect_to_index = [i for i, v in enumerate(self.token_span) if (v[0] <= aspect_to) & (v[1] >= aspect_to)][0]\n",
    "      \n",
    "        aspect_length = aspect_to_index - aspect_from_index\n",
    "        bio_tags = bio_tags[:aspect_from_index] + ['B'] + ['I'] * (aspect_length) + bio_tags[aspect_to_index+1:]\n",
    "        unified_bio_tags = unified_bio_tags[:aspect_from_index] + ['B' + polarity] + ['I'+ polarity] * (aspect_length) + unified_bio_tags[aspect_to_index+1:]\n",
    "\n",
    "    self.set_aspect_bio_tags(bio_tags)\n",
    "    self.set_aspect_unified_bio_tags(unified_bio_tags)\n",
    "\n",
    "  def rebuild_sentence_from_token(self):\n",
    "    '''\n",
    "    rebuild_sentence_from_token\n",
    "\n",
    "    Return sentence built from computed tokens\n",
    "    '''\n",
    "    return ''.join([(' ' if self.space_pre_token[i] else '') + self.sentence[k[0]:k[1]] for i, k in enumerate(self.token_span)])\n",
    " \n",
    "  def set_aspect_bio_tags(self, aspect_bio_tags):\n",
    "    '''\n",
    "    set_aspect_bio_tags\n",
    "\n",
    "    Setter method to set aspect_unified_bio_tags and aspect_bio_tags\n",
    "    '''\n",
    "    self.aspect_bio_tags = aspect_bio_tags\n",
    "    self.aspect_unified_bio_tags = aspect_bio_tags\n",
    "\n",
    "  def set_aspect_unified_bio_tags(self, aspect_unified_bio_tags):\n",
    "    ''''\n",
    "    set_aspect_unified_bio_tags\n",
    "    \n",
    "    Setter method to set aspect_unified_bio_tags and aspect_bio_tags\n",
    "    '''\n",
    "    self.aspect_unified_bio_tags = aspect_unified_bio_tags\n",
    "    self.aspect_bio_tags = [k[0:1] for k in aspect_unified_bio_tags]\n",
    "\n",
    "  def get_tokens(self):\n",
    "    '''\n",
    "    get_tokens()\n",
    "    Return an array of sentence word tokens\n",
    "    '''\n",
    "    return [self.sentence[k[0]:k[1]] for k in self.token_span]\n",
    "  \n",
    "  def check_rebuild_sentence_from_token(self):\n",
    "    '''\n",
    "    check_rebuild_sentence_from_token()\n",
    "\n",
    "    This is a test / debugger function.\n",
    "    This help validating if we have computed the sentence to token properly and whether we can re-compute the exact sentence from information stored.\n",
    "    '''\n",
    "    return re.sub(r'\\s+', ' ',self.sentence.strip()) == self.rebuild_sentence_from_token().strip()\n",
    "  \n",
    "  def check_rebuild_aspect_terms(self, aspect_dict):\n",
    "    '''\n",
    "    check_rebuild_aspect_terms(aspect_dict)\n",
    "\n",
    "    This is a test / debugger fucntion. \n",
    "    This help validate if we have compute the correct aspect terms as given by the aspect dict\n",
    "\n",
    "    INPUT:\n",
    "    aspect dict: array of aspect dictionaries in the following format\n",
    "      [{'term': 'storage', \n",
    "       'polarity': 'positive', \n",
    "       'from': '14', \n",
    "       'to': '21'}]\n",
    "    '''\n",
    "    aspect_dict = sorted(aspect_dict, key=lambda d: int(d['from']))\n",
    "    aspect_input = [k['term'].replace(u\"\\u00A0\", \" \").replace(u'\\xa0',' ') for k in aspect_dict if k['term'] != '' ]\n",
    "    aspect_computed = []\n",
    "    aspect = ''\n",
    "    \n",
    "    for i,k in enumerate(self.aspect_bio_tags):\n",
    "      token = self.sentence[self.token_span[i][0]:self.token_span[i][1]]\n",
    "      \n",
    "      if k == 'B':\n",
    "        if (self.aspect_bio_tags[i-1] == 'B' if i > 0 else False):\n",
    "          aspect_computed.append(aspect)\n",
    "        aspect = token\n",
    "      elif k == 'I':\n",
    "        aspect += ' ' * ((self.token_span[i][0] -  self.token_span[i-1][1]) if i > 0 else 0) + token\n",
    "      \n",
    "      if (aspect != '') & ((k == 'O') or (i == (len(self.aspect_bio_tags) - 1))):\n",
    "          aspect_computed.append(aspect)\n",
    "          aspect = ''\n",
    "\n",
    "    return [aspect_input == aspect_computed, aspect_input, aspect_computed]\n",
    "\n",
    "  def __str__(self):\n",
    "    return self.rebuild_sentence_from_token()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. <a id='toc1_2_'></a>[Load data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_Data():\n",
    "  df_train = pd.read_json('data/laptop/train.json')\n",
    "  # First, I will need to drop some duplicated data in our training dataset, as identified in the EDA process.\n",
    "  # We have removed 12 duplicated records in our training dataset\n",
    "  df_train.drop_duplicates(subset='text', inplace=True)\n",
    "  print('df_train shape: ', df_train.shape)\n",
    "\n",
    "  df_val = pd.read_json('data/laptop/validate.json') # This will only be used for the very last step to evaluate how well the model is, but is input now for validating the BIO tagging to ensure the function works properly\n",
    "  print('df_val shape: ', df_val.shape)\n",
    "\n",
    "  df_train['sentence_token'] = df_train.apply(lambda x: SentenceToken(x['text'], 'dict', x['aspects']), axis=1)\n",
    "  df_train['sentence_check'] = df_train.apply(lambda x: x['sentence_token'].check_rebuild_sentence_from_token(), axis=1)\n",
    "  df_train['aspect_check'] = df_train.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects']), axis=1)\n",
    "  df_train['aspect_check_TF'] = df_train.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects'])[0], axis=1)\n",
    "  df_train['tokens'] = df_train.apply(lambda x: x['sentence_token'].get_tokens(), axis=1)\n",
    "  df_train['tags'] = df_train.apply(lambda x: x['sentence_token'].aspect_unified_bio_tags, axis=1)\n",
    "\n",
    "  df_val['sentence_token'] = df_val.apply(lambda x: SentenceToken(x['text'], 'dict', x['aspects']), axis=1)\n",
    "  df_val['sentence_check'] = df_val.apply(lambda x: x['sentence_token'].check_rebuild_sentence_from_token(), axis=1)\n",
    "  df_val['aspect_check'] = df_val.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects']), axis=1)\n",
    "  df_val['aspect_check_TF'] = df_val.apply(lambda x: x['sentence_token'].check_rebuild_aspect_terms(x['aspects'])[0], axis=1)\n",
    "  df_val['tokens'] = df_val.apply(lambda x: x['sentence_token'].get_tokens(), axis=1)\n",
    "  df_val['tags'] = df_val.apply(lambda x: x['sentence_token'].aspect_unified_bio_tags, axis=1)\n",
    "  return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape:  (3036, 3)\n",
      "df_val shape:  (800, 3)\n",
      "# of df_train records having tokenizing issues:  0\n",
      "# of df_train records having aspect bio tagging issues:  36\n",
      "# of df_test records having tokenizing issues:  0\n",
      "# of df_test records having aspect bio tagging issues:  9\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = reload_Data()\n",
    "print('# of df_train records having tokenizing issues: ', len(df_train[df_train['sentence_check']==False]))\n",
    "print('# of df_train records having aspect bio tagging issues: ', len(df_train[df_train['aspect_check_TF']==False]))\n",
    "print('# of df_test records having tokenizing issues: ', len(df_test[df_test['sentence_check']==False]))\n",
    "print('# of df_test records having aspect bio tagging issues: ', len(df_test[df_test['aspect_check_TF']==False]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. <a id='toc1_3_'></a>[Inspect tagging issues](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 125,  140,  220,  293,  374,  375,  431,  612,  656,  834,  922,  924,\n",
      "        953,  999, 1031, 1374, 1456, 1502, 1631, 1716, 1936, 1958, 2113, 2160,\n",
      "       2244, 2392, 2502, 2533, 2587, 2606, 2783, 2831, 2842, 2876, 2930, 2940],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(df_train[df_train['aspect_check_TF']==False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'term': 'delivery service', 'polarity': 'negative', 'from': '59', 'to': '75'}]\n",
      "After way too many times sending the thing in for repairs (delivery service was slow, and without the laptop I had no access to the internet, and thus no way of tracking it to find out when I might hope to see my computer again), it finally kicked the bucket after just over 2 years.\n",
      "[False, ['delivery service'], ['(delivery service']]\n",
      "['After', 'way', 'too', 'many', 'times', 'sending', 'the', 'thing', 'in', 'for', 'repairs', '(', 'delivery', 'service', 'was', 'slow', ',', 'and', 'without', 'the', 'laptop', 'I', 'had', 'no', 'access', 'to', 'the', 'internet', ',', 'and', 'thus', 'no', 'way', 'of', 'tracking', 'it', 'to', 'find', 'out', 'when', 'I', 'might', 'hope', 'to', 'see', 'my', 'computer', 'again', ')', ',', 'it', 'finally', 'kicked', 'the', 'bucket', 'after', 'just', 'over', '2', 'years', '.']\n"
     ]
    }
   ],
   "source": [
    "num = 2606\n",
    "\n",
    "print(df_train.loc[num]['aspects'])\n",
    "print(df_train.loc[num]['text'])\n",
    "print(df_train.loc[num]['aspect_check'])\n",
    "print(df_train.loc[num]['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the tagging issues due to word that are not separated properly from special characters/ punctuations. The issue is unavoidable in practice as reviews may not adherent to perfect grammar.\n",
    "\n",
    "I have tried to fix this issues to have 100% accuracy with further token breakdown to match the specified aspect tokens, however, this can break some of the standard logics for word tokenizer and further modelling. \n",
    "\n",
    "Therefore, I decided to include a whole token where the aspect may start or end, even if the index is in the middle of token, which may results with aspect tokens that could include extra characters than planned. This is the risk we will accept for this approach, and we can perform a cleaning process to remove these extra characters during implementation with actual use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. <a id='toc1_4_'></a>[Merge conflict to negative & remove neutral](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tags'] = df_train['tags'].apply(lambda x: [tag[:2] + 'NEG' if tag[2:] == 'CON' else tag for tag in x ])\n",
    "df_test['tags'] = df_test['tags'].apply(lambda x: [tag[:2] + 'NEG' if tag[2:] == 'CON' else tag for tag in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['tags'] = df_train['tags'].apply(lambda x: ['O' if tag[2:] == 'NEU' else tag for tag in x])\n",
    "# df_test['tags'] = df_test['tags'].apply(lambda x: ['O' if tag[2:] == 'NEU' else tag for tag in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. <a id='toc1_5_'></a>[Convert df to HuggingFace datasets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset, DatasetDict, Features, Sequence, Value, ClassLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert aspect tag to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of unique aspect tags\n",
    "tags = list(set(sum(df_train['tags'],[])))\n",
    "tags.sort()\n",
    "\n",
    "tag2idx = {k:i for i,k in enumerate(tags)}\n",
    "idx2tag = {i:k for i,k in enumerate(tags)}\n",
    "\n",
    "# Convert aspect tag text to ids\n",
    "df_train['tags_idx'] = df_train['tags'].apply(lambda x: [tag2idx[k] for k in x])\n",
    "df_test['tags_idx'] = df_test['tags'].apply(lambda x: [tag2idx[k] for k in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-NEG',\n",
       " 1: 'B-NEU',\n",
       " 2: 'B-POS',\n",
       " 3: 'I-NEG',\n",
       " 4: 'I-NEU',\n",
       " 5: 'I-POS',\n",
       " 6: 'O'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-NEG', 'B-NEU', 'B-POS', 'I-NEG', 'I-NEU', 'I-POS', 'O']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert pandas to HuggingFace datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into train & validation set\n",
    "df_train_ori, df_val = train_test_split(df_train, test_size=0.3, random_state=42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags_idx'],\n",
      "        num_rows: 2125\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags_idx'],\n",
      "        num_rows: 911\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags_idx'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Define dataset features\n",
    "features = Features({'tokens': Sequence(Value(dtype='string', id=None)),\n",
    "                    'tags_idx': Sequence(ClassLabel(names=tags))\n",
    "                    })\n",
    "\n",
    "tds = Dataset.from_pandas(df_train_ori[['tokens','tags_idx']], features=features, preserve_index=False)\n",
    "vds = Dataset.from_pandas(df_val[['tokens','tags_idx']], features=features,  preserve_index=False)\n",
    "tsds = Dataset.from_pandas(df_test[['tokens','tags_idx']], features=features, preserve_index=False)\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = tds\n",
    "ds['validation'] = vds\n",
    "ds['test'] = tsds\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for total counts per aspect type in each data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79691b5ee9f4369aa2ff0f807a2b020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3642db37e314414a15b19b142a354f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f17631f5bb4cbab7b0f806e70b5b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert aspect idx to aspect aspect text\n",
    "def create_tag_names(batch):\n",
    "    return {\"tags\": [ds[\"train\"].features[\"tags_idx\"].feature.int2str(idx) for idx in batch[\"tags_idx\"]]}\n",
    "\n",
    "ds = ds.map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NEG</th>\n",
       "      <th>POS</th>\n",
       "      <th>NEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>582</td>\n",
       "      <td>675</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>325</td>\n",
       "      <td>312</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>144</td>\n",
       "      <td>340</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NEG  POS  NEU\n",
       "train       582  675  304\n",
       "validation  325  312  157\n",
       "test        144  340  169"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform aspect type counts per each dataset split\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in ds.items():\n",
    "    for row in dataset[\"tags\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "                \n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. <a id='toc1_6_'></a>[Word features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords, opinion_lexicon\n",
    "import string\n",
    "\n",
    "# Load positive and negative words from the opinion lexicon\n",
    "POSITIVE_WORDS = set(opinion_lexicon.positive())\n",
    "NEGATIVE_WORDS = set(opinion_lexicon.negative())\n",
    "# Load common stop words in english\n",
    "EN_STOP_WORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert sentences into features\n",
    "def word2features(sent, word_idx, backward_window_size=5, forward_window_size=5): \n",
    "    word = sent[word_idx][0]\n",
    "\n",
    "    _, pos = zip(*nltk.pos_tag([x[0] for x in sent]))\n",
    "\n",
    "    tag_sentiment = lambda word: 'POS' if word in POSITIVE_WORDS else 'NEG' if word in NEGATIVE_WORDS else 'NEU'\n",
    "    features = {\n",
    "        'word.lower()': word.lower(), # word\n",
    "        'word.index()': word_idx,\n",
    "        'word.reverseindex()': len(sent) - 1 - word_idx, # reverse index - nth word from end of sentence\n",
    "        'word.pos': pos[word_idx],\n",
    "        'word.opinionlexicon': tag_sentiment(word.lower()),\n",
    "        'word.isstopword()': word.lower() in EN_STOP_WORDS,\n",
    "        'word[-3:]': word[-3:], # last 4 char\n",
    "        'word[-2:]': word[-2:], # last 3 char - in case of -ing, -ion, etc.\n",
    "        'word.isupper()': word.isupper(), # is the word in upper case\n",
    "        'word.istitle()': word.istitle(), # is the first letter of the word in upper case\n",
    "        'word.isdigit()': word.isdigit(), # is the word full of digit\n",
    "        'word.ispunctuation()': word.lower() in string.punctuation, # is punctuation\n",
    "    }\n",
    "\n",
    "    if word_idx > 0:\n",
    "        for k in range(1, min(backward_window_size, word_idx)+1):\n",
    "            prev_word = sent[word_idx - k][0]\n",
    "            prev_pos = pos[word_idx - k]\n",
    "            \n",
    "            features.update({\n",
    "                f'-{k}:word.lower()': prev_word.lower(),\n",
    "                f'-{k}:word.pos': prev_pos,\n",
    "                f'-{k}:word.opinionlexicon': tag_sentiment(word.lower()),\n",
    "                f'-{k}:word.isstopword()': prev_word in EN_STOP_WORDS,\n",
    "                f'-{k}:word.istitle()': prev_word.istitle(),\n",
    "                f'-{k}:word.isupper()': prev_word.isupper(),\n",
    "                f'-{k}:word.ispunctuation()': prev_word.lower() in string.punctuation, # is punctuation\n",
    "            })\n",
    "    else:\n",
    "        features['BOS'] = True  # Beginning of sentence\n",
    "\n",
    "    if word_idx < len(sent) - 1:\n",
    "        for k in range(1, min(forward_window_size, len(sent) - word_idx - 1)+1):\n",
    "            next_word = sent[word_idx + k][0]\n",
    "            next_pos = pos[word_idx + k]\n",
    "\n",
    "            features.update({\n",
    "                f'+{k}:word.lower()': next_word.lower(),\n",
    "                f'+{k}:word.pos': next_pos,\n",
    "                f'+{k}:word.opinionlexicon': tag_sentiment(word.lower()),\n",
    "                f'+{k}:word.isstopword()': next_word in EN_STOP_WORDS,\n",
    "                f'+{k}:word.istitle()': next_word.istitle(),\n",
    "                f'+{k}:word.isupper()': next_word.isupper(),\n",
    "                f'+{k}:word.ispunctuation()': next_word.lower() in string.punctuation, # is punctuation\n",
    "            })\n",
    "    else:\n",
    "        features['EOS'] = True  # End of sentence\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to convert sentences into feature sequences\n",
    "def sent2features(sent, backward_window_size=5, forward_window_size=5):\n",
    "    return [word2features(sent, i, backward_window_size, forward_window_size) for i in range(len(sent))]\n",
    "\n",
    "def get_features(example):\n",
    "    example['word_features'] = [ sent2features(sent) for sent in example['tokens']]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf2ed5f05714e138cb99da0da52c18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e49d8c4e3e41d8bf5b8251e190c451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12a2f669a7b41baa82b1260c0007867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_features = ds.map(get_features, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[EDA](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[Model performance class](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPerformanceLog:\n",
    "  \n",
    "  def __init__(self, y_true):\n",
    "    self.y_true = y_true\n",
    "    self.log = {}\n",
    "    self.bert_epoch_history = pd.DataFrame()\n",
    "\n",
    "  def add_model_performance(self, model_name, y_pred, model=None): # Model can be path to the model or something like that\n",
    "    sklearn_f1_score, f1, clf_report = self.__calculate_metrics(y_pred)\n",
    "\n",
    "    model_perf = {'y_pred': y_pred\n",
    "                  ,'model': model\n",
    "                  ,'sklearn_f1_score': sklearn_f1_score.round(2)\n",
    "                  ,'f1': f1.round(4)\n",
    "                  ,'report': clf_report\n",
    "                  }\n",
    "    \n",
    "    self.log[model_name] = model_perf\n",
    "\n",
    "  def __calculate_sklearn_f1(self, y_pred):\n",
    "    y_pred = sum(y_pred,[])\n",
    "    y_true = sum(self.y_true,[])\n",
    "    return sklearn_f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "\n",
    "  def __calculate_metrics(self, y_pred):\n",
    "    return self.__calculate_sklearn_f1(y_pred), f1_score(self.y_true, y_pred), classification_report(self.y_true, y_pred, zero_division=0)\n",
    "\n",
    "  def get_logs(self):\n",
    "    logs_df = pd.DataFrame(list(self.log.values()), index=self.log.keys())\n",
    "    return logs_df[['sklearn_f1_score', 'f1']]\n",
    "  \n",
    "  def add_bert_training_epoch_history(self, model_name, epoch_history_df):\n",
    "    epoch_history_df['Model'] = model_name\n",
    "    self.bert_epoch_history = pd.concat([self.bert_epoch_history, epoch_history_df])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = ds['validation'].to_pandas()['tags_idx']\n",
    "y_val = [[idx2tag[tag] for tag in sent] for sent in y_val]\n",
    "\n",
    "modelPerformanceLog = ModelPerformanceLog(y_val)\n",
    "# modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[Random forest](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features2df(sent, sent_idx):\n",
    "  sent_df = pd.DataFrame(list(sent))\n",
    "  sent_df['sentence_idx'] = sent_idx\n",
    "\n",
    "  return sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags2df(tags, sent_idx):\n",
    "  tags_df = pd.DataFrame({'tags': tags})\n",
    "\n",
    "  tags_df['sentence_idx'] = sent_idx\n",
    "  return tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_data_prepare(ds, one_hot_encoder=None):\n",
    "  X_train = ds.to_pandas()['word_features']\n",
    "  X_train = pd.concat([features2df(sent, i) for i, sent in enumerate(X_train)], ignore_index=True)\n",
    "\n",
    "  X_train.replace(True,1, inplace=True)\n",
    "  X_train.replace(False,0, inplace=True)\n",
    "\n",
    "    # Fill NaN values in object-type columns with a 'missing'\n",
    "  object_columns = X_train.select_dtypes(include=['object']).columns\n",
    "  X_train[object_columns] = X_train[object_columns].fillna(value='missing')\n",
    "\n",
    "  # Fill the rest NaN with -1, since most of missing features are boolean\n",
    "  X_train = X_train.fillna(-1)\n",
    "\n",
    "  # We renove all categorical columns that are not POS, or sentiment lexicon + nth_sentence which the number of the sentence we we use to string back the data at the end, but is not needed for training\n",
    "  drop_cols = [x for x in list(X_train.columns) if re.match('(.*word\\.lower\\(\\))|(.*word\\[-\\d\\:])', x)] # word columns\n",
    "  X_train = X_train.drop(columns=drop_cols, axis=1)\n",
    "\n",
    "    # Perform one-hot-encoder on the reamining columns\n",
    "  if one_hot_encoder is None: # This is to make sure we use the same one-hot-encoder for both train & test split (avoiding data leakage)\n",
    "    one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop='first')  # 'drop' parameter is optional, set to 'first' to avoid multicollinearity\n",
    "    encoded_data = one_hot_encoder.fit_transform(X_train.select_dtypes(include=['object']))\n",
    "\n",
    "  else: # when we perform data prep for test data, we can reuse the one-hot-encoder used during training data preparation\n",
    "    encoded_data = one_hot_encoder.transform(X_train.select_dtypes(include=['object']))\n",
    "\n",
    "  # Re-added one-hot-encoding data back to the main dataframe\n",
    "  df_encoded = pd.DataFrame(encoded_data, columns=one_hot_encoder.get_feature_names_out(X_train.select_dtypes(include=['object']).columns))\n",
    "  X_train = pd.concat([X_train, df_encoded], axis=1)\n",
    "\n",
    "  # Dropped all the categorical features that have already been one-hot-encoded\n",
    "  X_train.drop(columns=X_train.select_dtypes(include=['object']).columns, inplace=True)\n",
    "\n",
    "  y_train =  pd.concat([tags2df(sent, i) for i, sent in enumerate(ds.to_pandas()['tags_idx'])], ignore_index=True)# sum(ds.to_pandas()['tags_idx'], [])\n",
    "  return X_train, y_train, one_hot_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [3, 5, 7, 9] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, one_hot_encoder = random_forest_data_prepare(ds_features['train'])\n",
    "X_val, y_val, _ = random_forest_data_prepare(ds_features['validation'], one_hot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_train_scaled = scaler.fit_transform(X_train.drop('sentence_idx', axis=1))\n",
    "X_val_scaled = scaler.transform(X_val.drop('sentence_idx', axis=1)) # Double check why we are seeing more columns in test????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=5, random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train['tags'])\n",
    "\n",
    "y_pred_rf = rf_classifier.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn_f1_score</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sklearn_f1_score   f1\n",
       "random forest              0.14  0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add back to validation set to get sentence id\n",
    "y_val['predict'] = y_pred_rf \n",
    "\n",
    "# Collapse back to the required format\n",
    "y_pred_rf = y_val.groupby('sentence_idx')['predict'].agg(lambda x: x.tolist())\n",
    "\n",
    "# Convert to name lablel\n",
    "y_pred_rf = [[idx2tag[tag] for tag in sent] for sent in y_pred_rf]\n",
    "\n",
    "modelPerformanceLog.add_model_performance('random forest',y_pred_rf)\n",
    "modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. <a id='toc5_'></a>[CRF](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ds_features['train'].to_pandas()['word_features']\n",
    "y_train = ds_features['train'].to_pandas()['tags_idx']\n",
    "y_train = [[idx2tag[tag] for tag in sent] for sent in y_train]\n",
    "\n",
    "X_val = ds_features['validation'].to_pandas()['word_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train CRF model\n",
    "crf_model = CRF(algorithm='lbfgs',\n",
    "                max_iterations=100,\n",
    "                c1=0.5,\n",
    "                c2=0.05)\n",
    "\n",
    "# There is this error existing with this library: 'CRF' object has no attribute 'keep_tempfiles'\n",
    "# which has not been resolved and we can bypass it using this trick.\n",
    "try:\n",
    "  crf_model.fit(X_train, y_train)\n",
    "except AttributeError:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_crf = crf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn_f1_score</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crf</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sklearn_f1_score   f1\n",
       "random forest              0.14  0.0\n",
       "crf                        0.14  0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPerformanceLog.add_model_performance('crf',y_pred_crf)\n",
    "modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. <a id='toc6_'></a>[Bi-LSTM](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Author: Robert Guthrie\n",
    "\n",
    "# import torch\n",
    "# import torch.autograd as autograd\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def argmax(vec):\n",
    "#     # return the argmax as a python int\n",
    "#     _, idx = torch.max(vec, 1)\n",
    "#     return idx.item()\n",
    "\n",
    "\n",
    "# def prepare_sequence(seq, to_ix):\n",
    "#     idxs = [to_ix[w] for w in seq]\n",
    "#     return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# # Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "# def log_sum_exp(vec):\n",
    "#     max_score = vec[0, argmax(vec)]\n",
    "#     max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "#     return max_score + \\\n",
    "#         torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "#     def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "#         super(BiLSTM_CRF, self).__init__()\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.tag_to_ix = tag_to_ix\n",
    "#         self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "#         self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "#         self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "#                             num_layers=1, bidirectional=True)\n",
    "\n",
    "#         # Maps the output of the LSTM into tag space.\n",
    "#         self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "#         # Matrix of transition parameters.  Entry i,j is the score of\n",
    "#         # transitioning *to* i *from* j.\n",
    "#         self.transitions = nn.Parameter(\n",
    "#             torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "#         # These two statements enforce the constraint that we never transfer\n",
    "#         # to the start tag and we never transfer from the stop tag\n",
    "#         self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "#         self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "#         self.hidden = self.init_hidden()\n",
    "\n",
    "#     def init_hidden(self):\n",
    "#         return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "#                 torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "#     def _forward_alg(self, feats):\n",
    "#         # Do the forward algorithm to compute the partition function\n",
    "#         init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "#         # START_TAG has all of the score.\n",
    "#         init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "#         # Wrap in a variable so that we will get automatic backprop\n",
    "#         forward_var = init_alphas\n",
    "\n",
    "#         # Iterate through the sentence\n",
    "#         for feat in feats:\n",
    "#             alphas_t = []  # The forward tensors at this timestep\n",
    "#             for next_tag in range(self.tagset_size):\n",
    "#                 # broadcast the emission score: it is the same regardless of\n",
    "#                 # the previous tag\n",
    "#                 emit_score = feat[next_tag].view(\n",
    "#                     1, -1).expand(1, self.tagset_size)\n",
    "#                 # the ith entry of trans_score is the score of transitioning to\n",
    "#                 # next_tag from i\n",
    "#                 trans_score = self.transitions[next_tag].view(1, -1)\n",
    "#                 # The ith entry of next_tag_var is the value for the\n",
    "#                 # edge (i -> next_tag) before we do log-sum-exp\n",
    "#                 next_tag_var = forward_var + trans_score + emit_score\n",
    "#                 # The forward variable for this tag is log-sum-exp of all the\n",
    "#                 # scores.\n",
    "#                 alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "#             forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "#         terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "#         alpha = log_sum_exp(terminal_var)\n",
    "#         return alpha\n",
    "\n",
    "#     def _get_lstm_features(self, sentence):\n",
    "#         self.hidden = self.init_hidden()\n",
    "#         embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "#         lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "#         lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "#         lstm_feats = self.hidden2tag(lstm_out)\n",
    "#         return lstm_feats\n",
    "\n",
    "#     def _score_sentence(self, feats, tags):\n",
    "#         # Gives the score of a provided tag sequence\n",
    "#         score = torch.zeros(1)\n",
    "#         tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "#         for i, feat in enumerate(feats):\n",
    "#             score = score + \\\n",
    "#                 self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "#         score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "#         return score\n",
    "\n",
    "#     def _viterbi_decode(self, feats):\n",
    "#         backpointers = []\n",
    "\n",
    "#         # Initialize the viterbi variables in log space\n",
    "#         init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "#         init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "#         # forward_var at step i holds the viterbi variables for step i-1\n",
    "#         forward_var = init_vvars\n",
    "#         for feat in feats:\n",
    "#             bptrs_t = []  # holds the backpointers for this step\n",
    "#             viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "#             for next_tag in range(self.tagset_size):\n",
    "#                 # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "#                 # previous step, plus the score of transitioning\n",
    "#                 # from tag i to next_tag.\n",
    "#                 # We don't include the emission scores here because the max\n",
    "#                 # does not depend on them (we add them in below)\n",
    "#                 next_tag_var = forward_var + self.transitions[next_tag]\n",
    "#                 best_tag_id = argmax(next_tag_var)\n",
    "#                 bptrs_t.append(best_tag_id)\n",
    "#                 viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "#             # Now add in the emission scores, and assign forward_var to the set\n",
    "#             # of viterbi variables we just computed\n",
    "#             forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "#             backpointers.append(bptrs_t)\n",
    "\n",
    "#         # Transition to STOP_TAG\n",
    "#         terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "#         best_tag_id = argmax(terminal_var)\n",
    "#         path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "#         # Follow the back pointers to decode the best path.\n",
    "#         best_path = [best_tag_id]\n",
    "#         for bptrs_t in reversed(backpointers):\n",
    "#             best_tag_id = bptrs_t[best_tag_id]\n",
    "#             best_path.append(best_tag_id)\n",
    "#         # Pop off the start tag (we dont want to return that to the caller)\n",
    "#         start = best_path.pop()\n",
    "#         assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "#         best_path.reverse()\n",
    "#         return path_score, best_path\n",
    "\n",
    "#     def neg_log_likelihood(self, sentence, tags):\n",
    "#         feats = self._get_lstm_features(sentence)\n",
    "#         forward_score = self._forward_alg(feats)\n",
    "#         gold_score = self._score_sentence(feats, tags)\n",
    "#         return forward_score - gold_score\n",
    "\n",
    "#     def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "#         # Get the emission scores from the BiLSTM\n",
    "#         lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "#         # Find the best path, given the features.\n",
    "#         score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "#         return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START_TAG = \"<START>\"\n",
    "# STOP_TAG = \"<STOP>\"\n",
    "# EMBEDDING_DIM = 5\n",
    "# HIDDEN_DIM = 4\n",
    "\n",
    "# # Make up some training data\n",
    "# training_data = [(\n",
    "#     \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "#     \"B I I I O O O B I O O\".split()\n",
    "# ), (\n",
    "#     \"georgia tech is a university in georgia\".split(),\n",
    "#     \"B I O O O O B\".split()\n",
    "# )]\n",
    "\n",
    "# word_to_ix = {}\n",
    "# for sentence, tags in training_data:\n",
    "#     for word in sentence:\n",
    "#         if word not in word_to_ix:\n",
    "#             word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "# tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "\n",
    "# model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "# # Check predictions before training\n",
    "# with torch.no_grad():\n",
    "#     precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "#     precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "#     print(model(precheck_sent))\n",
    "\n",
    "# # Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "# for epoch in range(\n",
    "#         300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "#     for sentence, tags in training_data:\n",
    "#         # Step 1. Remember that Pytorch accumulates gradients.\n",
    "#         # We need to clear them out before each instance\n",
    "#         model.zero_grad()\n",
    "\n",
    "#         # Step 2. Get our inputs ready for the network, that is,\n",
    "#         # turn them into Tensors of word indices.\n",
    "#         sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "#         targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "#         # Step 3. Run our forward pass.\n",
    "#         loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "#         # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "#         # calling optimizer.step()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# # Check predictions after training\n",
    "# with torch.no_grad():\n",
    "#     precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "#     print(model(precheck_sent))\n",
    "# # We got it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. <a id='toc7_'></a>[BERT](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-03 17:23:52.363882: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from transformers import AutoConfig, DistilBertConfig, AutoTokenizer, TrainingArguments, DataCollatorForTokenClassification, Trainer\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.distilbert.modeling_distilbert import DistilBertModel\n",
    "from transformers.models.distilbert.modeling_distilbert import DistilBertPreTrainedModel\n",
    "\n",
    "device = torch.device('mps') # This is required for Mac\n",
    "# torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. <a id='toc7_1_'></a>[Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBertForABSA(DistilBertPreTrainedModel):\n",
    "  config_class = DistilBertConfig\n",
    "\n",
    "  def __init__(self, config, architecture, loss_token_weights):\n",
    "    super().__init__(config)\n",
    "    # Roberta body\n",
    "    self.num_labels = config.num_labels\n",
    "    self.distilbert = DistilBertModel(config)#, add_pooling_layer=False)\n",
    "    self.architecture = architecture\n",
    "    self.loss_token_weights = loss_token_weights\n",
    "    # Classification head\n",
    "    self.dropout = nn.Dropout(config.dropout)#hidden_dropout_prob)\n",
    "    \n",
    "\n",
    "    if architecture == 'additional_linear':\n",
    "        # Additional layer\n",
    "        self.additional_linear = nn.Linear(config.hidden_size, 10)\n",
    "        self.additional_dropout = nn.Dropout(0.5)#hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(10, config.num_labels)\n",
    "        \n",
    "\n",
    "    elif architecture == 'lstm':\n",
    "        self.lstm = nn.LSTM(config.hidden_size, 30, bidirectional=True)\n",
    "        self.additional_dropout = nn.Dropout(0.5)#hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(60, config.num_labels)\n",
    "    else:\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    # Load and initialize weights from pretrained\n",
    "    self.init_weights()\n",
    "\n",
    "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, \n",
    "                labels=None, **kwargs):\n",
    "        \n",
    "    # Use model body to get encoder representations\n",
    "    outputs = self.distilbert(input_ids, attention_mask=attention_mask,\n",
    "                        #    token_type_ids=token_type_ids,\n",
    "                                **kwargs)\n",
    "    \n",
    "    # Apply classifier to encoder representation (model head)\n",
    "    sequence_output = self.dropout(outputs[0])\n",
    "\n",
    "    if self.architecture == 'additional_linear':\n",
    "        # Additional layer\n",
    "      additional_linear_output = self.additional_linear(sequence_output)\n",
    "      logit_input = self.additional_dropout(additional_linear_output)\n",
    "    elif self.architecture == 'lstm':\n",
    "      lstm_output, _ = self.lstm(sequence_output)\n",
    "      logit_input = self.additional_dropout(lstm_output)\n",
    "    else:\n",
    "      logit_input = sequence_output\n",
    "    \n",
    "    logits = self.classifier(logit_input)\n",
    "    \n",
    "    # Calculate losses\n",
    "    loss = None\n",
    "    if labels is not None:\n",
    "        if len(self.loss_token_weights) > 0:\n",
    "          # loss_weights = torch.tensor(self.loss_token_weights, dtype=torch.float16).to(device) # This kills the kernel, not sure why\n",
    "          loss_fct = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "          loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "    # Return model output object\n",
    "    return TokenClassifierOutput(loss=loss, logits=logits, \n",
    "                                     hidden_states=outputs.hidden_states, \n",
    "                                     attentions=outputs.attentions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. <a id='toc7_3_'></a>[Upsampling / downsampling](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "df_train_ori['aspect_token_counts'] = df_train_ori['tags'].apply(lambda x: sum([1 for tag in x if tag != 'O']))\n",
    "df_train_ori['select'] = df_train_ori['aspect_token_counts'].apply(lambda x: randint(0,2) if x == 0 else 1)\n",
    "\n",
    "downsample_df_train = df_train_ori[df_train_ori['select']==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 1382\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 911\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 2125\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 911\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "downsample_tds = Dataset.from_pandas(downsample_df_train[['tokens','tags_idx','tags']], features=ds['train'].features, preserve_index=False)\n",
    "\n",
    "downsample_ds = copy.copy(ds)\n",
    "\n",
    "downsample_ds['train'] = downsample_tds\n",
    "\n",
    "\n",
    "print(downsample_ds)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log,sqrt, ceil\n",
    "\n",
    "def custom_sampling_based_on_score(df, method):\n",
    "  # Get stats of the class distribution of the dataset\n",
    "  labels = sum(df['tags'],[])\n",
    "  num_tokens = len(labels)\n",
    "  ent = [label[2:] for label in labels if label != 'O']\n",
    "  stats = Counter(ent)\n",
    "  for key in stats:\n",
    "      #Use frequency instead of count\n",
    "      stats[key] = stats[key]/num_tokens\n",
    "\n",
    "  if method not in ['sc','sCR','sCRD','nsCRD']:\n",
    "    raise ValueError(\"Unidentified Resampling Method\")\n",
    "\n",
    "\n",
    "  \n",
    "  # df['score'] = df['tags'].apply(lambda x: sum([ 0 if tag.startswith('O') else 1 for tag in x  ]) + 1)\n",
    "  \n",
    "  custom_sampled_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "  # for idx in range(len(df)):\n",
    "  #     num_samples = df.iloc[idx]['score']\n",
    "  #     sent = df.iloc[idx].to_dict()\n",
    "\n",
    "  #     for i in range(num_samples):\n",
    "  #     # Append the sampled subset to the list\n",
    "  #       sampled_data.append(sent)\n",
    "  #       # custom_sampled_df = pd.concat([custom_sampled_df, df.iloc[idx]], ignore_index=True, axis = 0)\n",
    "  # # Concatenate the sampled subsets to create the final upsampled DataFrame\n",
    "  # custom_sampled_df = pd.concat([custom_sampled_df, pd.DataFrame(sampled_data)], ignore_index=True)\n",
    "  \n",
    "  for sen in range(len(df)):\n",
    "    sampled_data = [] \n",
    "    # Resampling time can at least be 1, which means sentence without \n",
    "    # entity will be reserved in the dataset  \n",
    "    rsp_time = 1\n",
    "    sen_len = len(df.iloc[sen]['tags'])\n",
    "    ents = Counter([label[2:] for label in df.iloc[sen]['tags'] if label != 'O'])\n",
    "          # Pass if there's no entity in a sentence\n",
    "    \n",
    "    \n",
    "    if ents:\n",
    "      for ent in ents.keys():\n",
    "        # Resampling method selection and resampling time calculation, \n",
    "        # see section 'Resampling Functions' in our paper for details.\n",
    "        if method == 'sc':\n",
    "          rsp_time += ents[ent]\n",
    "        if method == 'sCR' or method == 'sCRD':\n",
    "          weight = -log(stats[ent],2)\n",
    "          rsp_time += ents[ent]*weight\n",
    "        if method == 'nsCRD':\n",
    "          weight = -log(stats[ent],2)\n",
    "          rsp_time += sqrt(ents[ent])*weight\n",
    "        if method == 'sCR':\n",
    "          rsp_time = sqrt(rsp_time)\n",
    "        if method == 'sCRD' or method == 'nsCRD':\n",
    "          rsp_time = rsp_time/sqrt(sen_len)\n",
    "      # Ceiling to ensure the integrity of resamling time\n",
    "      rsp_time = ceil(rsp_time) \n",
    "    \n",
    "    for t in range(rsp_time):\n",
    "      for token in range(sen_len):\n",
    "        sampled_data.append(df.iloc[sen].to_dict())\n",
    "\n",
    "\n",
    "    custom_sampled_df = pd.concat([custom_sampled_df, pd.DataFrame(sampled_data)], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  return custom_sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95286\n"
     ]
    }
   ],
   "source": [
    "# Use the custom sampling method\n",
    "sCR_df = custom_sampling_based_on_score(df_train_ori.copy(), 'sCR')\n",
    "\n",
    "# Check the distribution of scores in the custom sampled DataFrame\n",
    "# print(custom_sampled_df['entities_score'].value_counts())\n",
    "print(len(sCR_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform aspect type counts per each dataset split\n",
    "split2freqs = defaultdict(Counter)\n",
    "\n",
    "for row in df_train_ori[\"tags\"]:\n",
    "    for tag in row:\n",
    "        if tag.startswith(\"B\"):\n",
    "            tag_type = tag.split(\"-\")[1]\n",
    "        # split2freqs['train'][tag] += 1\n",
    "\n",
    "for row in sCR_df[\"tags\"]:\n",
    "    for tag in row:\n",
    "        if tag.startswith(\"B\"):\n",
    "            tag_type = tag.split(\"-\")[1]\n",
    "        # split2freqs['sCR_df'][tag] += 1\n",
    "                \n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 95286\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 911\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 2125\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 911\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'tags_idx', 'tags'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "scr_tds = Dataset.from_pandas(sCR_df[['tokens','tags_idx','tags']], features=ds['train'].features, preserve_index=False)\n",
    "\n",
    "scr_ds = copy.copy(ds)\n",
    "\n",
    "scr_ds['train'] = scr_tds\n",
    "\n",
    "\n",
    "print(scr_ds)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_ori['score'] = df_train_ori['tags'].apply(lambda x:sum([ 1 for tag in x if tag != 'O']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(df_train_ori))\n",
    "# print(len(df_train_ori[df_train_ori['score']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from random import randint\n",
    "# df_train_ori['select'] = df_train_ori['score'].apply(lambda x: randint(0,2) if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_sampled_df = df_train_ori[df_train_ori['select']==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in custom_sampled_df[\"tags\"]:\n",
    "#     for tag in row:\n",
    "#         # if tag.startswith(\"B\"):\n",
    "#         #     tag_type = tag.split(\"-\")[1]\n",
    "#         split2freqs['down_sample_1_3'][tag] += 1\n",
    "\n",
    "# pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_counts = pd.DataFrame.from_dict(split2freqs, orient=\"index\")\n",
    "\n",
    "# tag_counts['total_tag'] = tag_counts.sum(axis=1)\n",
    "# tag_counts['entity_ratio'] = tag_counts['O'] / tag_counts['total_tag']\n",
    "# tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. <a id='toc7_4_'></a>[Model tuning](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTuning:\n",
    "  def __init__(self, pretrained_model_name, index2tag, tag2index, y_validation=None, modelPerformanceLog=None):\n",
    "    \n",
    "    self.pretrained_model_name = pretrained_model_name\n",
    "    self.index2tag = index2tag\n",
    "    self.tag2index = tag2index\n",
    "\n",
    "    self.pretrained_model_config = AutoConfig.from_pretrained(pretrained_model_name, \n",
    "                                        num_labels=len(self.index2tag),\n",
    "                                        id2label=index2tag, label2id=tag2index)\n",
    "    \n",
    "    if modelPerformanceLog != None:\n",
    "      self.modelPerformanceLog = modelPerformanceLog\n",
    "    else:\n",
    "      self.modelPerformanceLog = ModelPerformanceLog(y_validation)\n",
    "\n",
    "  def model_init(self, architecture, loss_token_weights):\n",
    "    return (DistilBertForABSA\n",
    "            .from_pretrained(self.pretrained_model_name, config=self.pretrained_model_config, architecture=architecture, loss_token_weights=loss_token_weights)\n",
    "            .to(device))\n",
    "  \n",
    "  def align_predictions(self, predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                index2tag = self.pretrained_model_config.id2label.copy()\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list\n",
    "\n",
    "  # Define performance metrics\n",
    "  def compute_metrics(self, eval_pred):\n",
    "    y_pred, y_true = self.align_predictions(eval_pred.predictions, \n",
    "                                        eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred, average='macro')}\n",
    "\n",
    "  def forward_pass_with_label(self,data_collator, trainer, batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model  \n",
    "        output = trainer.model.to(device)(input_ids, attention_mask)\n",
    "\n",
    "        # Logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, tags.num_classes), \n",
    "                          labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}\n",
    "\n",
    "  def tokenize_and_align_labels(self, tokenizer, examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, \n",
    "                                      is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"tags_idx\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "  \n",
    "  def encode_dataset(self, tokenizer, corpus):\n",
    "    return corpus.map(lambda examples: self.tokenize_and_align_labels(tokenizer, examples), \n",
    "                      batched=True, \n",
    "                      remove_columns=['tags_idx', 'tokens','tags']\n",
    "                      )\n",
    "     \n",
    "  def fine_tune_model(self, ds, model_name, architecture, num_epochs=6, batch_size=32, weight_decay=0.01, loss_token_weights=None):\n",
    "\n",
    "    \n",
    "    # Define tokenizer\n",
    "    pretrained_tokenizer = AutoTokenizer.from_pretrained(self.pretrained_model_name)\n",
    "\n",
    "    # Define data collator for data batching \n",
    "    data_collator = DataCollatorForTokenClassification(pretrained_tokenizer)\n",
    "\n",
    "    ds_encoded = self.encode_dataset(pretrained_tokenizer, ds)\n",
    "\n",
    "    logging_steps = len(ds_encoded['train']) // batch_size\n",
    "    model_name_ = f\"{model_name}_{architecture}_e{num_epochs}_ld{re.sub(r'[^0-9]+','',str(weight_decay))}_b{batch_size}_w{'T' if len(loss_token_weights) > 0 else 'F'}\"\n",
    "    \n",
    "    print('Training model: ', model_name_)\n",
    "    training_args = TrainingArguments(output_dir=\"model/logs/\" + model_name_\n",
    "                                      ,log_level=\"error\"\n",
    "                                      ,num_train_epochs=num_epochs\n",
    "                                      ,per_device_train_batch_size=batch_size\n",
    "                                      ,per_device_eval_batch_size=batch_size\n",
    "                                      ,evaluation_strategy=\"epoch\"\n",
    "                                      ,save_steps=1e6\n",
    "                                      ,weight_decay=weight_decay\n",
    "                                      ,disable_tqdm=True\n",
    "                                      ,logging_steps=logging_steps\n",
    "                                      ,push_to_hub=False)\n",
    "    \n",
    "    trainer = Trainer(model_init=lambda: self.model_init(architecture, loss_token_weights)\n",
    "                      ,args=training_args\n",
    "                      ,data_collator=data_collator\n",
    "                      ,compute_metrics=self.compute_metrics\n",
    "                      ,train_dataset=ds_encoded[\"train\"]\n",
    "                      ,eval_dataset=ds_encoded[\"validation\"]\n",
    "                      ,tokenizer=pretrained_tokenizer)\n",
    "    \n",
    "    trainer.train()\n",
    "    # self.trainer = trainer\n",
    "\n",
    "    trainer_res_df = pd.DataFrame(trainer.state.log_history)[['epoch','loss' ,'eval_loss','eval_f1']]\n",
    "    trainer_res_df = trainer_res_df.rename(columns={\"epoch\":\"Epoch\",\"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", 'eval_f1':'F1'})\n",
    "    trainer_res_df['Epoch'] = trainer_res_df[\"Epoch\"].apply(lambda x: round(x))\n",
    "    trainer_res_df['Training Loss'] = trainer_res_df[\"Training Loss\"].ffill()\n",
    "    trainer_res_df[['Validation Loss', 'F1']] = trainer_res_df[['Validation Loss', 'F1']].bfill().ffill()\n",
    "    trainer_res_df = trainer_res_df.drop_duplicates()\n",
    "    self.modelPerformanceLog.add_bert_training_epoch_history(model_name_, trainer_res_df)\n",
    "\n",
    "    validation_set = ds_encoded[\"validation\"]\n",
    "    validation_set = validation_set.map(lambda batch: self.forward_pass_with_label(data_collator, trainer, batch), batched=True, batch_size=32)\n",
    "    df_validation = validation_set.to_pandas()\n",
    "\n",
    "    # Cleanup & conver id2text \n",
    "    index2tag = trainer.model.config.id2label.copy()\n",
    "    index2tag[-100] = \"IGN\"\n",
    "    df_validation[\"input_tokens\"] = df_validation[\"input_ids\"].apply(\n",
    "        lambda x: pretrained_tokenizer.convert_ids_to_tokens(x))\n",
    "    df_validation[\"predicted_label_txt\"] = df_validation[\"predicted_label\"].apply(\n",
    "        lambda x: [index2tag[i] for i in x])\n",
    "    df_validation[\"labels_txt\"] = df_validation[\"labels\"].apply(\n",
    "        lambda x: [index2tag[i] for i in x])\n",
    "    df_validation['loss'] = df_validation.apply(\n",
    "        lambda x: x['loss'][:len(x['input_ids'])], axis=1) # Remove padding tokens\n",
    "    df_validation['predicted_label'] = df_validation.apply(\n",
    "        lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1) # Remove padding tokens\n",
    "    df_validation['predicted_label_txt'] = df_validation.apply(\n",
    "        lambda x: x['predicted_label_txt'][:len(x['input_ids'])], axis=1) # Remove padding tokens\n",
    "    df_validation['labels_txt'] = df_validation.apply(\n",
    "        lambda x: x['labels_txt'][:len(x['input_ids'])], axis=1) # Remove padding tokens\n",
    "\n",
    "\n",
    "    # Flatten the outputs\n",
    "    df_tokens = df_validation.apply(pd.Series.explode)\n",
    "    df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "    df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "\n",
    "    df_validation_metrics = df_validation.copy()\n",
    "\n",
    "    df_validation_metrics['predicted_label_txt'] = df_validation_metrics.apply(lambda x: [x['predicted_label_txt'][i] for i,k in enumerate(x['labels_txt']) if k != 'IGN' ], axis=1)\n",
    "    df_validation_metrics[['input_tokens','predicted_label_txt']].to_csv('model/predictions/'+ model_name_ +'.csv')\n",
    "\n",
    "    self.modelPerformanceLog.add_model_performance(model_name_,df_validation_metrics['predicted_label_txt'])\n",
    "\n",
    "    trainer.save_model('model/saved/bert_'+ model_name_)\n",
    "    return model_name_, df_validation, df_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"distilbert-base-uncased\"\n",
    "tags = ds['train'].features['tags_idx'].feature\n",
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
    "\n",
    "y_val = ds['validation'].to_pandas()['tags_idx']\n",
    "y_val = [[index2tag[tag] for tag in sent] for sent in y_val]\n",
    "\n",
    "modelTuning = ModelTuning(pretrained_model_name, index2tag, tag2index, y_val, modelPerformanceLog)\n",
    "# modelTuning.modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenarios(model_idx, scenarios):\n",
    "  runtime = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "  \n",
    "  datasets = {'ori': ds\n",
    "            ,'down': downsample_ds\n",
    "            ,'scr': scr_ds\n",
    "            ,'batch_size': 64\n",
    "            }\n",
    "\n",
    "  for scenario in scenarios:\n",
    "    # Clear cache\n",
    "    torch.mps.empty_cache()\n",
    "    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0' # this setting is needed to run NN on my Mac\n",
    "    device = torch.device('mps') # This is required for Mac\n",
    "    \n",
    "    model_name_input = f\"sc_{model_idx}_ds_{scenario['dataset']}\"\n",
    "    print('Start training: ', model_name_input)\n",
    "    model_name, df_validation_predict, df_tokens_predict = modelTuning.fine_tune_model(datasets[scenario['dataset']], model_name_input, scenario['architecture'], scenario['epoch'],scenario['batch_size'],scenario['weight_decay'],[])\n",
    "    model_idx += 1\n",
    "\n",
    "  modelTuning.modelPerformanceLog.get_logs().to_csv(f'model/model_tuning_results_{runtime}.csv')  \n",
    "  modelTuning.modelPerformanceLog.bert_epoch_history.to_csv(f'model/bert_epoch_history_{runtime}.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4e08065fbd4f31b38dc98189f9b612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2125 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8b3208607944369c7b3f65f333ee79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6600aa58604ca384cbd4311ab9168d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  sc_1_ds_ori_linear_e15_ld01_b64_wF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4314, 'learning_rate': 4.6764705882352944e-05, 'epoch': 0.97}\n",
      "{'eval_loss': 0.23763501644134521, 'eval_f1': 0.13653438514583166, 'eval_runtime': 15.585, 'eval_samples_per_second': 58.454, 'eval_steps_per_second': 0.962, 'epoch': 1.0}\n",
      "{'loss': 0.168, 'learning_rate': 4.3529411764705885e-05, 'epoch': 1.94}\n",
      "{'eval_loss': 0.18244996666908264, 'eval_f1': 0.3100483046325188, 'eval_runtime': 16.0764, 'eval_samples_per_second': 56.667, 'eval_steps_per_second': 0.933, 'epoch': 2.0}\n",
      "{'loss': 0.113, 'learning_rate': 4.029411764705883e-05, 'epoch': 2.91}\n",
      "{'eval_loss': 0.16173210740089417, 'eval_f1': 0.37333183385814966, 'eval_runtime': 17.4929, 'eval_samples_per_second': 52.078, 'eval_steps_per_second': 0.857, 'epoch': 3.0}\n",
      "{'loss': 0.0716, 'learning_rate': 3.705882352941177e-05, 'epoch': 3.88}\n",
      "{'eval_loss': 0.15820477902889252, 'eval_f1': 0.4666225354205377, 'eval_runtime': 16.411, 'eval_samples_per_second': 55.511, 'eval_steps_per_second': 0.914, 'epoch': 4.0}\n",
      "{'loss': 0.0493, 'learning_rate': 3.382352941176471e-05, 'epoch': 4.85}\n",
      "{'eval_loss': 0.17056021094322205, 'eval_f1': 0.48755157863907206, 'eval_runtime': 16.4124, 'eval_samples_per_second': 55.507, 'eval_steps_per_second': 0.914, 'epoch': 5.0}\n",
      "{'loss': 0.0364, 'learning_rate': 3.058823529411765e-05, 'epoch': 5.82}\n",
      "{'eval_loss': 0.17509882152080536, 'eval_f1': 0.4915665697955866, 'eval_runtime': 15.4769, 'eval_samples_per_second': 58.862, 'eval_steps_per_second': 0.969, 'epoch': 6.0}\n",
      "{'loss': 0.0263, 'learning_rate': 2.7352941176470593e-05, 'epoch': 6.79}\n",
      "{'eval_loss': 0.18735186755657196, 'eval_f1': 0.4986733302129415, 'eval_runtime': 15.7126, 'eval_samples_per_second': 57.979, 'eval_steps_per_second': 0.955, 'epoch': 7.0}\n",
      "{'loss': 0.0183, 'learning_rate': 2.411764705882353e-05, 'epoch': 7.76}\n",
      "{'eval_loss': 0.20096077024936676, 'eval_f1': 0.4966023774068316, 'eval_runtime': 15.4282, 'eval_samples_per_second': 59.048, 'eval_steps_per_second': 0.972, 'epoch': 8.0}\n",
      "{'loss': 0.0144, 'learning_rate': 2.0882352941176472e-05, 'epoch': 8.74}\n",
      "{'eval_loss': 0.19647692143917084, 'eval_f1': 0.5121904087704362, 'eval_runtime': 15.4417, 'eval_samples_per_second': 58.996, 'eval_steps_per_second': 0.971, 'epoch': 9.0}\n",
      "{'loss': 0.0098, 'learning_rate': 1.7647058823529414e-05, 'epoch': 9.71}\n",
      "{'eval_loss': 0.20196205377578735, 'eval_f1': 0.504114506214385, 'eval_runtime': 15.442, 'eval_samples_per_second': 58.995, 'eval_steps_per_second': 0.971, 'epoch': 10.0}\n",
      "{'loss': 0.0084, 'learning_rate': 1.4411764705882352e-05, 'epoch': 10.68}\n",
      "{'eval_loss': 0.20701450109481812, 'eval_f1': 0.5037701654317038, 'eval_runtime': 15.1518, 'eval_samples_per_second': 60.125, 'eval_steps_per_second': 0.99, 'epoch': 11.0}\n",
      "{'loss': 0.0067, 'learning_rate': 1.1176470588235295e-05, 'epoch': 11.65}\n",
      "{'eval_loss': 0.20989778637886047, 'eval_f1': 0.5148179978321615, 'eval_runtime': 15.1866, 'eval_samples_per_second': 59.987, 'eval_steps_per_second': 0.988, 'epoch': 12.0}\n",
      "{'loss': 0.0056, 'learning_rate': 7.941176470588235e-06, 'epoch': 12.62}\n",
      "{'eval_loss': 0.2130459100008011, 'eval_f1': 0.5170734042628281, 'eval_runtime': 15.22, 'eval_samples_per_second': 59.855, 'eval_steps_per_second': 0.986, 'epoch': 13.0}\n",
      "{'loss': 0.005, 'learning_rate': 4.705882352941177e-06, 'epoch': 13.59}\n",
      "{'eval_loss': 0.21544702351093292, 'eval_f1': 0.5065733467911498, 'eval_runtime': 15.2286, 'eval_samples_per_second': 59.822, 'eval_steps_per_second': 0.985, 'epoch': 14.0}\n",
      "{'loss': 0.0051, 'learning_rate': 1.4705882352941177e-06, 'epoch': 14.56}\n",
      "{'eval_loss': 0.2161852866411209, 'eval_f1': 0.5027105177327887, 'eval_runtime': 15.1844, 'eval_samples_per_second': 59.996, 'eval_steps_per_second': 0.988, 'epoch': 15.0}\n",
      "{'train_runtime': 1887.7157, 'train_samples_per_second': 16.885, 'train_steps_per_second': 0.27, 'train_loss': 0.06285188644393987, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca62e11a0174f5285cb00c28204654e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runtime = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "model_idx = 1\n",
    "\n",
    "dataset = ds\n",
    "architecture = 'linear'\n",
    "epoch = 15\n",
    "batch_size = 64\n",
    "weight_decay = 0.1\n",
    "loss_weights = []\n",
    "\n",
    "# Clear cache\n",
    "torch.mps.empty_cache()\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0' # this setting is needed to run NN on my Mac\n",
    "device = torch.device('mps') # This is required for Mac\n",
    "\n",
    "model_name_input = f\"sc_{model_idx}_ds_ori\"\n",
    "model_name, df_validation_predict, df_tokens_predict = modelTuning.fine_tune_model(dataset, model_name_input, architecture, epoch,batch_size,weight_decay,loss_weights)\n",
    "\n",
    "modelTuning.modelPerformanceLog.get_logs().to_csv(f'model/model_tuning_results_{runtime}.csv')  \n",
    "modelTuning.modelPerformanceLog.bert_epoch_history.to_csv(f'model/bert_epoch_history_{runtime}.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn_f1_score</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crf</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_1_ds_ori_linear_e15_ld01_b64_wF</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.5338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sklearn_f1_score      f1\n",
       "random forest                                   0.14  0.0000\n",
       "crf                                             0.14  0.0000\n",
       "sc_1_ds_ori_linear_e15_ld01_b64_wF              0.60  0.5338"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTuning.modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4314</td>\n",
       "      <td>0.237635</td>\n",
       "      <td>0.136534</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.182450</td>\n",
       "      <td>0.310048</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.161732</td>\n",
       "      <td>0.373332</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.158205</td>\n",
       "      <td>0.466623</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.170560</td>\n",
       "      <td>0.487552</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.175099</td>\n",
       "      <td>0.491567</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.187352</td>\n",
       "      <td>0.498673</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.200961</td>\n",
       "      <td>0.496602</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.196477</td>\n",
       "      <td>0.512190</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.201962</td>\n",
       "      <td>0.504115</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.207015</td>\n",
       "      <td>0.503770</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.209898</td>\n",
       "      <td>0.514818</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.213046</td>\n",
       "      <td>0.517073</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.215447</td>\n",
       "      <td>0.506573</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.216185</td>\n",
       "      <td>0.502711</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Epoch  Training Loss  Validation Loss        F1  \\\n",
       "0       1         0.4314         0.237635  0.136534   \n",
       "2       2         0.1680         0.182450  0.310048   \n",
       "4       3         0.1130         0.161732  0.373332   \n",
       "6       4         0.0716         0.158205  0.466623   \n",
       "8       5         0.0493         0.170560  0.487552   \n",
       "10      6         0.0364         0.175099  0.491567   \n",
       "12      7         0.0263         0.187352  0.498673   \n",
       "14      8         0.0183         0.200961  0.496602   \n",
       "16      9         0.0144         0.196477  0.512190   \n",
       "18     10         0.0098         0.201962  0.504115   \n",
       "20     11         0.0084         0.207015  0.503770   \n",
       "22     12         0.0067         0.209898  0.514818   \n",
       "24     13         0.0056         0.213046  0.517073   \n",
       "26     14         0.0050         0.215447  0.506573   \n",
       "28     15         0.0051         0.216185  0.502711   \n",
       "\n",
       "                                 Model  \n",
       "0   sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "2   sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "4   sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "6   sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "8   sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "10  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "12  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "14  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "16  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "18  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "20  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "22  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "24  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "26  sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "28  sc_1_ds_ori_linear_e15_ld01_b64_wF  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTuning.modelPerformanceLog.bert_epoch_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. <a id='toc7_5_'></a>[Error analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1. <a id='toc7_5_1_'></a>[Group by word token](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "#     .agg([\"count\", \"mean\", \"sum\"])\n",
    "#     .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "#     .sort_values(by=\"sum\", ascending=False)\n",
    "#     .reset_index()\n",
    "#     .round(2)\n",
    "#     .head(10)\n",
    "#     .T\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#   df_tokens[df_tokens['input_tokens']=='battery'].groupby([\"predicted_label\", 'labels'])[[\"loss\"]]\n",
    "#     .agg([\"count\", \"mean\", \"sum\"])\n",
    "#     .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "#     .sort_values(by=\"sum\", ascending=False)\n",
    "#     .reset_index()\n",
    "#     .round(2)\n",
    "#     .head(10)\n",
    "#     .T\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2. <a id='toc7_5_2_'></a>[Group by Tag ID](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     df_tokens.groupby(\"labels\")[[\"loss\"]] \n",
    "#     .agg([\"count\", \"mean\", \"sum\"])\n",
    "#     .droplevel(level=0, axis=1)\n",
    "#     .sort_values(by=\"mean\", ascending=False)\n",
    "#     .reset_index()\n",
    "#     .round(2)\n",
    "#     .T\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "#     cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "#     fig, ax = plt.subplots(figsize=(6, 6))\n",
    "#     disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "#     disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "#     plt.title(\"Normalized confusion matrix\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"],\n",
    "#                       list(tag2index.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_samples(df):\n",
    "#     for _, row in df.iterrows():\n",
    "#         labels, preds, tokens, losses = [], [], [], []\n",
    "#         for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "#             if i not in {0, len(row[\"attention_mask\"])}:\n",
    "#                 labels.append(row[\"labels\"][i])\n",
    "#                 preds.append(row[\"predicted_label\"][i])\n",
    "#                 tokens.append(row[\"input_tokens\"][i])\n",
    "#                 losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "#         df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels, \n",
    "#                                \"preds\": preds, \"losses\": losses}).T\n",
    "#         yield df_tmp\n",
    "\n",
    "# df_validation[\"total_loss\"] = df_validation[\"loss\"].apply(sum)\n",
    "# df_tmp = df_validation.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "# for sample in get_samples(df_tmp):\n",
    "#     display(sample.T)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors could be from human / annotation errors: United Nations is ORG, not PER, similar to Central African Republic. This can happen as data was annotated using rule based, it is better with human annotations, but mistakes can always occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tmp = df_validation.loc[df_validation[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(2)\n",
    "# for sample in get_samples(df_tmp):\n",
    "#     display(sample.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:  sc_10_ds_down\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0125ef68106b4bd1a7163e974e988dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e145d91e8f46ab8f2a89e0267d5236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f1bf0ae35e410caab584c053dfdeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  sc_10_ds_down_linear_e15_ld01_b64_wF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.616, 'learning_rate': 4.681818181818182e-05, 'epoch': 0.95}\n",
      "{'eval_loss': 0.25522541999816895, 'eval_f1': 0.06150440123042863, 'eval_runtime': 15.1583, 'eval_samples_per_second': 60.099, 'eval_steps_per_second': 0.99, 'epoch': 1.0}\n",
      "{'loss': 0.2489, 'learning_rate': 4.3636363636363636e-05, 'epoch': 1.91}\n",
      "{'eval_loss': 0.19782713055610657, 'eval_f1': 0.23462517387580198, 'eval_runtime': 14.6496, 'eval_samples_per_second': 62.186, 'eval_steps_per_second': 1.024, 'epoch': 2.0}\n",
      "{'loss': 0.1772, 'learning_rate': 4.045454545454546e-05, 'epoch': 2.86}\n",
      "{'eval_loss': 0.1702330857515335, 'eval_f1': 0.3299829789035698, 'eval_runtime': 16.0862, 'eval_samples_per_second': 56.632, 'eval_steps_per_second': 0.932, 'epoch': 3.0}\n",
      "{'loss': 0.1229, 'learning_rate': 3.7272727272727276e-05, 'epoch': 3.82}\n",
      "{'eval_loss': 0.15534688532352448, 'eval_f1': 0.4139983871257707, 'eval_runtime': 14.5215, 'eval_samples_per_second': 62.734, 'eval_steps_per_second': 1.033, 'epoch': 4.0}\n",
      "{'loss': 0.0871, 'learning_rate': 3.409090909090909e-05, 'epoch': 4.77}\n",
      "{'eval_loss': 0.17143703997135162, 'eval_f1': 0.43924233314553124, 'eval_runtime': 15.4405, 'eval_samples_per_second': 59.001, 'eval_steps_per_second': 0.971, 'epoch': 5.0}\n",
      "{'loss': 0.0685, 'learning_rate': 3.090909090909091e-05, 'epoch': 5.73}\n",
      "{'eval_loss': 0.16841894388198853, 'eval_f1': 0.48772441153650115, 'eval_runtime': 14.7082, 'eval_samples_per_second': 61.938, 'eval_steps_per_second': 1.02, 'epoch': 6.0}\n",
      "{'loss': 0.0442, 'learning_rate': 2.772727272727273e-05, 'epoch': 6.68}\n",
      "{'eval_loss': 0.18032605946063995, 'eval_f1': 0.4948340082668441, 'eval_runtime': 16.0191, 'eval_samples_per_second': 56.87, 'eval_steps_per_second': 0.936, 'epoch': 7.0}\n",
      "{'loss': 0.0346, 'learning_rate': 2.4545454545454545e-05, 'epoch': 7.64}\n",
      "{'eval_loss': 0.18285176157951355, 'eval_f1': 0.5085232325228374, 'eval_runtime': 14.7238, 'eval_samples_per_second': 61.872, 'eval_steps_per_second': 1.019, 'epoch': 8.0}\n",
      "{'loss': 0.0284, 'learning_rate': 2.1363636363636362e-05, 'epoch': 8.59}\n",
      "{'eval_loss': 0.18825744092464447, 'eval_f1': 0.5082256199277476, 'eval_runtime': 15.79, 'eval_samples_per_second': 57.695, 'eval_steps_per_second': 0.95, 'epoch': 9.0}\n",
      "{'loss': 0.021, 'learning_rate': 1.8181818181818182e-05, 'epoch': 9.55}\n",
      "{'eval_loss': 0.19529546797275543, 'eval_f1': 0.511229289454804, 'eval_runtime': 15.1763, 'eval_samples_per_second': 60.028, 'eval_steps_per_second': 0.988, 'epoch': 10.0}\n",
      "{'loss': 0.0156, 'learning_rate': 1.5e-05, 'epoch': 10.5}\n",
      "{'eval_loss': 0.20448525249958038, 'eval_f1': 0.5169270093266428, 'eval_runtime': 14.7616, 'eval_samples_per_second': 61.714, 'eval_steps_per_second': 1.016, 'epoch': 11.0}\n",
      "{'loss': 0.0141, 'learning_rate': 1.1818181818181819e-05, 'epoch': 11.45}\n",
      "{'eval_loss': 0.2017410695552826, 'eval_f1': 0.5113774525604954, 'eval_runtime': 14.6076, 'eval_samples_per_second': 62.365, 'eval_steps_per_second': 1.027, 'epoch': 12.0}\n",
      "{'loss': 0.0114, 'learning_rate': 8.636363636363637e-06, 'epoch': 12.41}\n",
      "{'eval_loss': 0.2025163173675537, 'eval_f1': 0.5129017289368035, 'eval_runtime': 14.6033, 'eval_samples_per_second': 62.383, 'eval_steps_per_second': 1.027, 'epoch': 13.0}\n",
      "{'loss': 0.0099, 'learning_rate': 5.4545454545454545e-06, 'epoch': 13.36}\n",
      "{'eval_loss': 0.20554471015930176, 'eval_f1': 0.5177121497093299, 'eval_runtime': 15.9717, 'eval_samples_per_second': 57.038, 'eval_steps_per_second': 0.939, 'epoch': 14.0}\n",
      "{'loss': 0.0094, 'learning_rate': 2.2727272727272728e-06, 'epoch': 14.32}\n",
      "{'eval_loss': 0.2055848240852356, 'eval_f1': 0.5163385747859072, 'eval_runtime': 14.4483, 'eval_samples_per_second': 63.053, 'eval_steps_per_second': 1.038, 'epoch': 15.0}\n",
      "{'train_runtime': 1323.787, 'train_samples_per_second': 15.66, 'train_steps_per_second': 0.249, 'train_loss': 0.0964486740303762, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98039a6d997548718c4291dae49e7fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:  sc_11_ds_scr\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b3c8fd454849d18cd2b8cc651d8198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/95286 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e15de917d148f0af28a088f2e468c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f96b9a9a81f4203a0463ac4a774b302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  sc_11_ds_scr_linear_e15_ld01_b64_wF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0204, 'learning_rate': 4.6668905305574214e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 0.31874021887779236, 'eval_f1': 0.4706011739540095, 'eval_runtime': 14.4768, 'eval_samples_per_second': 62.928, 'eval_steps_per_second': 1.036, 'epoch': 1.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 25\u001b[0m\n\u001b[1;32m      1\u001b[0m model_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m scenarios \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;66;03m# {'dataset': 'ori'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m             \u001b[38;5;66;03m#  ,'epoch': 15\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m             }\n\u001b[1;32m     23\u001b[0m             ]\n\u001b[0;32m---> 25\u001b[0m \u001b[43mrun_scenarios\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenarios\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m modelTuning\u001b[38;5;241m.\u001b[39mmodelPerformanceLog\u001b[38;5;241m.\u001b[39mget_logs()\n",
      "Cell \u001b[0;32mIn[56], line 18\u001b[0m, in \u001b[0;36mrun_scenarios\u001b[0;34m(model_idx, scenarios)\u001b[0m\n\u001b[1;32m     16\u001b[0m   model_name_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msc_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_ds_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscenario[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart training: \u001b[39m\u001b[38;5;124m'\u001b[39m, model_name_input)\n\u001b[0;32m---> 18\u001b[0m   model_name, df_validation_predict, df_tokens_predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodelTuning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marchitecture\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m   model_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     21\u001b[0m modelTuning\u001b[38;5;241m.\u001b[39mmodelPerformanceLog\u001b[38;5;241m.\u001b[39mget_logs()\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel/model_tuning_results_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruntime\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n",
      "Cell \u001b[0;32mIn[54], line 130\u001b[0m, in \u001b[0;36mModelTuning.fine_tune_model\u001b[0;34m(self, ds, model_name, architecture, num_epochs, batch_size, weight_decay, loss_token_weights)\u001b[0m\n\u001b[1;32m    110\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/logs/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_\n\u001b[1;32m    111\u001b[0m                                   ,log_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m                                   ,num_train_epochs\u001b[38;5;241m=\u001b[39mnum_epochs\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                   ,logging_steps\u001b[38;5;241m=\u001b[39mlogging_steps\n\u001b[1;32m    120\u001b[0m                                   ,push_to_hub\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_init(architecture, loss_token_weights)\n\u001b[1;32m    123\u001b[0m                   ,args\u001b[38;5;241m=\u001b[39mtraining_args\n\u001b[1;32m    124\u001b[0m                   ,data_collator\u001b[38;5;241m=\u001b[39mdata_collator\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m                   ,eval_dataset\u001b[38;5;241m=\u001b[39mds_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    128\u001b[0m                   ,tokenizer\u001b[38;5;241m=\u001b[39mpretrained_tokenizer)\n\u001b[0;32m--> 130\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# self.trainer = trainer\u001b[39;00m\n\u001b[1;32m    133\u001b[0m trainer_res_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlog_history)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1630\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1631\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1632\u001b[0m )\n\u001b[0;32m-> 1633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1900\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1901\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1905\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1906\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1907\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1908\u001b[0m ):\n\u001b[1;32m   1909\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1910\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/trainer.py:2663\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2661\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[1;32m   2662\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2663\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_idx = 10\n",
    "scenarios = [\n",
    "            # {'dataset': 'ori'\n",
    "            #  ,'epoch': 15\n",
    "            #  ,'architecture': 'linear'\n",
    "            #  ,'weight_decay': 0.1\n",
    "            #  ,'batch_size': 64\n",
    "            # }\n",
    "            \n",
    "            {'dataset': 'down'\n",
    "             ,'epoch': 15\n",
    "             ,'architecture': 'linear'\n",
    "             ,'weight_decay': 0.1\n",
    "             ,'batch_size': 64\n",
    "            }\n",
    "\n",
    "            # ,{'dataset': 'scr'\n",
    "            #  ,'epoch': 15\n",
    "            #  ,'architecture': 'linear'\n",
    "            #  ,'weight_decay': 0.1\n",
    "            #  ,'batch_size': 64\n",
    "            # }\n",
    "            ]\n",
    "\n",
    "run_scenarios(model_idx, scenarios)\n",
    "modelTuning.modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ds = 'down' # 'scr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:  sc_10000_ds_down\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068c4042dd754bd5854871ba87e00e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920c0f8e77a54fde88304acf46641d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6cfa7aadc646589f826d1a68013c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  sc_10000_ds_down_additional_linear_e150_ld01_b64_wF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6377, 'learning_rate': 4.968181818181818e-05, 'epoch': 0.95}\n",
      "{'eval_loss': 1.379583477973938, 'eval_f1': 0.0, 'eval_runtime': 14.6425, 'eval_samples_per_second': 62.216, 'eval_steps_per_second': 1.024, 'epoch': 1.0}\n",
      "{'loss': 1.3649, 'learning_rate': 4.936363636363637e-05, 'epoch': 1.91}\n",
      "{'eval_loss': 1.2475454807281494, 'eval_f1': 0.0, 'eval_runtime': 16.0435, 'eval_samples_per_second': 56.783, 'eval_steps_per_second': 0.935, 'epoch': 2.0}\n",
      "{'loss': 1.2707, 'learning_rate': 4.904545454545455e-05, 'epoch': 2.86}\n",
      "{'eval_loss': 1.142648458480835, 'eval_f1': 0.0, 'eval_runtime': 14.5504, 'eval_samples_per_second': 62.61, 'eval_steps_per_second': 1.031, 'epoch': 3.0}\n",
      "{'loss': 1.1788, 'learning_rate': 4.872727272727273e-05, 'epoch': 3.82}\n",
      "{'eval_loss': 1.0339782238006592, 'eval_f1': 0.0, 'eval_runtime': 15.3201, 'eval_samples_per_second': 59.464, 'eval_steps_per_second': 0.979, 'epoch': 4.0}\n",
      "{'loss': 1.0846, 'learning_rate': 4.840909090909091e-05, 'epoch': 4.77}\n",
      "{'eval_loss': 0.9249370694160461, 'eval_f1': 0.0, 'eval_runtime': 15.1492, 'eval_samples_per_second': 60.135, 'eval_steps_per_second': 0.99, 'epoch': 5.0}\n",
      "{'loss': 0.9945, 'learning_rate': 4.8090909090909094e-05, 'epoch': 5.73}\n",
      "{'eval_loss': 0.8180984258651733, 'eval_f1': 0.0, 'eval_runtime': 15.7321, 'eval_samples_per_second': 57.907, 'eval_steps_per_second': 0.953, 'epoch': 6.0}\n",
      "{'loss': 0.9017, 'learning_rate': 4.777272727272727e-05, 'epoch': 6.68}\n",
      "{'eval_loss': 0.7188425660133362, 'eval_f1': 0.0, 'eval_runtime': 15.4045, 'eval_samples_per_second': 59.138, 'eval_steps_per_second': 0.974, 'epoch': 7.0}\n",
      "{'loss': 0.8266, 'learning_rate': 4.745454545454546e-05, 'epoch': 7.64}\n",
      "{'eval_loss': 0.6305903196334839, 'eval_f1': 0.0, 'eval_runtime': 15.4331, 'eval_samples_per_second': 59.029, 'eval_steps_per_second': 0.972, 'epoch': 8.0}\n",
      "{'loss': 0.7487, 'learning_rate': 4.713636363636364e-05, 'epoch': 8.59}\n",
      "{'eval_loss': 0.5571046471595764, 'eval_f1': 0.0, 'eval_runtime': 15.1754, 'eval_samples_per_second': 60.031, 'eval_steps_per_second': 0.988, 'epoch': 9.0}\n",
      "{'loss': 0.6959, 'learning_rate': 4.681818181818182e-05, 'epoch': 9.55}\n",
      "{'eval_loss': 0.49945303797721863, 'eval_f1': 0.0, 'eval_runtime': 15.1849, 'eval_samples_per_second': 59.994, 'eval_steps_per_second': 0.988, 'epoch': 10.0}\n",
      "{'loss': 0.6445, 'learning_rate': 4.6500000000000005e-05, 'epoch': 10.5}\n",
      "{'eval_loss': 0.45833081007003784, 'eval_f1': 0.0, 'eval_runtime': 14.7045, 'eval_samples_per_second': 61.954, 'eval_steps_per_second': 1.02, 'epoch': 11.0}\n",
      "{'loss': 0.6179, 'learning_rate': 4.618181818181818e-05, 'epoch': 11.45}\n",
      "{'eval_loss': 0.4324904680252075, 'eval_f1': 0.0, 'eval_runtime': 15.3167, 'eval_samples_per_second': 59.478, 'eval_steps_per_second': 0.979, 'epoch': 12.0}\n",
      "{'loss': 0.5691, 'learning_rate': 4.5863636363636365e-05, 'epoch': 12.41}\n",
      "{'eval_loss': 0.4202025234699249, 'eval_f1': 0.0, 'eval_runtime': 15.8564, 'eval_samples_per_second': 57.453, 'eval_steps_per_second': 0.946, 'epoch': 13.0}\n",
      "{'loss': 0.573, 'learning_rate': 4.5545454545454544e-05, 'epoch': 13.36}\n",
      "{'eval_loss': 0.363552987575531, 'eval_f1': 0.0, 'eval_runtime': 14.7977, 'eval_samples_per_second': 61.564, 'eval_steps_per_second': 1.014, 'epoch': 14.0}\n",
      "{'loss': 0.5147, 'learning_rate': 4.522727272727273e-05, 'epoch': 14.32}\n",
      "{'eval_loss': 0.2705744802951813, 'eval_f1': 0.06201550387596899, 'eval_runtime': 14.5914, 'eval_samples_per_second': 62.434, 'eval_steps_per_second': 1.028, 'epoch': 15.0}\n",
      "{'loss': 0.3884, 'learning_rate': 4.490909090909091e-05, 'epoch': 15.27}\n",
      "{'eval_loss': 0.24935373663902283, 'eval_f1': 0.08339393939393941, 'eval_runtime': 14.773, 'eval_samples_per_second': 61.667, 'eval_steps_per_second': 1.015, 'epoch': 16.0}\n",
      "{'loss': 0.3364, 'learning_rate': 4.45909090909091e-05, 'epoch': 16.23}\n",
      "{'eval_loss': 0.23240886628627777, 'eval_f1': 0.08333333333333333, 'eval_runtime': 16.3671, 'eval_samples_per_second': 55.66, 'eval_steps_per_second': 0.916, 'epoch': 17.0}\n",
      "{'loss': 0.2992, 'learning_rate': 4.4272727272727276e-05, 'epoch': 17.18}\n",
      "{'eval_loss': 0.23456892371177673, 'eval_f1': 0.0826001955034213, 'eval_runtime': 14.8244, 'eval_samples_per_second': 61.453, 'eval_steps_per_second': 1.012, 'epoch': 18.0}\n",
      "{'loss': 0.2628, 'learning_rate': 4.3954545454545456e-05, 'epoch': 18.14}\n",
      "{'eval_loss': 0.23157165944576263, 'eval_f1': 0.08191463113742907, 'eval_runtime': 14.7456, 'eval_samples_per_second': 61.781, 'eval_steps_per_second': 1.017, 'epoch': 19.0}\n",
      "{'loss': 0.2436, 'learning_rate': 4.3636363636363636e-05, 'epoch': 19.09}\n",
      "{'eval_loss': 0.24840417504310608, 'eval_f1': 0.09594377816820716, 'eval_runtime': 14.6714, 'eval_samples_per_second': 62.094, 'eval_steps_per_second': 1.022, 'epoch': 20.0}\n",
      "{'loss': 0.2311, 'learning_rate': 4.331818181818182e-05, 'epoch': 20.05}\n",
      "{'loss': 0.2155, 'learning_rate': 4.3e-05, 'epoch': 21.0}\n",
      "{'eval_loss': 0.24941611289978027, 'eval_f1': 0.09972371869210471, 'eval_runtime': 16.496, 'eval_samples_per_second': 55.225, 'eval_steps_per_second': 0.909, 'epoch': 21.0}\n",
      "{'loss': 0.2044, 'learning_rate': 4.268181818181818e-05, 'epoch': 21.95}\n",
      "{'eval_loss': 0.2459583282470703, 'eval_f1': 0.1127767569397602, 'eval_runtime': 14.76, 'eval_samples_per_second': 61.721, 'eval_steps_per_second': 1.016, 'epoch': 22.0}\n",
      "{'loss': 0.1961, 'learning_rate': 4.236363636363637e-05, 'epoch': 22.91}\n",
      "{'eval_loss': 0.23702001571655273, 'eval_f1': 0.16219697053524, 'eval_runtime': 14.9073, 'eval_samples_per_second': 61.111, 'eval_steps_per_second': 1.006, 'epoch': 23.0}\n",
      "{'loss': 0.188, 'learning_rate': 4.204545454545455e-05, 'epoch': 23.86}\n",
      "{'eval_loss': 0.23518623411655426, 'eval_f1': 0.20935682477596193, 'eval_runtime': 14.7564, 'eval_samples_per_second': 61.736, 'eval_steps_per_second': 1.017, 'epoch': 24.0}\n",
      "{'loss': 0.1813, 'learning_rate': 4.1727272727272734e-05, 'epoch': 24.82}\n",
      "{'eval_loss': 0.2275211215019226, 'eval_f1': 0.2361127204534829, 'eval_runtime': 16.5412, 'eval_samples_per_second': 55.075, 'eval_steps_per_second': 0.907, 'epoch': 25.0}\n",
      "{'loss': 0.1758, 'learning_rate': 4.1409090909090907e-05, 'epoch': 25.77}\n",
      "{'eval_loss': 0.2457556426525116, 'eval_f1': 0.23294279262835463, 'eval_runtime': 14.6688, 'eval_samples_per_second': 62.105, 'eval_steps_per_second': 1.023, 'epoch': 26.0}\n",
      "{'loss': 0.1726, 'learning_rate': 4.109090909090909e-05, 'epoch': 26.73}\n",
      "{'eval_loss': 0.243685781955719, 'eval_f1': 0.24689604577765034, 'eval_runtime': 15.4571, 'eval_samples_per_second': 58.937, 'eval_steps_per_second': 0.97, 'epoch': 27.0}\n",
      "{'loss': 0.1678, 'learning_rate': 4.077272727272727e-05, 'epoch': 27.68}\n",
      "{'eval_loss': 0.2423262745141983, 'eval_f1': 0.2546551793886383, 'eval_runtime': 14.8737, 'eval_samples_per_second': 61.249, 'eval_steps_per_second': 1.008, 'epoch': 28.0}\n",
      "{'loss': 0.1603, 'learning_rate': 4.045454545454546e-05, 'epoch': 28.64}\n",
      "{'eval_loss': 0.2492143213748932, 'eval_f1': 0.2430785591942122, 'eval_runtime': 16.6151, 'eval_samples_per_second': 54.83, 'eval_steps_per_second': 0.903, 'epoch': 29.0}\n",
      "{'loss': 0.1537, 'learning_rate': 4.013636363636364e-05, 'epoch': 29.59}\n",
      "{'eval_loss': 0.24871976673603058, 'eval_f1': 0.24994787038166044, 'eval_runtime': 14.9631, 'eval_samples_per_second': 60.883, 'eval_steps_per_second': 1.002, 'epoch': 30.0}\n",
      "{'loss': 0.1583, 'learning_rate': 3.981818181818182e-05, 'epoch': 30.55}\n",
      "{'eval_loss': 0.25213250517845154, 'eval_f1': 0.2977280900800993, 'eval_runtime': 15.5946, 'eval_samples_per_second': 58.418, 'eval_steps_per_second': 0.962, 'epoch': 31.0}\n",
      "{'loss': 0.152, 'learning_rate': 3.9500000000000005e-05, 'epoch': 31.5}\n",
      "{'eval_loss': 0.2503340542316437, 'eval_f1': 0.2962111704842781, 'eval_runtime': 14.9161, 'eval_samples_per_second': 61.075, 'eval_steps_per_second': 1.006, 'epoch': 32.0}\n",
      "{'loss': 0.1423, 'learning_rate': 3.9181818181818184e-05, 'epoch': 32.45}\n",
      "{'eval_loss': 0.2502564489841461, 'eval_f1': 0.3137113429857909, 'eval_runtime': 15.382, 'eval_samples_per_second': 59.225, 'eval_steps_per_second': 0.975, 'epoch': 33.0}\n",
      "{'loss': 0.149, 'learning_rate': 3.8863636363636364e-05, 'epoch': 33.41}\n",
      "{'eval_loss': 0.24272532761096954, 'eval_f1': 0.3502720001801436, 'eval_runtime': 14.7488, 'eval_samples_per_second': 61.768, 'eval_steps_per_second': 1.017, 'epoch': 34.0}\n",
      "{'loss': 0.1339, 'learning_rate': 3.8545454545454544e-05, 'epoch': 34.36}\n",
      "{'eval_loss': 0.24533964693546295, 'eval_f1': 0.3847405015101522, 'eval_runtime': 15.5433, 'eval_samples_per_second': 58.611, 'eval_steps_per_second': 0.965, 'epoch': 35.0}\n",
      "{'loss': 0.1382, 'learning_rate': 3.822727272727273e-05, 'epoch': 35.32}\n",
      "{'eval_loss': 0.24652311205863953, 'eval_f1': 0.36441531799624566, 'eval_runtime': 14.7871, 'eval_samples_per_second': 61.608, 'eval_steps_per_second': 1.014, 'epoch': 36.0}\n",
      "{'loss': 0.1328, 'learning_rate': 3.790909090909091e-05, 'epoch': 36.27}\n",
      "{'eval_loss': 0.25680381059646606, 'eval_f1': 0.3710388503227378, 'eval_runtime': 14.9047, 'eval_samples_per_second': 61.122, 'eval_steps_per_second': 1.006, 'epoch': 37.0}\n",
      "{'loss': 0.1279, 'learning_rate': 3.7590909090909096e-05, 'epoch': 37.23}\n",
      "{'eval_loss': 0.2727820575237274, 'eval_f1': 0.32068503359009193, 'eval_runtime': 16.3304, 'eval_samples_per_second': 55.785, 'eval_steps_per_second': 0.919, 'epoch': 38.0}\n",
      "{'loss': 0.1285, 'learning_rate': 3.7272727272727276e-05, 'epoch': 38.18}\n",
      "{'eval_loss': 0.2570798397064209, 'eval_f1': 0.39010205704915624, 'eval_runtime': 14.9759, 'eval_samples_per_second': 60.831, 'eval_steps_per_second': 1.002, 'epoch': 39.0}\n",
      "{'loss': 0.1287, 'learning_rate': 3.6954545454545455e-05, 'epoch': 39.14}\n",
      "{'eval_loss': 0.25796079635620117, 'eval_f1': 0.37512478673173827, 'eval_runtime': 15.2173, 'eval_samples_per_second': 59.866, 'eval_steps_per_second': 0.986, 'epoch': 40.0}\n",
      "{'loss': 0.118, 'learning_rate': 3.663636363636364e-05, 'epoch': 40.09}\n",
      "{'eval_loss': 0.26985442638397217, 'eval_f1': 0.38025908858166924, 'eval_runtime': 14.9386, 'eval_samples_per_second': 60.983, 'eval_steps_per_second': 1.004, 'epoch': 41.0}\n",
      "{'loss': 0.123, 'learning_rate': 3.6318181818181815e-05, 'epoch': 41.05}\n",
      "{'loss': 0.1137, 'learning_rate': 3.6e-05, 'epoch': 42.0}\n",
      "{'eval_loss': 0.26772308349609375, 'eval_f1': 0.37508775604350153, 'eval_runtime': 14.7812, 'eval_samples_per_second': 61.632, 'eval_steps_per_second': 1.015, 'epoch': 42.0}\n",
      "{'loss': 0.1158, 'learning_rate': 3.568181818181818e-05, 'epoch': 42.95}\n",
      "{'eval_loss': 0.2575368285179138, 'eval_f1': 0.37407821949545617, 'eval_runtime': 14.8258, 'eval_samples_per_second': 61.447, 'eval_steps_per_second': 1.012, 'epoch': 43.0}\n",
      "{'loss': 0.1103, 'learning_rate': 3.536363636363637e-05, 'epoch': 43.91}\n",
      "{'eval_loss': 0.2705046534538269, 'eval_f1': 0.38807061211137334, 'eval_runtime': 15.4425, 'eval_samples_per_second': 58.993, 'eval_steps_per_second': 0.971, 'epoch': 44.0}\n",
      "{'loss': 0.1109, 'learning_rate': 3.5045454545454547e-05, 'epoch': 44.86}\n",
      "{'eval_loss': 0.2618546187877655, 'eval_f1': 0.43817004530987874, 'eval_runtime': 14.7949, 'eval_samples_per_second': 61.575, 'eval_steps_per_second': 1.014, 'epoch': 45.0}\n",
      "{'loss': 0.1052, 'learning_rate': 3.472727272727273e-05, 'epoch': 45.82}\n",
      "{'eval_loss': 0.2659377455711365, 'eval_f1': 0.444291697532623, 'eval_runtime': 14.7137, 'eval_samples_per_second': 61.915, 'eval_steps_per_second': 1.019, 'epoch': 46.0}\n",
      "{'loss': 0.1082, 'learning_rate': 3.440909090909091e-05, 'epoch': 46.77}\n",
      "{'eval_loss': 0.2652004361152649, 'eval_f1': 0.4428793692465627, 'eval_runtime': 14.8537, 'eval_samples_per_second': 61.332, 'eval_steps_per_second': 1.01, 'epoch': 47.0}\n",
      "{'loss': 0.1057, 'learning_rate': 3.409090909090909e-05, 'epoch': 47.73}\n",
      "{'eval_loss': 0.2697581350803375, 'eval_f1': 0.43324003546389384, 'eval_runtime': 16.3305, 'eval_samples_per_second': 55.785, 'eval_steps_per_second': 0.919, 'epoch': 48.0}\n",
      "{'loss': 0.0993, 'learning_rate': 3.377272727272727e-05, 'epoch': 48.68}\n",
      "{'eval_loss': 0.2770029604434967, 'eval_f1': 0.42698847259391615, 'eval_runtime': 14.8825, 'eval_samples_per_second': 61.213, 'eval_steps_per_second': 1.008, 'epoch': 49.0}\n",
      "{'loss': 0.1029, 'learning_rate': 3.345454545454546e-05, 'epoch': 49.64}\n",
      "{'eval_loss': 0.27157995104789734, 'eval_f1': 0.4363888409894116, 'eval_runtime': 15.2567, 'eval_samples_per_second': 59.711, 'eval_steps_per_second': 0.983, 'epoch': 50.0}\n",
      "{'loss': 0.0987, 'learning_rate': 3.313636363636364e-05, 'epoch': 50.59}\n",
      "{'eval_loss': 0.2699744999408722, 'eval_f1': 0.445998553801575, 'eval_runtime': 14.9737, 'eval_samples_per_second': 60.84, 'eval_steps_per_second': 1.002, 'epoch': 51.0}\n",
      "{'loss': 0.0983, 'learning_rate': 3.281818181818182e-05, 'epoch': 51.55}\n",
      "{'eval_loss': 0.2705852687358856, 'eval_f1': 0.42335938918896504, 'eval_runtime': 16.5418, 'eval_samples_per_second': 55.073, 'eval_steps_per_second': 0.907, 'epoch': 52.0}\n",
      "{'loss': 0.0958, 'learning_rate': 3.2500000000000004e-05, 'epoch': 52.5}\n",
      "{'eval_loss': 0.2722127437591553, 'eval_f1': 0.42997765937545385, 'eval_runtime': 14.7343, 'eval_samples_per_second': 61.828, 'eval_steps_per_second': 1.018, 'epoch': 53.0}\n",
      "{'loss': 0.0918, 'learning_rate': 3.2181818181818184e-05, 'epoch': 53.45}\n",
      "{'eval_loss': 0.27305349707603455, 'eval_f1': 0.4722412924660791, 'eval_runtime': 15.417, 'eval_samples_per_second': 59.091, 'eval_steps_per_second': 0.973, 'epoch': 54.0}\n",
      "{'loss': 0.0922, 'learning_rate': 3.186363636363637e-05, 'epoch': 54.41}\n",
      "{'eval_loss': 0.2764967679977417, 'eval_f1': 0.43249080945783214, 'eval_runtime': 14.6945, 'eval_samples_per_second': 61.996, 'eval_steps_per_second': 1.021, 'epoch': 55.0}\n",
      "{'loss': 0.0915, 'learning_rate': 3.154545454545454e-05, 'epoch': 55.36}\n",
      "{'eval_loss': 0.2815723419189453, 'eval_f1': 0.42188522675384094, 'eval_runtime': 16.3351, 'eval_samples_per_second': 55.77, 'eval_steps_per_second': 0.918, 'epoch': 56.0}\n",
      "{'loss': 0.087, 'learning_rate': 3.122727272727273e-05, 'epoch': 56.32}\n",
      "{'eval_loss': 0.27624234557151794, 'eval_f1': 0.4540918618874952, 'eval_runtime': 14.6945, 'eval_samples_per_second': 61.996, 'eval_steps_per_second': 1.021, 'epoch': 57.0}\n",
      "{'loss': 0.0919, 'learning_rate': 3.090909090909091e-05, 'epoch': 57.27}\n",
      "{'eval_loss': 0.27750900387763977, 'eval_f1': 0.4689004963454133, 'eval_runtime': 16.3363, 'eval_samples_per_second': 55.765, 'eval_steps_per_second': 0.918, 'epoch': 58.0}\n",
      "{'loss': 0.0836, 'learning_rate': 3.0590909090909095e-05, 'epoch': 58.23}\n",
      "{'eval_loss': 0.2777675688266754, 'eval_f1': 0.4496940020164844, 'eval_runtime': 14.7797, 'eval_samples_per_second': 61.639, 'eval_steps_per_second': 1.015, 'epoch': 59.0}\n",
      "{'loss': 0.0855, 'learning_rate': 3.0272727272727275e-05, 'epoch': 59.18}\n",
      "{'eval_loss': 0.28446316719055176, 'eval_f1': 0.4558878107827032, 'eval_runtime': 16.1598, 'eval_samples_per_second': 56.374, 'eval_steps_per_second': 0.928, 'epoch': 60.0}\n",
      "{'loss': 0.0816, 'learning_rate': 2.9954545454545458e-05, 'epoch': 60.14}\n",
      "{'eval_loss': 0.2885277271270752, 'eval_f1': 0.44985851688617134, 'eval_runtime': 14.6389, 'eval_samples_per_second': 62.231, 'eval_steps_per_second': 1.025, 'epoch': 61.0}\n",
      "{'loss': 0.0852, 'learning_rate': 2.963636363636364e-05, 'epoch': 61.09}\n",
      "{'eval_loss': 0.30440330505371094, 'eval_f1': 0.4624116636301055, 'eval_runtime': 16.0825, 'eval_samples_per_second': 56.645, 'eval_steps_per_second': 0.933, 'epoch': 62.0}\n",
      "{'loss': 0.0786, 'learning_rate': 2.9318181818181817e-05, 'epoch': 62.05}\n",
      "{'loss': 0.0806, 'learning_rate': 2.9e-05, 'epoch': 63.0}\n",
      "{'eval_loss': 0.3028944432735443, 'eval_f1': 0.44951410474733505, 'eval_runtime': 14.8481, 'eval_samples_per_second': 61.355, 'eval_steps_per_second': 1.01, 'epoch': 63.0}\n",
      "{'loss': 0.0814, 'learning_rate': 2.8681818181818183e-05, 'epoch': 63.95}\n",
      "{'eval_loss': 0.29545149207115173, 'eval_f1': 0.4501541481212737, 'eval_runtime': 16.171, 'eval_samples_per_second': 56.335, 'eval_steps_per_second': 0.928, 'epoch': 64.0}\n",
      "{'loss': 0.0791, 'learning_rate': 2.8363636363636363e-05, 'epoch': 64.91}\n",
      "{'eval_loss': 0.3040871024131775, 'eval_f1': 0.44638434655496795, 'eval_runtime': 14.6503, 'eval_samples_per_second': 62.183, 'eval_steps_per_second': 1.024, 'epoch': 65.0}\n",
      "{'loss': 0.0773, 'learning_rate': 2.8045454545454546e-05, 'epoch': 65.86}\n",
      "{'eval_loss': 0.3009473383426666, 'eval_f1': 0.4579118272858625, 'eval_runtime': 15.5114, 'eval_samples_per_second': 58.731, 'eval_steps_per_second': 0.967, 'epoch': 66.0}\n",
      "{'loss': 0.077, 'learning_rate': 2.772727272727273e-05, 'epoch': 66.82}\n",
      "{'eval_loss': 0.29640060663223267, 'eval_f1': 0.46379570755491173, 'eval_runtime': 14.6242, 'eval_samples_per_second': 62.294, 'eval_steps_per_second': 1.026, 'epoch': 67.0}\n",
      "{'loss': 0.0741, 'learning_rate': 2.7409090909090912e-05, 'epoch': 67.77}\n",
      "{'eval_loss': 0.2875891327857971, 'eval_f1': 0.46095589882026605, 'eval_runtime': 15.5574, 'eval_samples_per_second': 58.558, 'eval_steps_per_second': 0.964, 'epoch': 68.0}\n",
      "{'loss': 0.0767, 'learning_rate': 2.7090909090909095e-05, 'epoch': 68.73}\n",
      "{'eval_loss': 0.2988113760948181, 'eval_f1': 0.4551865871492858, 'eval_runtime': 14.764, 'eval_samples_per_second': 61.704, 'eval_steps_per_second': 1.016, 'epoch': 69.0}\n",
      "{'loss': 0.072, 'learning_rate': 2.677272727272727e-05, 'epoch': 69.68}\n",
      "{'eval_loss': 0.30037692189216614, 'eval_f1': 0.45596188176881336, 'eval_runtime': 18.5452, 'eval_samples_per_second': 49.123, 'eval_steps_per_second': 0.809, 'epoch': 70.0}\n",
      "{'loss': 0.077, 'learning_rate': 2.6454545454545454e-05, 'epoch': 70.64}\n",
      "{'eval_loss': 0.29226166009902954, 'eval_f1': 0.4528282647109115, 'eval_runtime': 14.515, 'eval_samples_per_second': 62.763, 'eval_steps_per_second': 1.033, 'epoch': 71.0}\n",
      "{'loss': 0.0679, 'learning_rate': 2.6136363636363637e-05, 'epoch': 71.59}\n",
      "{'eval_loss': 0.29901322722435, 'eval_f1': 0.4523466716365185, 'eval_runtime': 16.1922, 'eval_samples_per_second': 56.262, 'eval_steps_per_second': 0.926, 'epoch': 72.0}\n",
      "{'loss': 0.0744, 'learning_rate': 2.581818181818182e-05, 'epoch': 72.55}\n",
      "{'eval_loss': 0.2958134710788727, 'eval_f1': 0.45865668145837946, 'eval_runtime': 14.5322, 'eval_samples_per_second': 62.688, 'eval_steps_per_second': 1.032, 'epoch': 73.0}\n",
      "{'loss': 0.0684, 'learning_rate': 2.5500000000000003e-05, 'epoch': 73.5}\n",
      "{'eval_loss': 0.30196234583854675, 'eval_f1': 0.45753965283121767, 'eval_runtime': 15.3055, 'eval_samples_per_second': 59.521, 'eval_steps_per_second': 0.98, 'epoch': 74.0}\n",
      "{'loss': 0.0673, 'learning_rate': 2.5181818181818183e-05, 'epoch': 74.45}\n",
      "{'eval_loss': 0.30486103892326355, 'eval_f1': 0.4654139613591955, 'eval_runtime': 14.5478, 'eval_samples_per_second': 62.621, 'eval_steps_per_second': 1.031, 'epoch': 75.0}\n",
      "{'loss': 0.0692, 'learning_rate': 2.4863636363636362e-05, 'epoch': 75.41}\n",
      "{'eval_loss': 0.3094393312931061, 'eval_f1': 0.46507666789316077, 'eval_runtime': 14.4016, 'eval_samples_per_second': 63.257, 'eval_steps_per_second': 1.042, 'epoch': 76.0}\n",
      "{'loss': 0.0649, 'learning_rate': 2.4545454545454545e-05, 'epoch': 76.36}\n",
      "{'eval_loss': 0.30404040217399597, 'eval_f1': 0.4581832825539676, 'eval_runtime': 14.3651, 'eval_samples_per_second': 63.417, 'eval_steps_per_second': 1.044, 'epoch': 77.0}\n",
      "{'loss': 0.0661, 'learning_rate': 2.422727272727273e-05, 'epoch': 77.32}\n",
      "{'eval_loss': 0.3246760070323944, 'eval_f1': 0.4534523420486097, 'eval_runtime': 14.3326, 'eval_samples_per_second': 63.561, 'eval_steps_per_second': 1.047, 'epoch': 78.0}\n",
      "{'loss': 0.0675, 'learning_rate': 2.390909090909091e-05, 'epoch': 78.27}\n",
      "{'eval_loss': 0.31851086020469666, 'eval_f1': 0.465506165705399, 'eval_runtime': 15.8484, 'eval_samples_per_second': 57.482, 'eval_steps_per_second': 0.946, 'epoch': 79.0}\n",
      "{'loss': 0.0663, 'learning_rate': 2.359090909090909e-05, 'epoch': 79.23}\n",
      "{'eval_loss': 0.3062109649181366, 'eval_f1': 0.4731875267580503, 'eval_runtime': 14.3939, 'eval_samples_per_second': 63.291, 'eval_steps_per_second': 1.042, 'epoch': 80.0}\n",
      "{'loss': 0.0675, 'learning_rate': 2.3272727272727274e-05, 'epoch': 80.18}\n",
      "{'eval_loss': 0.30780357122421265, 'eval_f1': 0.4580920134248121, 'eval_runtime': 15.1949, 'eval_samples_per_second': 59.954, 'eval_steps_per_second': 0.987, 'epoch': 81.0}\n",
      "{'loss': 0.0631, 'learning_rate': 2.2954545454545457e-05, 'epoch': 81.14}\n",
      "{'eval_loss': 0.30738434195518494, 'eval_f1': 0.4747342139406345, 'eval_runtime': 14.6387, 'eval_samples_per_second': 62.232, 'eval_steps_per_second': 1.025, 'epoch': 82.0}\n",
      "{'loss': 0.0617, 'learning_rate': 2.2636363636363637e-05, 'epoch': 82.09}\n",
      "{'eval_loss': 0.31084588170051575, 'eval_f1': 0.45901238728522004, 'eval_runtime': 15.5742, 'eval_samples_per_second': 58.494, 'eval_steps_per_second': 0.963, 'epoch': 83.0}\n",
      "{'loss': 0.0645, 'learning_rate': 2.231818181818182e-05, 'epoch': 83.05}\n",
      "{'loss': 0.0614, 'learning_rate': 2.2000000000000003e-05, 'epoch': 84.0}\n",
      "{'eval_loss': 0.32289013266563416, 'eval_f1': 0.4583114174051741, 'eval_runtime': 14.5645, 'eval_samples_per_second': 62.549, 'eval_steps_per_second': 1.03, 'epoch': 84.0}\n",
      "{'loss': 0.0609, 'learning_rate': 2.1681818181818182e-05, 'epoch': 84.95}\n",
      "{'eval_loss': 0.32053130865097046, 'eval_f1': 0.4590342797972642, 'eval_runtime': 14.7602, 'eval_samples_per_second': 61.72, 'eval_steps_per_second': 1.016, 'epoch': 85.0}\n",
      "{'loss': 0.0595, 'learning_rate': 2.1363636363636362e-05, 'epoch': 85.91}\n",
      "{'eval_loss': 0.32396984100341797, 'eval_f1': 0.46503600716944454, 'eval_runtime': 16.8361, 'eval_samples_per_second': 54.11, 'eval_steps_per_second': 0.891, 'epoch': 86.0}\n",
      "{'loss': 0.0583, 'learning_rate': 2.1045454545454545e-05, 'epoch': 86.86}\n",
      "{'eval_loss': 0.3109302520751953, 'eval_f1': 0.4762757548964445, 'eval_runtime': 16.422, 'eval_samples_per_second': 55.474, 'eval_steps_per_second': 0.913, 'epoch': 87.0}\n",
      "{'loss': 0.0621, 'learning_rate': 2.0727272727272728e-05, 'epoch': 87.82}\n",
      "{'eval_loss': 0.3256106376647949, 'eval_f1': 0.4644507040604768, 'eval_runtime': 14.7424, 'eval_samples_per_second': 61.795, 'eval_steps_per_second': 1.017, 'epoch': 88.0}\n",
      "{'loss': 0.0608, 'learning_rate': 2.040909090909091e-05, 'epoch': 88.77}\n",
      "{'eval_loss': 0.3289625346660614, 'eval_f1': 0.4729968938573615, 'eval_runtime': 15.618, 'eval_samples_per_second': 58.33, 'eval_steps_per_second': 0.96, 'epoch': 89.0}\n",
      "{'loss': 0.0579, 'learning_rate': 2.009090909090909e-05, 'epoch': 89.73}\n",
      "{'eval_loss': 0.32599177956581116, 'eval_f1': 0.46793143593356024, 'eval_runtime': 14.8114, 'eval_samples_per_second': 61.507, 'eval_steps_per_second': 1.013, 'epoch': 90.0}\n",
      "{'loss': 0.058, 'learning_rate': 1.9772727272727274e-05, 'epoch': 90.68}\n",
      "{'eval_loss': 0.3244154453277588, 'eval_f1': 0.4678424558731507, 'eval_runtime': 16.0776, 'eval_samples_per_second': 56.663, 'eval_steps_per_second': 0.933, 'epoch': 91.0}\n",
      "{'loss': 0.0571, 'learning_rate': 1.9454545454545457e-05, 'epoch': 91.64}\n",
      "{'eval_loss': 0.3300752341747284, 'eval_f1': 0.4630558232409096, 'eval_runtime': 14.9913, 'eval_samples_per_second': 60.768, 'eval_steps_per_second': 1.001, 'epoch': 92.0}\n",
      "{'loss': 0.0578, 'learning_rate': 1.913636363636364e-05, 'epoch': 92.59}\n",
      "{'eval_loss': 0.3420039117336273, 'eval_f1': 0.45452360574467177, 'eval_runtime': 15.3724, 'eval_samples_per_second': 59.262, 'eval_steps_per_second': 0.976, 'epoch': 93.0}\n",
      "{'loss': 0.058, 'learning_rate': 1.881818181818182e-05, 'epoch': 93.55}\n",
      "{'eval_loss': 0.34849876165390015, 'eval_f1': 0.4727145069440588, 'eval_runtime': 15.3073, 'eval_samples_per_second': 59.514, 'eval_steps_per_second': 0.98, 'epoch': 94.0}\n",
      "{'loss': 0.0611, 'learning_rate': 1.85e-05, 'epoch': 94.5}\n",
      "{'eval_loss': 0.33796533942222595, 'eval_f1': 0.4521983607122129, 'eval_runtime': 15.3213, 'eval_samples_per_second': 59.46, 'eval_steps_per_second': 0.979, 'epoch': 95.0}\n",
      "{'loss': 0.057, 'learning_rate': 1.8181818181818182e-05, 'epoch': 95.45}\n",
      "{'eval_loss': 0.33636608719825745, 'eval_f1': 0.4595804766670189, 'eval_runtime': 14.7809, 'eval_samples_per_second': 61.634, 'eval_steps_per_second': 1.015, 'epoch': 96.0}\n",
      "{'loss': 0.0595, 'learning_rate': 1.7863636363636365e-05, 'epoch': 96.41}\n",
      "{'eval_loss': 0.3381132483482361, 'eval_f1': 0.4610153827144156, 'eval_runtime': 15.0883, 'eval_samples_per_second': 60.378, 'eval_steps_per_second': 0.994, 'epoch': 97.0}\n",
      "{'loss': 0.0563, 'learning_rate': 1.7545454545454545e-05, 'epoch': 97.36}\n",
      "{'eval_loss': 0.3454262316226959, 'eval_f1': 0.4670961562838672, 'eval_runtime': 15.4683, 'eval_samples_per_second': 58.895, 'eval_steps_per_second': 0.97, 'epoch': 98.0}\n",
      "{'loss': 0.0529, 'learning_rate': 1.7227272727272728e-05, 'epoch': 98.32}\n",
      "{'eval_loss': 0.3266844153404236, 'eval_f1': 0.45611252694417, 'eval_runtime': 14.7119, 'eval_samples_per_second': 61.923, 'eval_steps_per_second': 1.02, 'epoch': 99.0}\n",
      "{'loss': 0.0539, 'learning_rate': 1.690909090909091e-05, 'epoch': 99.27}\n",
      "{'eval_loss': 0.32768604159355164, 'eval_f1': 0.47401419313235804, 'eval_runtime': 14.7605, 'eval_samples_per_second': 61.719, 'eval_steps_per_second': 1.016, 'epoch': 100.0}\n",
      "{'loss': 0.0544, 'learning_rate': 1.6590909090909094e-05, 'epoch': 100.23}\n",
      "{'eval_loss': 0.3354683816432953, 'eval_f1': 0.4679551160838904, 'eval_runtime': 14.9132, 'eval_samples_per_second': 61.087, 'eval_steps_per_second': 1.006, 'epoch': 101.0}\n",
      "{'loss': 0.0542, 'learning_rate': 1.6272727272727273e-05, 'epoch': 101.18}\n",
      "{'eval_loss': 0.33405452966690063, 'eval_f1': 0.4721325854939968, 'eval_runtime': 15.4424, 'eval_samples_per_second': 58.993, 'eval_steps_per_second': 0.971, 'epoch': 102.0}\n",
      "{'loss': 0.0525, 'learning_rate': 1.5954545454545456e-05, 'epoch': 102.14}\n",
      "{'eval_loss': 0.3437190353870392, 'eval_f1': 0.4719712411875539, 'eval_runtime': 14.8123, 'eval_samples_per_second': 61.503, 'eval_steps_per_second': 1.013, 'epoch': 103.0}\n",
      "{'loss': 0.0545, 'learning_rate': 1.563636363636364e-05, 'epoch': 103.09}\n",
      "{'eval_loss': 0.3560742735862732, 'eval_f1': 0.46048865473252204, 'eval_runtime': 14.8762, 'eval_samples_per_second': 61.239, 'eval_steps_per_second': 1.008, 'epoch': 104.0}\n",
      "{'loss': 0.0528, 'learning_rate': 1.531818181818182e-05, 'epoch': 104.05}\n",
      "{'loss': 0.0542, 'learning_rate': 1.5e-05, 'epoch': 105.0}\n",
      "{'eval_loss': 0.3384552299976349, 'eval_f1': 0.46150430107309565, 'eval_runtime': 14.7599, 'eval_samples_per_second': 61.721, 'eval_steps_per_second': 1.016, 'epoch': 105.0}\n",
      "{'loss': 0.0526, 'learning_rate': 1.4681818181818183e-05, 'epoch': 105.95}\n",
      "{'eval_loss': 0.34761178493499756, 'eval_f1': 0.4646601058057056, 'eval_runtime': 15.9565, 'eval_samples_per_second': 57.093, 'eval_steps_per_second': 0.94, 'epoch': 106.0}\n",
      "{'loss': 0.0524, 'learning_rate': 1.4363636363636365e-05, 'epoch': 106.91}\n",
      "{'eval_loss': 0.3456159830093384, 'eval_f1': 0.4492684463373276, 'eval_runtime': 14.8222, 'eval_samples_per_second': 61.462, 'eval_steps_per_second': 1.012, 'epoch': 107.0}\n",
      "{'loss': 0.0512, 'learning_rate': 1.4045454545454544e-05, 'epoch': 107.86}\n",
      "{'eval_loss': 0.3542243242263794, 'eval_f1': 0.4453065774804905, 'eval_runtime': 15.0499, 'eval_samples_per_second': 60.532, 'eval_steps_per_second': 0.997, 'epoch': 108.0}\n",
      "{'loss': 0.0526, 'learning_rate': 1.3727272727272727e-05, 'epoch': 108.82}\n",
      "{'eval_loss': 0.35897213220596313, 'eval_f1': 0.45511632126728996, 'eval_runtime': 14.8591, 'eval_samples_per_second': 61.309, 'eval_steps_per_second': 1.009, 'epoch': 109.0}\n",
      "{'loss': 0.0498, 'learning_rate': 1.340909090909091e-05, 'epoch': 109.77}\n",
      "{'eval_loss': 0.3589820861816406, 'eval_f1': 0.4535263816310753, 'eval_runtime': 16.5057, 'eval_samples_per_second': 55.193, 'eval_steps_per_second': 0.909, 'epoch': 110.0}\n",
      "{'loss': 0.0512, 'learning_rate': 1.3090909090909093e-05, 'epoch': 110.73}\n",
      "{'eval_loss': 0.35584285855293274, 'eval_f1': 0.46409582526082, 'eval_runtime': 15.3557, 'eval_samples_per_second': 59.327, 'eval_steps_per_second': 0.977, 'epoch': 111.0}\n",
      "{'loss': 0.0488, 'learning_rate': 1.2772727272727273e-05, 'epoch': 111.68}\n",
      "{'eval_loss': 0.3562770187854767, 'eval_f1': 0.4555602897977082, 'eval_runtime': 15.0327, 'eval_samples_per_second': 60.601, 'eval_steps_per_second': 0.998, 'epoch': 112.0}\n",
      "{'loss': 0.0503, 'learning_rate': 1.2454545454545454e-05, 'epoch': 112.64}\n",
      "{'eval_loss': 0.3487609922885895, 'eval_f1': 0.47085215678696263, 'eval_runtime': 14.6887, 'eval_samples_per_second': 62.021, 'eval_steps_per_second': 1.021, 'epoch': 113.0}\n",
      "{'loss': 0.0499, 'learning_rate': 1.2136363636363637e-05, 'epoch': 113.59}\n",
      "{'eval_loss': 0.361161470413208, 'eval_f1': 0.4591008733707406, 'eval_runtime': 16.6588, 'eval_samples_per_second': 54.686, 'eval_steps_per_second': 0.9, 'epoch': 114.0}\n",
      "{'loss': 0.0506, 'learning_rate': 1.1818181818181819e-05, 'epoch': 114.55}\n",
      "{'eval_loss': 0.3514162302017212, 'eval_f1': 0.4723982304245462, 'eval_runtime': 14.7181, 'eval_samples_per_second': 61.897, 'eval_steps_per_second': 1.019, 'epoch': 115.0}\n",
      "{'loss': 0.0501, 'learning_rate': 1.1500000000000002e-05, 'epoch': 115.5}\n",
      "{'eval_loss': 0.3575383126735687, 'eval_f1': 0.46499311781287656, 'eval_runtime': 15.5468, 'eval_samples_per_second': 58.597, 'eval_steps_per_second': 0.965, 'epoch': 116.0}\n",
      "{'loss': 0.0513, 'learning_rate': 1.1181818181818183e-05, 'epoch': 116.45}\n",
      "{'eval_loss': 0.3576323091983795, 'eval_f1': 0.4658424076692212, 'eval_runtime': 14.8106, 'eval_samples_per_second': 61.51, 'eval_steps_per_second': 1.013, 'epoch': 117.0}\n",
      "{'loss': 0.0533, 'learning_rate': 1.0863636363636364e-05, 'epoch': 117.41}\n",
      "{'eval_loss': 0.36101484298706055, 'eval_f1': 0.46007005780216303, 'eval_runtime': 16.1955, 'eval_samples_per_second': 56.25, 'eval_steps_per_second': 0.926, 'epoch': 118.0}\n",
      "{'loss': 0.0495, 'learning_rate': 1.0545454545454546e-05, 'epoch': 118.36}\n",
      "{'eval_loss': 0.36075863242149353, 'eval_f1': 0.4445442932675511, 'eval_runtime': 14.6076, 'eval_samples_per_second': 62.365, 'eval_steps_per_second': 1.027, 'epoch': 119.0}\n",
      "{'loss': 0.0477, 'learning_rate': 1.0227272727272729e-05, 'epoch': 119.32}\n",
      "{'eval_loss': 0.3571852147579193, 'eval_f1': 0.45657329700748167, 'eval_runtime': 15.5307, 'eval_samples_per_second': 58.658, 'eval_steps_per_second': 0.966, 'epoch': 120.0}\n",
      "{'loss': 0.0509, 'learning_rate': 9.90909090909091e-06, 'epoch': 120.27}\n",
      "{'eval_loss': 0.3533075153827667, 'eval_f1': 0.4674674306222603, 'eval_runtime': 14.9852, 'eval_samples_per_second': 60.793, 'eval_steps_per_second': 1.001, 'epoch': 121.0}\n",
      "{'loss': 0.0501, 'learning_rate': 9.590909090909091e-06, 'epoch': 121.23}\n",
      "{'eval_loss': 0.35899636149406433, 'eval_f1': 0.4590446946825466, 'eval_runtime': 15.3561, 'eval_samples_per_second': 59.325, 'eval_steps_per_second': 0.977, 'epoch': 122.0}\n",
      "{'loss': 0.0454, 'learning_rate': 9.272727272727273e-06, 'epoch': 122.18}\n",
      "{'eval_loss': 0.36100056767463684, 'eval_f1': 0.4624637048481029, 'eval_runtime': 14.717, 'eval_samples_per_second': 61.901, 'eval_steps_per_second': 1.019, 'epoch': 123.0}\n",
      "{'loss': 0.0459, 'learning_rate': 8.954545454545454e-06, 'epoch': 123.14}\n",
      "{'eval_loss': 0.3616505265235901, 'eval_f1': 0.46273805050657696, 'eval_runtime': 15.3961, 'eval_samples_per_second': 59.171, 'eval_steps_per_second': 0.974, 'epoch': 124.0}\n",
      "{'loss': 0.0486, 'learning_rate': 8.636363636363637e-06, 'epoch': 124.09}\n",
      "{'eval_loss': 0.3634319305419922, 'eval_f1': 0.45856722186161303, 'eval_runtime': 14.9269, 'eval_samples_per_second': 61.031, 'eval_steps_per_second': 1.005, 'epoch': 125.0}\n",
      "{'loss': 0.0493, 'learning_rate': 8.318181818181818e-06, 'epoch': 125.05}\n",
      "{'loss': 0.0465, 'learning_rate': 8.000000000000001e-06, 'epoch': 126.0}\n",
      "{'eval_loss': 0.3582593500614166, 'eval_f1': 0.4580317445671304, 'eval_runtime': 15.3292, 'eval_samples_per_second': 59.429, 'eval_steps_per_second': 0.979, 'epoch': 126.0}\n",
      "{'loss': 0.0463, 'learning_rate': 7.681818181818181e-06, 'epoch': 126.95}\n",
      "{'eval_loss': 0.3605066239833832, 'eval_f1': 0.4594054474603652, 'eval_runtime': 14.8139, 'eval_samples_per_second': 61.496, 'eval_steps_per_second': 1.013, 'epoch': 127.0}\n",
      "{'loss': 0.0483, 'learning_rate': 7.363636363636364e-06, 'epoch': 127.91}\n",
      "{'eval_loss': 0.35626253485679626, 'eval_f1': 0.46431132969594513, 'eval_runtime': 14.9736, 'eval_samples_per_second': 60.84, 'eval_steps_per_second': 1.002, 'epoch': 128.0}\n",
      "{'loss': 0.0468, 'learning_rate': 7.045454545454545e-06, 'epoch': 128.86}\n",
      "{'eval_loss': 0.36070236563682556, 'eval_f1': 0.4619318946303643, 'eval_runtime': 14.8176, 'eval_samples_per_second': 61.481, 'eval_steps_per_second': 1.012, 'epoch': 129.0}\n",
      "{'loss': 0.0476, 'learning_rate': 6.727272727272728e-06, 'epoch': 129.82}\n",
      "{'eval_loss': 0.35790571570396423, 'eval_f1': 0.4631680311235858, 'eval_runtime': 14.7943, 'eval_samples_per_second': 61.578, 'eval_steps_per_second': 1.014, 'epoch': 130.0}\n",
      "{'loss': 0.0454, 'learning_rate': 6.409090909090909e-06, 'epoch': 130.77}\n",
      "{'eval_loss': 0.3582865595817566, 'eval_f1': 0.4679139101146954, 'eval_runtime': 14.8379, 'eval_samples_per_second': 61.397, 'eval_steps_per_second': 1.011, 'epoch': 131.0}\n",
      "{'loss': 0.0481, 'learning_rate': 6.090909090909091e-06, 'epoch': 131.73}\n",
      "{'eval_loss': 0.36011913418769836, 'eval_f1': 0.46587252680371477, 'eval_runtime': 14.8223, 'eval_samples_per_second': 61.462, 'eval_steps_per_second': 1.012, 'epoch': 132.0}\n",
      "{'loss': 0.0455, 'learning_rate': 5.772727272727272e-06, 'epoch': 132.68}\n",
      "{'eval_loss': 0.3639913499355316, 'eval_f1': 0.45170417807171165, 'eval_runtime': 15.0444, 'eval_samples_per_second': 60.554, 'eval_steps_per_second': 0.997, 'epoch': 133.0}\n",
      "{'loss': 0.0469, 'learning_rate': 5.4545454545454545e-06, 'epoch': 133.64}\n",
      "{'eval_loss': 0.36271432042121887, 'eval_f1': 0.45486739948826455, 'eval_runtime': 14.5949, 'eval_samples_per_second': 62.419, 'eval_steps_per_second': 1.028, 'epoch': 134.0}\n",
      "{'loss': 0.0479, 'learning_rate': 5.136363636363637e-06, 'epoch': 134.59}\n",
      "{'eval_loss': 0.36663171648979187, 'eval_f1': 0.45684010622410115, 'eval_runtime': 14.7519, 'eval_samples_per_second': 61.755, 'eval_steps_per_second': 1.017, 'epoch': 135.0}\n",
      "{'loss': 0.0445, 'learning_rate': 4.818181818181818e-06, 'epoch': 135.55}\n",
      "{'eval_loss': 0.3678531050682068, 'eval_f1': 0.4619558883903833, 'eval_runtime': 14.764, 'eval_samples_per_second': 61.704, 'eval_steps_per_second': 1.016, 'epoch': 136.0}\n",
      "{'loss': 0.0438, 'learning_rate': 4.5e-06, 'epoch': 136.5}\n",
      "{'eval_loss': 0.36839255690574646, 'eval_f1': 0.4606713984075717, 'eval_runtime': 15.7197, 'eval_samples_per_second': 57.953, 'eval_steps_per_second': 0.954, 'epoch': 137.0}\n",
      "{'loss': 0.0461, 'learning_rate': 4.181818181818182e-06, 'epoch': 137.45}\n",
      "{'eval_loss': 0.3672473430633545, 'eval_f1': 0.4635968783017523, 'eval_runtime': 14.6949, 'eval_samples_per_second': 61.994, 'eval_steps_per_second': 1.021, 'epoch': 138.0}\n",
      "{'loss': 0.0457, 'learning_rate': 3.863636363636364e-06, 'epoch': 138.41}\n",
      "{'eval_loss': 0.36770328879356384, 'eval_f1': 0.46314336099156345, 'eval_runtime': 14.8005, 'eval_samples_per_second': 61.552, 'eval_steps_per_second': 1.013, 'epoch': 139.0}\n",
      "{'loss': 0.0466, 'learning_rate': 3.5454545454545454e-06, 'epoch': 139.36}\n",
      "{'eval_loss': 0.36554306745529175, 'eval_f1': 0.4601483418807917, 'eval_runtime': 14.6629, 'eval_samples_per_second': 62.13, 'eval_steps_per_second': 1.023, 'epoch': 140.0}\n",
      "{'loss': 0.0413, 'learning_rate': 3.2272727272727275e-06, 'epoch': 140.32}\n",
      "{'eval_loss': 0.3661288917064667, 'eval_f1': 0.4613020623274429, 'eval_runtime': 16.1551, 'eval_samples_per_second': 56.391, 'eval_steps_per_second': 0.929, 'epoch': 141.0}\n",
      "{'loss': 0.046, 'learning_rate': 2.9090909090909093e-06, 'epoch': 141.27}\n",
      "{'eval_loss': 0.3642762303352356, 'eval_f1': 0.458669875077546, 'eval_runtime': 14.6478, 'eval_samples_per_second': 62.194, 'eval_steps_per_second': 1.024, 'epoch': 142.0}\n",
      "{'loss': 0.0452, 'learning_rate': 2.590909090909091e-06, 'epoch': 142.23}\n",
      "{'eval_loss': 0.36480891704559326, 'eval_f1': 0.4639885704681066, 'eval_runtime': 15.4186, 'eval_samples_per_second': 59.084, 'eval_steps_per_second': 0.973, 'epoch': 143.0}\n",
      "{'loss': 0.0475, 'learning_rate': 2.2727272727272728e-06, 'epoch': 143.18}\n",
      "{'eval_loss': 0.36598554253578186, 'eval_f1': 0.4647201880606835, 'eval_runtime': 15.2639, 'eval_samples_per_second': 59.683, 'eval_steps_per_second': 0.983, 'epoch': 144.0}\n",
      "{'loss': 0.0458, 'learning_rate': 1.954545454545455e-06, 'epoch': 144.14}\n",
      "{'eval_loss': 0.3673345744609833, 'eval_f1': 0.4616959420221695, 'eval_runtime': 16.6401, 'eval_samples_per_second': 54.747, 'eval_steps_per_second': 0.901, 'epoch': 145.0}\n",
      "{'loss': 0.0449, 'learning_rate': 1.6363636363636367e-06, 'epoch': 145.09}\n",
      "{'eval_loss': 0.3672187924385071, 'eval_f1': 0.4600889361495358, 'eval_runtime': 14.7069, 'eval_samples_per_second': 61.944, 'eval_steps_per_second': 1.02, 'epoch': 146.0}\n",
      "{'loss': 0.0447, 'learning_rate': 1.3181818181818182e-06, 'epoch': 146.05}\n",
      "{'loss': 0.0447, 'learning_rate': 1.0000000000000002e-06, 'epoch': 147.0}\n",
      "{'eval_loss': 0.3672660291194916, 'eval_f1': 0.4604353242171703, 'eval_runtime': 15.443, 'eval_samples_per_second': 58.991, 'eval_steps_per_second': 0.971, 'epoch': 147.0}\n",
      "{'loss': 0.0444, 'learning_rate': 6.818181818181818e-07, 'epoch': 147.95}\n",
      "{'eval_loss': 0.3658818304538727, 'eval_f1': 0.46006973855526606, 'eval_runtime': 15.3973, 'eval_samples_per_second': 59.166, 'eval_steps_per_second': 0.974, 'epoch': 148.0}\n",
      "{'loss': 0.0472, 'learning_rate': 3.6363636363636366e-07, 'epoch': 148.91}\n",
      "{'eval_loss': 0.36575716733932495, 'eval_f1': 0.46055771529411826, 'eval_runtime': 15.8964, 'eval_samples_per_second': 57.309, 'eval_steps_per_second': 0.944, 'epoch': 149.0}\n",
      "{'loss': 0.0431, 'learning_rate': 4.545454545454546e-08, 'epoch': 149.86}\n",
      "{'eval_loss': 0.3659135401248932, 'eval_f1': 0.459672619047619, 'eval_runtime': 14.7913, 'eval_samples_per_second': 61.59, 'eval_steps_per_second': 1.014, 'epoch': 150.0}\n",
      "{'train_runtime': 13344.3955, 'train_samples_per_second': 15.535, 'train_steps_per_second': 0.247, 'train_loss': 0.16605981479088466, 'epoch': 150.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3b42806abf4d0eb18d8783999ba553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:  sc_10001_ds_down\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685e976666c8453c91f1082a0a4133c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1dfd6c01f2414fa0cfcdecbb4399e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a448d2d46c544a99b732fa663b887a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  sc_10001_ds_down_lstm_e300_ld01_b64_wF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5747, 'learning_rate': 4.9840909090909096e-05, 'epoch': 0.95}\n",
      "{'eval_loss': 1.305628776550293, 'eval_f1': 0.0, 'eval_runtime': 15.0392, 'eval_samples_per_second': 60.575, 'eval_steps_per_second': 0.997, 'epoch': 1.0}\n",
      "{'loss': 1.2784, 'learning_rate': 4.968181818181818e-05, 'epoch': 1.91}\n",
      "{'eval_loss': 1.184409499168396, 'eval_f1': 0.0, 'eval_runtime': 16.0361, 'eval_samples_per_second': 56.809, 'eval_steps_per_second': 0.935, 'epoch': 2.0}\n",
      "{'loss': 1.1795, 'learning_rate': 4.9522727272727275e-05, 'epoch': 2.86}\n",
      "{'eval_loss': 1.1006083488464355, 'eval_f1': 0.0, 'eval_runtime': 14.8957, 'eval_samples_per_second': 61.159, 'eval_steps_per_second': 1.007, 'epoch': 3.0}\n",
      "{'loss': 1.1061, 'learning_rate': 4.936363636363637e-05, 'epoch': 3.82}\n",
      "{'eval_loss': 1.0270586013793945, 'eval_f1': 0.0, 'eval_runtime': 16.2541, 'eval_samples_per_second': 56.047, 'eval_steps_per_second': 0.923, 'epoch': 4.0}\n",
      "{'loss': 1.0396, 'learning_rate': 4.920454545454546e-05, 'epoch': 4.77}\n",
      "{'eval_loss': 0.9604736566543579, 'eval_f1': 0.0, 'eval_runtime': 14.9207, 'eval_samples_per_second': 61.056, 'eval_steps_per_second': 1.005, 'epoch': 5.0}\n",
      "{'loss': 0.9758, 'learning_rate': 4.904545454545455e-05, 'epoch': 5.73}\n",
      "{'eval_loss': 0.8989677429199219, 'eval_f1': 0.0, 'eval_runtime': 15.7439, 'eval_samples_per_second': 57.864, 'eval_steps_per_second': 0.953, 'epoch': 6.0}\n",
      "{'loss': 0.9238, 'learning_rate': 4.888636363636364e-05, 'epoch': 6.68}\n",
      "{'eval_loss': 0.8405866026878357, 'eval_f1': 0.0, 'eval_runtime': 14.9724, 'eval_samples_per_second': 60.845, 'eval_steps_per_second': 1.002, 'epoch': 7.0}\n",
      "{'loss': 0.8688, 'learning_rate': 4.872727272727273e-05, 'epoch': 7.64}\n",
      "{'eval_loss': 0.7853434681892395, 'eval_f1': 0.0, 'eval_runtime': 16.632, 'eval_samples_per_second': 54.774, 'eval_steps_per_second': 0.902, 'epoch': 8.0}\n",
      "{'loss': 0.8196, 'learning_rate': 4.856818181818182e-05, 'epoch': 8.59}\n",
      "{'eval_loss': 0.734958827495575, 'eval_f1': 0.0, 'eval_runtime': 14.983, 'eval_samples_per_second': 60.802, 'eval_steps_per_second': 1.001, 'epoch': 9.0}\n",
      "{'loss': 0.7745, 'learning_rate': 4.840909090909091e-05, 'epoch': 9.55}\n",
      "{'eval_loss': 0.6897664070129395, 'eval_f1': 0.0, 'eval_runtime': 15.7158, 'eval_samples_per_second': 57.967, 'eval_steps_per_second': 0.954, 'epoch': 10.0}\n",
      "{'loss': 0.7283, 'learning_rate': 4.825e-05, 'epoch': 10.5}\n",
      "{'eval_loss': 0.6492339968681335, 'eval_f1': 0.0, 'eval_runtime': 14.7925, 'eval_samples_per_second': 61.585, 'eval_steps_per_second': 1.014, 'epoch': 11.0}\n",
      "{'loss': 0.7012, 'learning_rate': 4.8090909090909094e-05, 'epoch': 11.45}\n",
      "{'eval_loss': 0.6130349636077881, 'eval_f1': 0.0, 'eval_runtime': 17.1681, 'eval_samples_per_second': 53.063, 'eval_steps_per_second': 0.874, 'epoch': 12.0}\n",
      "{'loss': 0.6652, 'learning_rate': 4.793181818181818e-05, 'epoch': 12.41}\n",
      "{'eval_loss': 0.5808501243591309, 'eval_f1': 0.0, 'eval_runtime': 15.0018, 'eval_samples_per_second': 60.726, 'eval_steps_per_second': 1.0, 'epoch': 13.0}\n",
      "{'loss': 0.6286, 'learning_rate': 4.777272727272727e-05, 'epoch': 13.36}\n",
      "{'eval_loss': 0.5523820519447327, 'eval_f1': 0.0, 'eval_runtime': 15.7956, 'eval_samples_per_second': 57.674, 'eval_steps_per_second': 0.95, 'epoch': 14.0}\n",
      "{'loss': 0.6072, 'learning_rate': 4.7613636363636367e-05, 'epoch': 14.32}\n",
      "{'eval_loss': 0.5274143218994141, 'eval_f1': 0.0, 'eval_runtime': 14.9308, 'eval_samples_per_second': 61.015, 'eval_steps_per_second': 1.005, 'epoch': 15.0}\n",
      "{'loss': 0.5938, 'learning_rate': 4.745454545454546e-05, 'epoch': 15.27}\n",
      "{'eval_loss': 0.505685031414032, 'eval_f1': 0.0, 'eval_runtime': 16.7638, 'eval_samples_per_second': 54.343, 'eval_steps_per_second': 0.895, 'epoch': 16.0}\n",
      "{'loss': 0.5659, 'learning_rate': 4.7295454545454546e-05, 'epoch': 16.23}\n",
      "{'eval_loss': 0.4869441092014313, 'eval_f1': 0.0, 'eval_runtime': 14.9583, 'eval_samples_per_second': 60.903, 'eval_steps_per_second': 1.003, 'epoch': 17.0}\n",
      "{'loss': 0.5433, 'learning_rate': 4.713636363636364e-05, 'epoch': 17.18}\n",
      "{'eval_loss': 0.47135668992996216, 'eval_f1': 0.0, 'eval_runtime': 15.4654, 'eval_samples_per_second': 58.906, 'eval_steps_per_second': 0.97, 'epoch': 18.0}\n",
      "{'loss': 0.5387, 'learning_rate': 4.697727272727273e-05, 'epoch': 18.14}\n",
      "{'eval_loss': 0.45920780301094055, 'eval_f1': 0.0, 'eval_runtime': 15.2166, 'eval_samples_per_second': 59.869, 'eval_steps_per_second': 0.986, 'epoch': 19.0}\n",
      "{'loss': 0.5224, 'learning_rate': 4.681818181818182e-05, 'epoch': 19.09}\n",
      "{'eval_loss': 0.44997042417526245, 'eval_f1': 0.0, 'eval_runtime': 16.7781, 'eval_samples_per_second': 54.297, 'eval_steps_per_second': 0.894, 'epoch': 20.0}\n",
      "{'loss': 0.5138, 'learning_rate': 4.665909090909091e-05, 'epoch': 20.05}\n",
      "{'loss': 0.5006, 'learning_rate': 4.6500000000000005e-05, 'epoch': 21.0}\n",
      "{'eval_loss': 0.44297751784324646, 'eval_f1': 0.0, 'eval_runtime': 15.0565, 'eval_samples_per_second': 60.506, 'eval_steps_per_second': 0.996, 'epoch': 21.0}\n",
      "{'loss': 0.4982, 'learning_rate': 4.634090909090909e-05, 'epoch': 21.95}\n",
      "{'eval_loss': 0.43746715784072876, 'eval_f1': 0.0, 'eval_runtime': 15.4558, 'eval_samples_per_second': 58.942, 'eval_steps_per_second': 0.971, 'epoch': 22.0}\n",
      "{'loss': 0.4992, 'learning_rate': 4.618181818181818e-05, 'epoch': 22.91}\n",
      "{'eval_loss': 0.4332582652568817, 'eval_f1': 0.0, 'eval_runtime': 14.9426, 'eval_samples_per_second': 60.967, 'eval_steps_per_second': 1.004, 'epoch': 23.0}\n",
      "{'loss': 0.495, 'learning_rate': 4.602272727272727e-05, 'epoch': 23.86}\n",
      "{'eval_loss': 0.4299030900001526, 'eval_f1': 0.0, 'eval_runtime': 16.4943, 'eval_samples_per_second': 55.231, 'eval_steps_per_second': 0.909, 'epoch': 24.0}\n",
      "{'loss': 0.5031, 'learning_rate': 4.5863636363636365e-05, 'epoch': 24.82}\n",
      "{'eval_loss': 0.4272872507572174, 'eval_f1': 0.0, 'eval_runtime': 15.9144, 'eval_samples_per_second': 57.244, 'eval_steps_per_second': 0.943, 'epoch': 25.0}\n",
      "{'loss': 0.485, 'learning_rate': 4.570454545454546e-05, 'epoch': 25.77}\n",
      "{'eval_loss': 0.42504391074180603, 'eval_f1': 0.0, 'eval_runtime': 14.9974, 'eval_samples_per_second': 60.744, 'eval_steps_per_second': 1.0, 'epoch': 26.0}\n",
      "{'loss': 0.4871, 'learning_rate': 4.5545454545454544e-05, 'epoch': 26.73}\n",
      "{'eval_loss': 0.4232124090194702, 'eval_f1': 0.0, 'eval_runtime': 15.4431, 'eval_samples_per_second': 58.991, 'eval_steps_per_second': 0.971, 'epoch': 27.0}\n",
      "{'loss': 0.4787, 'learning_rate': 4.538636363636364e-05, 'epoch': 27.68}\n",
      "{'eval_loss': 0.42166656255722046, 'eval_f1': 0.0, 'eval_runtime': 15.0569, 'eval_samples_per_second': 60.504, 'eval_steps_per_second': 0.996, 'epoch': 28.0}\n",
      "{'loss': 0.4939, 'learning_rate': 4.522727272727273e-05, 'epoch': 28.64}\n",
      "{'eval_loss': 0.42041781544685364, 'eval_f1': 0.0, 'eval_runtime': 15.8967, 'eval_samples_per_second': 57.308, 'eval_steps_per_second': 0.944, 'epoch': 29.0}\n",
      "{'loss': 0.4758, 'learning_rate': 4.506818181818182e-05, 'epoch': 29.59}\n",
      "{'eval_loss': 0.41930797696113586, 'eval_f1': 0.0, 'eval_runtime': 14.9832, 'eval_samples_per_second': 60.802, 'eval_steps_per_second': 1.001, 'epoch': 30.0}\n",
      "{'loss': 0.4992, 'learning_rate': 4.490909090909091e-05, 'epoch': 30.55}\n",
      "{'eval_loss': 0.4184698164463043, 'eval_f1': 0.0, 'eval_runtime': 15.5447, 'eval_samples_per_second': 58.605, 'eval_steps_per_second': 0.965, 'epoch': 31.0}\n",
      "{'loss': 0.4668, 'learning_rate': 4.4750000000000004e-05, 'epoch': 31.5}\n",
      "{'eval_loss': 0.41767314076423645, 'eval_f1': 0.0, 'eval_runtime': 15.0202, 'eval_samples_per_second': 60.652, 'eval_steps_per_second': 0.999, 'epoch': 32.0}\n",
      "{'loss': 0.4911, 'learning_rate': 4.45909090909091e-05, 'epoch': 32.45}\n",
      "{'eval_loss': 0.4170372784137726, 'eval_f1': 0.0, 'eval_runtime': 15.6692, 'eval_samples_per_second': 58.139, 'eval_steps_per_second': 0.957, 'epoch': 33.0}\n",
      "{'loss': 0.4703, 'learning_rate': 4.443181818181818e-05, 'epoch': 33.41}\n",
      "{'eval_loss': 0.41643011569976807, 'eval_f1': 0.0, 'eval_runtime': 15.0035, 'eval_samples_per_second': 60.719, 'eval_steps_per_second': 1.0, 'epoch': 34.0}\n",
      "{'loss': 0.487, 'learning_rate': 4.4272727272727276e-05, 'epoch': 34.36}\n",
      "{'eval_loss': 0.4159805178642273, 'eval_f1': 0.0, 'eval_runtime': 15.1946, 'eval_samples_per_second': 59.956, 'eval_steps_per_second': 0.987, 'epoch': 35.0}\n",
      "{'loss': 0.4712, 'learning_rate': 4.411363636363637e-05, 'epoch': 35.32}\n",
      "{'eval_loss': 0.4155772030353546, 'eval_f1': 0.0, 'eval_runtime': 15.3358, 'eval_samples_per_second': 59.404, 'eval_steps_per_second': 0.978, 'epoch': 36.0}\n",
      "{'loss': 0.4757, 'learning_rate': 4.3954545454545456e-05, 'epoch': 36.27}\n",
      "{'eval_loss': 0.4152092933654785, 'eval_f1': 0.0, 'eval_runtime': 14.8252, 'eval_samples_per_second': 61.45, 'eval_steps_per_second': 1.012, 'epoch': 37.0}\n",
      "{'loss': 0.486, 'learning_rate': 4.379545454545454e-05, 'epoch': 37.23}\n",
      "{'eval_loss': 0.41489896178245544, 'eval_f1': 0.0, 'eval_runtime': 15.2251, 'eval_samples_per_second': 59.835, 'eval_steps_per_second': 0.985, 'epoch': 38.0}\n",
      "{'loss': 0.4714, 'learning_rate': 4.3636363636363636e-05, 'epoch': 38.18}\n",
      "{'eval_loss': 0.4146139323711395, 'eval_f1': 0.0, 'eval_runtime': 16.128, 'eval_samples_per_second': 56.486, 'eval_steps_per_second': 0.93, 'epoch': 39.0}\n",
      "{'loss': 0.4875, 'learning_rate': 4.347727272727273e-05, 'epoch': 39.14}\n",
      "{'eval_loss': 0.4144213795661926, 'eval_f1': 0.0, 'eval_runtime': 16.5346, 'eval_samples_per_second': 55.097, 'eval_steps_per_second': 0.907, 'epoch': 40.0}\n",
      "{'loss': 0.476, 'learning_rate': 4.331818181818182e-05, 'epoch': 40.09}\n",
      "{'eval_loss': 0.4139365553855896, 'eval_f1': 0.0, 'eval_runtime': 15.6556, 'eval_samples_per_second': 58.19, 'eval_steps_per_second': 0.958, 'epoch': 41.0}\n",
      "{'loss': 0.4765, 'learning_rate': 4.315909090909091e-05, 'epoch': 41.05}\n",
      "{'loss': 0.4096, 'learning_rate': 4.3e-05, 'epoch': 42.0}\n",
      "{'eval_loss': 0.3286924660205841, 'eval_f1': 0.0, 'eval_runtime': 14.9899, 'eval_samples_per_second': 60.774, 'eval_steps_per_second': 1.001, 'epoch': 42.0}\n",
      "{'loss': 0.3541, 'learning_rate': 4.2840909090909095e-05, 'epoch': 42.95}\n",
      "{'eval_loss': 0.29744476079940796, 'eval_f1': 0.0, 'eval_runtime': 14.9987, 'eval_samples_per_second': 60.738, 'eval_steps_per_second': 1.0, 'epoch': 43.0}\n",
      "{'loss': 0.3233, 'learning_rate': 4.268181818181818e-05, 'epoch': 43.91}\n",
      "{'eval_loss': 0.28376710414886475, 'eval_f1': 0.0, 'eval_runtime': 15.7452, 'eval_samples_per_second': 57.859, 'eval_steps_per_second': 0.953, 'epoch': 44.0}\n",
      "{'loss': 0.3043, 'learning_rate': 4.2522727272727274e-05, 'epoch': 44.86}\n",
      "{'eval_loss': 0.27946123480796814, 'eval_f1': 0.0, 'eval_runtime': 14.8507, 'eval_samples_per_second': 61.344, 'eval_steps_per_second': 1.01, 'epoch': 45.0}\n",
      "{'loss': 0.2926, 'learning_rate': 4.236363636363637e-05, 'epoch': 45.82}\n",
      "{'eval_loss': 0.2716189920902252, 'eval_f1': 0.0, 'eval_runtime': 15.0523, 'eval_samples_per_second': 60.522, 'eval_steps_per_second': 0.997, 'epoch': 46.0}\n",
      "{'loss': 0.2806, 'learning_rate': 4.220454545454546e-05, 'epoch': 46.77}\n",
      "{'eval_loss': 0.27948668599128723, 'eval_f1': 0.021436227224008574, 'eval_runtime': 15.1393, 'eval_samples_per_second': 60.174, 'eval_steps_per_second': 0.991, 'epoch': 47.0}\n",
      "{'loss': 0.2751, 'learning_rate': 4.204545454545455e-05, 'epoch': 47.73}\n",
      "{'eval_loss': 0.26651519536972046, 'eval_f1': 0.0013149243918474688, 'eval_runtime': 14.9066, 'eval_samples_per_second': 61.114, 'eval_steps_per_second': 1.006, 'epoch': 48.0}\n",
      "{'loss': 0.2647, 'learning_rate': 4.188636363636364e-05, 'epoch': 48.68}\n",
      "{'eval_loss': 0.2614608705043793, 'eval_f1': 0.011251758087201124, 'eval_runtime': 15.1385, 'eval_samples_per_second': 60.178, 'eval_steps_per_second': 0.991, 'epoch': 49.0}\n",
      "{'loss': 0.2561, 'learning_rate': 4.1727272727272734e-05, 'epoch': 49.64}\n",
      "{'eval_loss': 0.26087838411331177, 'eval_f1': 0.006299212598425197, 'eval_runtime': 15.0877, 'eval_samples_per_second': 60.38, 'eval_steps_per_second': 0.994, 'epoch': 50.0}\n",
      "{'loss': 0.2623, 'learning_rate': 4.156818181818182e-05, 'epoch': 50.59}\n",
      "{'eval_loss': 0.2594263553619385, 'eval_f1': 0.009377664109121909, 'eval_runtime': 15.1615, 'eval_samples_per_second': 60.086, 'eval_steps_per_second': 0.989, 'epoch': 51.0}\n",
      "{'loss': 0.2482, 'learning_rate': 4.1409090909090907e-05, 'epoch': 51.55}\n",
      "{'eval_loss': 0.258372962474823, 'eval_f1': 0.012210012210012208, 'eval_runtime': 16.8714, 'eval_samples_per_second': 53.997, 'eval_steps_per_second': 0.889, 'epoch': 52.0}\n",
      "{'loss': 0.2506, 'learning_rate': 4.125e-05, 'epoch': 52.5}\n",
      "{'eval_loss': 0.2535386383533478, 'eval_f1': 0.007543611504007543, 'eval_runtime': 15.7727, 'eval_samples_per_second': 57.758, 'eval_steps_per_second': 0.951, 'epoch': 53.0}\n",
      "{'loss': 0.2331, 'learning_rate': 4.109090909090909e-05, 'epoch': 53.45}\n",
      "{'eval_loss': 0.25205501914024353, 'eval_f1': 0.012037037037037039, 'eval_runtime': 14.9854, 'eval_samples_per_second': 60.793, 'eval_steps_per_second': 1.001, 'epoch': 54.0}\n",
      "{'loss': 0.238, 'learning_rate': 4.093181818181818e-05, 'epoch': 54.41}\n",
      "{'eval_loss': 0.2508546710014343, 'eval_f1': 0.01298701298701299, 'eval_runtime': 15.9386, 'eval_samples_per_second': 57.157, 'eval_steps_per_second': 0.941, 'epoch': 55.0}\n",
      "{'loss': 0.2383, 'learning_rate': 4.077272727272727e-05, 'epoch': 55.36}\n",
      "{'eval_loss': 0.2507266402244568, 'eval_f1': 0.00917813934084272, 'eval_runtime': 15.7409, 'eval_samples_per_second': 57.875, 'eval_steps_per_second': 0.953, 'epoch': 56.0}\n",
      "{'loss': 0.2313, 'learning_rate': 4.0613636363636366e-05, 'epoch': 56.32}\n",
      "{'eval_loss': 0.247464120388031, 'eval_f1': 0.013008130081300813, 'eval_runtime': 15.3985, 'eval_samples_per_second': 59.162, 'eval_steps_per_second': 0.974, 'epoch': 57.0}\n",
      "{'loss': 0.2315, 'learning_rate': 4.045454545454546e-05, 'epoch': 57.27}\n",
      "{'eval_loss': 0.24540692567825317, 'eval_f1': 0.01098436839881707, 'eval_runtime': 15.5994, 'eval_samples_per_second': 58.4, 'eval_steps_per_second': 0.962, 'epoch': 58.0}\n",
      "{'loss': 0.2304, 'learning_rate': 4.0295454545454545e-05, 'epoch': 58.23}\n",
      "{'eval_loss': 0.24626147747039795, 'eval_f1': 0.01098436839881707, 'eval_runtime': 16.463, 'eval_samples_per_second': 55.336, 'eval_steps_per_second': 0.911, 'epoch': 59.0}\n",
      "{'loss': 0.2225, 'learning_rate': 4.013636363636364e-05, 'epoch': 59.18}\n",
      "{'eval_loss': 0.2491968423128128, 'eval_f1': 0.01304181051016494, 'eval_runtime': 15.0077, 'eval_samples_per_second': 60.702, 'eval_steps_per_second': 0.999, 'epoch': 60.0}\n",
      "{'loss': 0.2236, 'learning_rate': 3.997727272727273e-05, 'epoch': 60.14}\n",
      "{'eval_loss': 0.2428533285856247, 'eval_f1': 0.009474590869939707, 'eval_runtime': 14.8358, 'eval_samples_per_second': 61.405, 'eval_steps_per_second': 1.011, 'epoch': 61.0}\n",
      "{'loss': 0.2194, 'learning_rate': 3.981818181818182e-05, 'epoch': 61.09}\n",
      "{'eval_loss': 0.24331416189670563, 'eval_f1': 0.012835032087580217, 'eval_runtime': 16.0359, 'eval_samples_per_second': 56.81, 'eval_steps_per_second': 0.935, 'epoch': 62.0}\n",
      "{'loss': 0.2232, 'learning_rate': 3.965909090909091e-05, 'epoch': 62.05}\n",
      "{'loss': 0.2176, 'learning_rate': 3.9500000000000005e-05, 'epoch': 63.0}\n",
      "{'eval_loss': 0.24244648218154907, 'eval_f1': 0.011124354390147001, 'eval_runtime': 15.0347, 'eval_samples_per_second': 60.593, 'eval_steps_per_second': 0.998, 'epoch': 63.0}\n",
      "{'loss': 0.2159, 'learning_rate': 3.93409090909091e-05, 'epoch': 63.95}\n",
      "{'eval_loss': 0.24171185493469238, 'eval_f1': 0.014043783560512184, 'eval_runtime': 15.0478, 'eval_samples_per_second': 60.541, 'eval_steps_per_second': 0.997, 'epoch': 64.0}\n",
      "{'loss': 0.2163, 'learning_rate': 3.9181818181818184e-05, 'epoch': 64.91}\n",
      "{'eval_loss': 0.24005372822284698, 'eval_f1': 0.011182795698924731, 'eval_runtime': 16.228, 'eval_samples_per_second': 56.137, 'eval_steps_per_second': 0.924, 'epoch': 65.0}\n",
      "{'loss': 0.2152, 'learning_rate': 3.902272727272727e-05, 'epoch': 65.86}\n",
      "{'eval_loss': 0.2402976155281067, 'eval_f1': 0.01355357899195256, 'eval_runtime': 15.8001, 'eval_samples_per_second': 57.658, 'eval_steps_per_second': 0.949, 'epoch': 66.0}\n",
      "{'loss': 0.2125, 'learning_rate': 3.8863636363636364e-05, 'epoch': 66.82}\n",
      "{'eval_loss': 0.23948463797569275, 'eval_f1': 0.013728013728013728, 'eval_runtime': 14.9302, 'eval_samples_per_second': 61.017, 'eval_steps_per_second': 1.005, 'epoch': 67.0}\n",
      "{'loss': 0.2105, 'learning_rate': 3.870454545454546e-05, 'epoch': 67.77}\n",
      "{'eval_loss': 0.23785994946956635, 'eval_f1': 0.008391608391608392, 'eval_runtime': 15.2468, 'eval_samples_per_second': 59.75, 'eval_steps_per_second': 0.984, 'epoch': 68.0}\n",
      "{'loss': 0.209, 'learning_rate': 3.8545454545454544e-05, 'epoch': 68.73}\n",
      "{'eval_loss': 0.24083924293518066, 'eval_f1': 0.008620689655172414, 'eval_runtime': 14.8118, 'eval_samples_per_second': 61.505, 'eval_steps_per_second': 1.013, 'epoch': 69.0}\n",
      "{'loss': 0.209, 'learning_rate': 3.838636363636364e-05, 'epoch': 69.68}\n",
      "{'eval_loss': 0.24275420606136322, 'eval_f1': 0.01366742596810934, 'eval_runtime': 15.7538, 'eval_samples_per_second': 57.827, 'eval_steps_per_second': 0.952, 'epoch': 70.0}\n",
      "{'loss': 0.2106, 'learning_rate': 3.822727272727273e-05, 'epoch': 70.64}\n",
      "{'eval_loss': 0.23980645835399628, 'eval_f1': 0.00947867298578199, 'eval_runtime': 15.4336, 'eval_samples_per_second': 59.027, 'eval_steps_per_second': 0.972, 'epoch': 71.0}\n",
      "{'loss': 0.2081, 'learning_rate': 3.8068181818181816e-05, 'epoch': 71.59}\n",
      "{'eval_loss': 0.23828554153442383, 'eval_f1': 0.013215859030837003, 'eval_runtime': 14.8596, 'eval_samples_per_second': 61.307, 'eval_steps_per_second': 1.009, 'epoch': 72.0}\n",
      "{'loss': 0.1999, 'learning_rate': 3.790909090909091e-05, 'epoch': 72.55}\n",
      "{'eval_loss': 0.23614761233329773, 'eval_f1': 0.020876826722338204, 'eval_runtime': 14.9916, 'eval_samples_per_second': 60.767, 'eval_steps_per_second': 1.001, 'epoch': 73.0}\n",
      "{'loss': 0.2026, 'learning_rate': 3.775e-05, 'epoch': 73.5}\n",
      "{'eval_loss': 0.2404864877462387, 'eval_f1': 0.014150943396226417, 'eval_runtime': 15.2884, 'eval_samples_per_second': 59.588, 'eval_steps_per_second': 0.981, 'epoch': 74.0}\n",
      "{'loss': 0.2028, 'learning_rate': 3.7590909090909096e-05, 'epoch': 74.45}\n",
      "{'eval_loss': 0.23964503407478333, 'eval_f1': 0.016442451420029893, 'eval_runtime': 14.8442, 'eval_samples_per_second': 61.371, 'eval_steps_per_second': 1.01, 'epoch': 75.0}\n",
      "{'loss': 0.1997, 'learning_rate': 3.743181818181818e-05, 'epoch': 75.41}\n",
      "{'eval_loss': 0.2363109439611435, 'eval_f1': 0.01327433628318584, 'eval_runtime': 14.8321, 'eval_samples_per_second': 61.421, 'eval_steps_per_second': 1.011, 'epoch': 76.0}\n",
      "{'loss': 0.2037, 'learning_rate': 3.7272727272727276e-05, 'epoch': 76.36}\n",
      "{'eval_loss': 0.23733025789260864, 'eval_f1': 0.010279001468428783, 'eval_runtime': 15.3175, 'eval_samples_per_second': 59.474, 'eval_steps_per_second': 0.979, 'epoch': 77.0}\n",
      "{'loss': 0.1975, 'learning_rate': 3.711363636363637e-05, 'epoch': 77.32}\n",
      "{'eval_loss': 0.24019266664981842, 'eval_f1': 0.011834319526627219, 'eval_runtime': 14.6915, 'eval_samples_per_second': 62.009, 'eval_steps_per_second': 1.021, 'epoch': 78.0}\n",
      "{'loss': 0.1973, 'learning_rate': 3.6954545454545455e-05, 'epoch': 78.27}\n",
      "{'eval_loss': 0.23750333487987518, 'eval_f1': 0.014267185473411154, 'eval_runtime': 14.981, 'eval_samples_per_second': 60.81, 'eval_steps_per_second': 1.001, 'epoch': 79.0}\n",
      "{'loss': 0.1999, 'learning_rate': 3.679545454545455e-05, 'epoch': 79.23}\n",
      "{'eval_loss': 0.23668637871742249, 'eval_f1': 0.015406162464985995, 'eval_runtime': 14.8543, 'eval_samples_per_second': 61.329, 'eval_steps_per_second': 1.01, 'epoch': 80.0}\n",
      "{'loss': 0.1984, 'learning_rate': 3.663636363636364e-05, 'epoch': 80.18}\n",
      "{'eval_loss': 0.23691853880882263, 'eval_f1': 0.013363028953229397, 'eval_runtime': 14.6804, 'eval_samples_per_second': 62.056, 'eval_steps_per_second': 1.022, 'epoch': 81.0}\n",
      "{'loss': 0.1961, 'learning_rate': 3.647727272727273e-05, 'epoch': 81.14}\n",
      "{'eval_loss': 0.23797613382339478, 'eval_f1': 0.01082753286929621, 'eval_runtime': 16.6164, 'eval_samples_per_second': 54.825, 'eval_steps_per_second': 0.903, 'epoch': 82.0}\n",
      "{'loss': 0.1951, 'learning_rate': 3.6318181818181815e-05, 'epoch': 82.09}\n",
      "{'eval_loss': 0.23476789891719818, 'eval_f1': 0.013544018058690746, 'eval_runtime': 14.823, 'eval_samples_per_second': 61.459, 'eval_steps_per_second': 1.012, 'epoch': 83.0}\n",
      "{'loss': 0.1932, 'learning_rate': 3.615909090909091e-05, 'epoch': 83.05}\n",
      "{'loss': 0.1967, 'learning_rate': 3.6e-05, 'epoch': 84.0}\n",
      "{'eval_loss': 0.23307767510414124, 'eval_f1': 0.011111111111111112, 'eval_runtime': 15.67, 'eval_samples_per_second': 58.137, 'eval_steps_per_second': 0.957, 'epoch': 84.0}\n",
      "{'loss': 0.1937, 'learning_rate': 3.5840909090909094e-05, 'epoch': 84.95}\n",
      "{'eval_loss': 0.23416543006896973, 'eval_f1': 0.010862186014935507, 'eval_runtime': 14.8008, 'eval_samples_per_second': 61.551, 'eval_steps_per_second': 1.013, 'epoch': 85.0}\n",
      "{'loss': 0.1934, 'learning_rate': 3.568181818181818e-05, 'epoch': 85.91}\n",
      "{'eval_loss': 0.23374682664871216, 'eval_f1': 0.008110300081103002, 'eval_runtime': 15.6997, 'eval_samples_per_second': 58.026, 'eval_steps_per_second': 0.955, 'epoch': 86.0}\n",
      "{'loss': 0.1879, 'learning_rate': 3.5522727272727274e-05, 'epoch': 86.86}\n",
      "{'eval_loss': 0.24334686994552612, 'eval_f1': 0.008051529790660225, 'eval_runtime': 14.7868, 'eval_samples_per_second': 61.609, 'eval_steps_per_second': 1.014, 'epoch': 87.0}\n",
      "{'loss': 0.1986, 'learning_rate': 3.536363636363637e-05, 'epoch': 87.82}\n",
      "{'eval_loss': 0.2342846542596817, 'eval_f1': 0.013015184381778741, 'eval_runtime': 14.9711, 'eval_samples_per_second': 60.85, 'eval_steps_per_second': 1.002, 'epoch': 88.0}\n",
      "{'loss': 0.1831, 'learning_rate': 3.520454545454545e-05, 'epoch': 88.77}\n",
      "{'eval_loss': 0.23485586047172546, 'eval_f1': 0.007541478129713424, 'eval_runtime': 15.8183, 'eval_samples_per_second': 57.592, 'eval_steps_per_second': 0.948, 'epoch': 89.0}\n",
      "{'loss': 0.1959, 'learning_rate': 3.5045454545454547e-05, 'epoch': 89.73}\n",
      "{'eval_loss': 0.23647542297840118, 'eval_f1': 0.01622418879056047, 'eval_runtime': 15.4546, 'eval_samples_per_second': 58.947, 'eval_steps_per_second': 0.971, 'epoch': 90.0}\n",
      "{'loss': 0.1889, 'learning_rate': 3.488636363636364e-05, 'epoch': 90.68}\n",
      "{'eval_loss': 0.23616595566272736, 'eval_f1': 0.014492753623188406, 'eval_runtime': 14.7895, 'eval_samples_per_second': 61.598, 'eval_steps_per_second': 1.014, 'epoch': 91.0}\n",
      "{'loss': 0.1895, 'learning_rate': 3.472727272727273e-05, 'epoch': 91.64}\n",
      "{'eval_loss': 0.24121984839439392, 'eval_f1': 0.013483146067415729, 'eval_runtime': 14.7084, 'eval_samples_per_second': 61.937, 'eval_steps_per_second': 1.02, 'epoch': 92.0}\n",
      "{'loss': 0.1878, 'learning_rate': 3.456818181818182e-05, 'epoch': 92.59}\n",
      "{'eval_loss': 0.23591946065425873, 'eval_f1': 0.010928961748633878, 'eval_runtime': 14.8364, 'eval_samples_per_second': 61.403, 'eval_steps_per_second': 1.011, 'epoch': 93.0}\n",
      "{'loss': 0.1848, 'learning_rate': 3.440909090909091e-05, 'epoch': 93.55}\n",
      "{'eval_loss': 0.23455944657325745, 'eval_f1': 0.01144492131616595, 'eval_runtime': 15.0381, 'eval_samples_per_second': 60.579, 'eval_steps_per_second': 0.997, 'epoch': 94.0}\n",
      "{'loss': 0.1925, 'learning_rate': 3.4250000000000006e-05, 'epoch': 94.5}\n",
      "{'eval_loss': 0.23502182960510254, 'eval_f1': 0.014094432699083859, 'eval_runtime': 15.2489, 'eval_samples_per_second': 59.742, 'eval_steps_per_second': 0.984, 'epoch': 95.0}\n",
      "{'loss': 0.1795, 'learning_rate': 3.409090909090909e-05, 'epoch': 95.45}\n",
      "{'eval_loss': 0.2390318214893341, 'eval_f1': 0.015636105188343994, 'eval_runtime': 14.6238, 'eval_samples_per_second': 62.296, 'eval_steps_per_second': 1.026, 'epoch': 96.0}\n",
      "{'loss': 0.1931, 'learning_rate': 3.393181818181818e-05, 'epoch': 96.41}\n",
      "{'eval_loss': 0.237056165933609, 'eval_f1': 0.010582010582010581, 'eval_runtime': 15.6269, 'eval_samples_per_second': 58.297, 'eval_steps_per_second': 0.96, 'epoch': 97.0}\n",
      "{'loss': 0.1825, 'learning_rate': 3.377272727272727e-05, 'epoch': 97.36}\n",
      "{'eval_loss': 0.2365075796842575, 'eval_f1': 0.018093249826026444, 'eval_runtime': 16.6719, 'eval_samples_per_second': 54.643, 'eval_steps_per_second': 0.9, 'epoch': 98.0}\n",
      "{'loss': 0.1845, 'learning_rate': 3.3613636363636365e-05, 'epoch': 98.32}\n",
      "{'eval_loss': 0.23613078892230988, 'eval_f1': 0.024286581663630843, 'eval_runtime': 14.8536, 'eval_samples_per_second': 61.332, 'eval_steps_per_second': 1.01, 'epoch': 99.0}\n",
      "{'loss': 0.1856, 'learning_rate': 3.345454545454546e-05, 'epoch': 99.27}\n",
      "{'eval_loss': 0.23603330552577972, 'eval_f1': 0.022028985507246374, 'eval_runtime': 14.8165, 'eval_samples_per_second': 61.486, 'eval_steps_per_second': 1.012, 'epoch': 100.0}\n",
      "{'loss': 0.1777, 'learning_rate': 3.3295454545454545e-05, 'epoch': 100.23}\n",
      "{'eval_loss': 0.23921768367290497, 'eval_f1': 0.018207282913165264, 'eval_runtime': 15.0254, 'eval_samples_per_second': 60.631, 'eval_steps_per_second': 0.998, 'epoch': 101.0}\n",
      "{'loss': 0.1883, 'learning_rate': 3.313636363636364e-05, 'epoch': 101.18}\n",
      "{'eval_loss': 0.2355591207742691, 'eval_f1': 0.017026850032743946, 'eval_runtime': 15.6865, 'eval_samples_per_second': 58.076, 'eval_steps_per_second': 0.956, 'epoch': 102.0}\n",
      "{'loss': 0.1784, 'learning_rate': 3.297727272727273e-05, 'epoch': 102.14}\n",
      "{'eval_loss': 0.23530089855194092, 'eval_f1': 0.018207282913165264, 'eval_runtime': 16.7111, 'eval_samples_per_second': 54.515, 'eval_steps_per_second': 0.898, 'epoch': 103.0}\n",
      "{'loss': 0.1854, 'learning_rate': 3.281818181818182e-05, 'epoch': 103.09}\n",
      "{'eval_loss': 0.23465467989444733, 'eval_f1': 0.02154882154882155, 'eval_runtime': 14.9509, 'eval_samples_per_second': 60.933, 'eval_steps_per_second': 1.003, 'epoch': 104.0}\n",
      "{'loss': 0.1825, 'learning_rate': 3.265909090909091e-05, 'epoch': 104.05}\n",
      "{'loss': 0.1785, 'learning_rate': 3.2500000000000004e-05, 'epoch': 105.0}\n",
      "{'eval_loss': 0.2327919602394104, 'eval_f1': 0.021592442645074223, 'eval_runtime': 15.1617, 'eval_samples_per_second': 60.086, 'eval_steps_per_second': 0.989, 'epoch': 105.0}\n",
      "{'loss': 0.1818, 'learning_rate': 3.23409090909091e-05, 'epoch': 105.95}\n",
      "{'eval_loss': 0.23430095613002777, 'eval_f1': 0.0176510522742702, 'eval_runtime': 16.8499, 'eval_samples_per_second': 54.066, 'eval_steps_per_second': 0.89, 'epoch': 106.0}\n",
      "{'loss': 0.1768, 'learning_rate': 3.2181818181818184e-05, 'epoch': 106.91}\n",
      "{'eval_loss': 0.23053842782974243, 'eval_f1': 0.014294996751137103, 'eval_runtime': 15.512, 'eval_samples_per_second': 58.729, 'eval_steps_per_second': 0.967, 'epoch': 107.0}\n",
      "{'loss': 0.1804, 'learning_rate': 3.202272727272728e-05, 'epoch': 107.86}\n",
      "{'eval_loss': 0.22991320490837097, 'eval_f1': 0.01779603011635866, 'eval_runtime': 15.0236, 'eval_samples_per_second': 60.638, 'eval_steps_per_second': 0.998, 'epoch': 108.0}\n",
      "{'loss': 0.1805, 'learning_rate': 3.186363636363637e-05, 'epoch': 108.82}\n",
      "{'eval_loss': 0.23155422508716583, 'eval_f1': 0.017759562841530054, 'eval_runtime': 15.5696, 'eval_samples_per_second': 58.511, 'eval_steps_per_second': 0.963, 'epoch': 109.0}\n",
      "{'loss': 0.182, 'learning_rate': 3.1704545454545456e-05, 'epoch': 109.77}\n",
      "{'eval_loss': 0.22832109034061432, 'eval_f1': 0.01840894148586456, 'eval_runtime': 14.9949, 'eval_samples_per_second': 60.754, 'eval_steps_per_second': 1.0, 'epoch': 110.0}\n",
      "{'loss': 0.1752, 'learning_rate': 3.154545454545454e-05, 'epoch': 110.73}\n",
      "{'eval_loss': 0.22997711598873138, 'eval_f1': 0.015312131919905771, 'eval_runtime': 15.7216, 'eval_samples_per_second': 57.946, 'eval_steps_per_second': 0.954, 'epoch': 111.0}\n",
      "{'loss': 0.1813, 'learning_rate': 3.1386363636363636e-05, 'epoch': 111.68}\n",
      "{'eval_loss': 0.2310415804386139, 'eval_f1': 0.03654188948306595, 'eval_runtime': 14.8877, 'eval_samples_per_second': 61.192, 'eval_steps_per_second': 1.008, 'epoch': 112.0}\n",
      "{'loss': 0.1747, 'learning_rate': 3.122727272727273e-05, 'epoch': 112.64}\n",
      "{'eval_loss': 0.23014166951179504, 'eval_f1': 0.015197568389057751, 'eval_runtime': 14.8507, 'eval_samples_per_second': 61.344, 'eval_steps_per_second': 1.01, 'epoch': 113.0}\n",
      "{'loss': 0.1815, 'learning_rate': 3.1068181818181816e-05, 'epoch': 113.59}\n",
      "{'eval_loss': 0.23096251487731934, 'eval_f1': 0.04231433506044904, 'eval_runtime': 14.8294, 'eval_samples_per_second': 61.432, 'eval_steps_per_second': 1.012, 'epoch': 114.0}\n",
      "{'loss': 0.1734, 'learning_rate': 3.090909090909091e-05, 'epoch': 114.55}\n",
      "{'eval_loss': 0.22965338826179504, 'eval_f1': 0.04642313546423135, 'eval_runtime': 15.2835, 'eval_samples_per_second': 59.607, 'eval_steps_per_second': 0.981, 'epoch': 115.0}\n",
      "{'loss': 0.1821, 'learning_rate': 3.075e-05, 'epoch': 115.5}\n",
      "{'eval_loss': 0.2294943630695343, 'eval_f1': 0.03239556692242115, 'eval_runtime': 14.9984, 'eval_samples_per_second': 60.74, 'eval_steps_per_second': 1.0, 'epoch': 116.0}\n",
      "{'loss': 0.1687, 'learning_rate': 3.0590909090909095e-05, 'epoch': 116.45}\n",
      "{'eval_loss': 0.2293519824743271, 'eval_f1': 0.03773584905660377, 'eval_runtime': 16.4984, 'eval_samples_per_second': 55.217, 'eval_steps_per_second': 0.909, 'epoch': 117.0}\n",
      "{'loss': 0.1782, 'learning_rate': 3.0431818181818185e-05, 'epoch': 117.41}\n",
      "{'eval_loss': 0.23030540347099304, 'eval_f1': 0.05463347164591978, 'eval_runtime': 14.8375, 'eval_samples_per_second': 61.398, 'eval_steps_per_second': 1.011, 'epoch': 118.0}\n",
      "{'loss': 0.1801, 'learning_rate': 3.0272727272727275e-05, 'epoch': 118.36}\n",
      "{'eval_loss': 0.228403702378273, 'eval_f1': 0.09446450060168471, 'eval_runtime': 14.8647, 'eval_samples_per_second': 61.286, 'eval_steps_per_second': 1.009, 'epoch': 119.0}\n",
      "{'loss': 0.1752, 'learning_rate': 3.0113636363636365e-05, 'epoch': 119.32}\n",
      "{'eval_loss': 0.22874660789966583, 'eval_f1': 0.08205128205128205, 'eval_runtime': 14.8462, 'eval_samples_per_second': 61.363, 'eval_steps_per_second': 1.01, 'epoch': 120.0}\n",
      "{'loss': 0.1767, 'learning_rate': 2.9954545454545458e-05, 'epoch': 120.27}\n",
      "{'eval_loss': 0.22936254739761353, 'eval_f1': 0.0813473149030823, 'eval_runtime': 15.6665, 'eval_samples_per_second': 58.15, 'eval_steps_per_second': 0.957, 'epoch': 121.0}\n",
      "{'loss': 0.1698, 'learning_rate': 2.9795454545454548e-05, 'epoch': 121.23}\n",
      "{'eval_loss': 0.23007416725158691, 'eval_f1': 0.07246376811594203, 'eval_runtime': 14.8385, 'eval_samples_per_second': 61.394, 'eval_steps_per_second': 1.011, 'epoch': 122.0}\n",
      "{'loss': 0.1774, 'learning_rate': 2.963636363636364e-05, 'epoch': 122.18}\n",
      "{'eval_loss': 0.22677212953567505, 'eval_f1': 0.07147258163894023, 'eval_runtime': 16.5473, 'eval_samples_per_second': 55.054, 'eval_steps_per_second': 0.906, 'epoch': 123.0}\n",
      "{'loss': 0.1737, 'learning_rate': 2.947727272727273e-05, 'epoch': 123.14}\n",
      "{'eval_loss': 0.22483232617378235, 'eval_f1': 0.0765338393421885, 'eval_runtime': 14.8193, 'eval_samples_per_second': 61.474, 'eval_steps_per_second': 1.012, 'epoch': 124.0}\n",
      "{'loss': 0.1756, 'learning_rate': 2.9318181818181817e-05, 'epoch': 124.09}\n",
      "{'eval_loss': 0.22325630486011505, 'eval_f1': 0.07081339712918659, 'eval_runtime': 15.9452, 'eval_samples_per_second': 57.133, 'eval_steps_per_second': 0.941, 'epoch': 125.0}\n",
      "{'loss': 0.1717, 'learning_rate': 2.9159090909090907e-05, 'epoch': 125.05}\n",
      "{'loss': 0.1744, 'learning_rate': 2.9e-05, 'epoch': 126.0}\n",
      "{'eval_loss': 0.22556783258914948, 'eval_f1': 0.06049149338374293, 'eval_runtime': 15.3177, 'eval_samples_per_second': 59.473, 'eval_steps_per_second': 0.979, 'epoch': 126.0}\n",
      "{'loss': 0.1708, 'learning_rate': 2.884090909090909e-05, 'epoch': 126.95}\n",
      "{'eval_loss': 0.2278403788805008, 'eval_f1': 0.07166337935568705, 'eval_runtime': 16.8368, 'eval_samples_per_second': 54.108, 'eval_steps_per_second': 0.891, 'epoch': 127.0}\n",
      "{'loss': 0.1769, 'learning_rate': 2.8681818181818183e-05, 'epoch': 127.91}\n",
      "{'eval_loss': 0.22893205285072327, 'eval_f1': 0.07024390243902438, 'eval_runtime': 15.1852, 'eval_samples_per_second': 59.993, 'eval_steps_per_second': 0.988, 'epoch': 128.0}\n",
      "{'loss': 0.1655, 'learning_rate': 2.8522727272727273e-05, 'epoch': 128.86}\n",
      "{'eval_loss': 0.22689153254032135, 'eval_f1': 0.05523066926575698, 'eval_runtime': 14.9519, 'eval_samples_per_second': 60.929, 'eval_steps_per_second': 1.003, 'epoch': 129.0}\n",
      "{'loss': 0.173, 'learning_rate': 2.8363636363636363e-05, 'epoch': 129.82}\n",
      "{'eval_loss': 0.22990939021110535, 'eval_f1': 0.0638224072147069, 'eval_runtime': 14.9033, 'eval_samples_per_second': 61.127, 'eval_steps_per_second': 1.006, 'epoch': 130.0}\n",
      "{'loss': 0.1744, 'learning_rate': 2.8204545454545456e-05, 'epoch': 130.77}\n",
      "{'eval_loss': 0.22618941962718964, 'eval_f1': 0.07413997627520759, 'eval_runtime': 17.2007, 'eval_samples_per_second': 52.963, 'eval_steps_per_second': 0.872, 'epoch': 131.0}\n",
      "{'loss': 0.1706, 'learning_rate': 2.8045454545454546e-05, 'epoch': 131.73}\n",
      "{'eval_loss': 0.22891461849212646, 'eval_f1': 0.09177820267686425, 'eval_runtime': 14.8693, 'eval_samples_per_second': 61.267, 'eval_steps_per_second': 1.009, 'epoch': 132.0}\n",
      "{'loss': 0.1704, 'learning_rate': 2.788636363636364e-05, 'epoch': 132.68}\n",
      "{'eval_loss': 0.22678416967391968, 'eval_f1': 0.10589239965841163, 'eval_runtime': 15.5206, 'eval_samples_per_second': 58.696, 'eval_steps_per_second': 0.966, 'epoch': 133.0}\n",
      "{'loss': 0.1664, 'learning_rate': 2.772727272727273e-05, 'epoch': 133.64}\n",
      "{'eval_loss': 0.22713269293308258, 'eval_f1': 0.10610079575596816, 'eval_runtime': 15.2639, 'eval_samples_per_second': 59.683, 'eval_steps_per_second': 0.983, 'epoch': 134.0}\n",
      "{'loss': 0.1706, 'learning_rate': 2.7568181818181822e-05, 'epoch': 134.59}\n",
      "{'eval_loss': 0.2282291203737259, 'eval_f1': 0.10603397773872292, 'eval_runtime': 15.2175, 'eval_samples_per_second': 59.865, 'eval_steps_per_second': 0.986, 'epoch': 135.0}\n",
      "{'loss': 0.1687, 'learning_rate': 2.7409090909090912e-05, 'epoch': 135.55}\n",
      "{'eval_loss': 0.22752182185649872, 'eval_f1': 0.10631424375917768, 'eval_runtime': 15.5068, 'eval_samples_per_second': 58.748, 'eval_steps_per_second': 0.967, 'epoch': 136.0}\n",
      "{'loss': 0.1712, 'learning_rate': 2.725e-05, 'epoch': 136.5}\n",
      "{'eval_loss': 0.2277369201183319, 'eval_f1': 0.10495963091118798, 'eval_runtime': 14.8916, 'eval_samples_per_second': 61.175, 'eval_steps_per_second': 1.007, 'epoch': 137.0}\n",
      "{'loss': 0.1689, 'learning_rate': 2.7090909090909095e-05, 'epoch': 137.45}\n",
      "{'eval_loss': 0.22871002554893494, 'eval_f1': 0.10578320255739611, 'eval_runtime': 14.884, 'eval_samples_per_second': 61.207, 'eval_steps_per_second': 1.008, 'epoch': 138.0}\n",
      "{'loss': 0.1691, 'learning_rate': 2.6931818181818185e-05, 'epoch': 138.41}\n",
      "{'eval_loss': 0.224896639585495, 'eval_f1': 0.10520297312750142, 'eval_runtime': 14.8258, 'eval_samples_per_second': 61.447, 'eval_steps_per_second': 1.012, 'epoch': 139.0}\n",
      "{'loss': 0.1661, 'learning_rate': 2.677272727272727e-05, 'epoch': 139.36}\n",
      "{'eval_loss': 0.22447484731674194, 'eval_f1': 0.13219630759179216, 'eval_runtime': 14.8622, 'eval_samples_per_second': 61.296, 'eval_steps_per_second': 1.009, 'epoch': 140.0}\n",
      "{'loss': 0.1633, 'learning_rate': 2.6613636363636364e-05, 'epoch': 140.32}\n",
      "{'eval_loss': 0.22588534653186798, 'eval_f1': 0.17619622475856014, 'eval_runtime': 16.6415, 'eval_samples_per_second': 54.742, 'eval_steps_per_second': 0.901, 'epoch': 141.0}\n",
      "{'loss': 0.1693, 'learning_rate': 2.6454545454545454e-05, 'epoch': 141.27}\n",
      "{'eval_loss': 0.22685351967811584, 'eval_f1': 0.17613944520325056, 'eval_runtime': 15.1261, 'eval_samples_per_second': 60.227, 'eval_steps_per_second': 0.992, 'epoch': 142.0}\n",
      "{'loss': 0.1671, 'learning_rate': 2.6295454545454544e-05, 'epoch': 142.23}\n",
      "{'eval_loss': 0.22575153410434723, 'eval_f1': 0.1968981693472027, 'eval_runtime': 15.0046, 'eval_samples_per_second': 60.715, 'eval_steps_per_second': 1.0, 'epoch': 143.0}\n",
      "{'loss': 0.1633, 'learning_rate': 2.6136363636363637e-05, 'epoch': 143.18}\n",
      "{'eval_loss': 0.22559088468551636, 'eval_f1': 0.19757761214442013, 'eval_runtime': 15.385, 'eval_samples_per_second': 59.214, 'eval_steps_per_second': 0.975, 'epoch': 144.0}\n",
      "{'loss': 0.1728, 'learning_rate': 2.5977272727272727e-05, 'epoch': 144.14}\n",
      "{'eval_loss': 0.22654226422309875, 'eval_f1': 0.218689116188452, 'eval_runtime': 15.0174, 'eval_samples_per_second': 60.663, 'eval_steps_per_second': 0.999, 'epoch': 145.0}\n",
      "{'loss': 0.1651, 'learning_rate': 2.581818181818182e-05, 'epoch': 145.09}\n",
      "{'eval_loss': 0.22615933418273926, 'eval_f1': 0.20236675870147255, 'eval_runtime': 14.7941, 'eval_samples_per_second': 61.579, 'eval_steps_per_second': 1.014, 'epoch': 146.0}\n",
      "{'loss': 0.164, 'learning_rate': 2.565909090909091e-05, 'epoch': 146.05}\n",
      "{'loss': 0.1642, 'learning_rate': 2.5500000000000003e-05, 'epoch': 147.0}\n",
      "{'eval_loss': 0.22875282168388367, 'eval_f1': 0.21035216725879238, 'eval_runtime': 14.9225, 'eval_samples_per_second': 61.049, 'eval_steps_per_second': 1.005, 'epoch': 147.0}\n",
      "{'loss': 0.1651, 'learning_rate': 2.5340909090909093e-05, 'epoch': 147.95}\n",
      "{'eval_loss': 0.2279045134782791, 'eval_f1': 0.22693541263945904, 'eval_runtime': 15.0381, 'eval_samples_per_second': 60.58, 'eval_steps_per_second': 0.997, 'epoch': 148.0}\n",
      "{'loss': 0.1657, 'learning_rate': 2.5181818181818183e-05, 'epoch': 148.91}\n",
      "{'eval_loss': 0.2281491607427597, 'eval_f1': 0.209987323239762, 'eval_runtime': 14.7643, 'eval_samples_per_second': 61.703, 'eval_steps_per_second': 1.016, 'epoch': 149.0}\n",
      "{'loss': 0.1625, 'learning_rate': 2.5022727272727276e-05, 'epoch': 149.86}\n",
      "{'eval_loss': 0.22690708935260773, 'eval_f1': 0.20791243382458147, 'eval_runtime': 16.1805, 'eval_samples_per_second': 56.302, 'eval_steps_per_second': 0.927, 'epoch': 150.0}\n",
      "{'loss': 0.1642, 'learning_rate': 2.4863636363636362e-05, 'epoch': 150.82}\n",
      "{'eval_loss': 0.22482404112815857, 'eval_f1': 0.20857533930308877, 'eval_runtime': 15.6252, 'eval_samples_per_second': 58.303, 'eval_steps_per_second': 0.96, 'epoch': 151.0}\n",
      "{'loss': 0.1639, 'learning_rate': 2.4704545454545456e-05, 'epoch': 151.77}\n",
      "{'eval_loss': 0.22789981961250305, 'eval_f1': 0.22490754437869823, 'eval_runtime': 14.7144, 'eval_samples_per_second': 61.912, 'eval_steps_per_second': 1.019, 'epoch': 152.0}\n",
      "{'loss': 0.1649, 'learning_rate': 2.4545454545454545e-05, 'epoch': 152.73}\n",
      "{'eval_loss': 0.22798992693424225, 'eval_f1': 0.22062831079183728, 'eval_runtime': 15.6206, 'eval_samples_per_second': 58.321, 'eval_steps_per_second': 0.96, 'epoch': 153.0}\n",
      "{'loss': 0.1597, 'learning_rate': 2.438636363636364e-05, 'epoch': 153.68}\n",
      "{'eval_loss': 0.22493626177310944, 'eval_f1': 0.21902539950104905, 'eval_runtime': 14.8683, 'eval_samples_per_second': 61.271, 'eval_steps_per_second': 1.009, 'epoch': 154.0}\n",
      "{'loss': 0.1594, 'learning_rate': 2.422727272727273e-05, 'epoch': 154.64}\n",
      "{'eval_loss': 0.22627294063568115, 'eval_f1': 0.2238724641949855, 'eval_runtime': 14.6158, 'eval_samples_per_second': 62.33, 'eval_steps_per_second': 1.026, 'epoch': 155.0}\n",
      "{'loss': 0.1655, 'learning_rate': 2.406818181818182e-05, 'epoch': 155.59}\n",
      "{'eval_loss': 0.22597870230674744, 'eval_f1': 0.21302692442407004, 'eval_runtime': 14.8597, 'eval_samples_per_second': 61.307, 'eval_steps_per_second': 1.009, 'epoch': 156.0}\n",
      "{'loss': 0.1622, 'learning_rate': 2.390909090909091e-05, 'epoch': 156.55}\n",
      "{'eval_loss': 0.22498422861099243, 'eval_f1': 0.22444245821789818, 'eval_runtime': 14.9455, 'eval_samples_per_second': 60.955, 'eval_steps_per_second': 1.004, 'epoch': 157.0}\n",
      "{'loss': 0.1631, 'learning_rate': 2.375e-05, 'epoch': 157.5}\n",
      "{'eval_loss': 0.22418515384197235, 'eval_f1': 0.223406154748696, 'eval_runtime': 15.0383, 'eval_samples_per_second': 60.579, 'eval_steps_per_second': 0.997, 'epoch': 158.0}\n",
      "{'loss': 0.1598, 'learning_rate': 2.359090909090909e-05, 'epoch': 158.45}\n",
      "{'eval_loss': 0.22474196553230286, 'eval_f1': 0.223119042437432, 'eval_runtime': 14.9019, 'eval_samples_per_second': 61.133, 'eval_steps_per_second': 1.007, 'epoch': 159.0}\n",
      "{'loss': 0.1616, 'learning_rate': 2.343181818181818e-05, 'epoch': 159.41}\n",
      "{'eval_loss': 0.22885018587112427, 'eval_f1': 0.2396792555196925, 'eval_runtime': 14.7885, 'eval_samples_per_second': 61.602, 'eval_steps_per_second': 1.014, 'epoch': 160.0}\n",
      "{'loss': 0.1638, 'learning_rate': 2.3272727272727274e-05, 'epoch': 160.36}\n",
      "{'eval_loss': 0.22445707023143768, 'eval_f1': 0.22460300414781806, 'eval_runtime': 15.7511, 'eval_samples_per_second': 57.837, 'eval_steps_per_second': 0.952, 'epoch': 161.0}\n",
      "{'loss': 0.1501, 'learning_rate': 2.3113636363636364e-05, 'epoch': 161.32}\n",
      "{'eval_loss': 0.22650876641273499, 'eval_f1': 0.2299789233022541, 'eval_runtime': 14.8031, 'eval_samples_per_second': 61.541, 'eval_steps_per_second': 1.013, 'epoch': 162.0}\n",
      "{'loss': 0.1678, 'learning_rate': 2.2954545454545457e-05, 'epoch': 162.27}\n",
      "{'eval_loss': 0.2284841239452362, 'eval_f1': 0.23066930456530665, 'eval_runtime': 14.8633, 'eval_samples_per_second': 61.292, 'eval_steps_per_second': 1.009, 'epoch': 163.0}\n",
      "{'loss': 0.1576, 'learning_rate': 2.2795454545454547e-05, 'epoch': 163.23}\n",
      "{'eval_loss': 0.22371596097946167, 'eval_f1': 0.2214043987893549, 'eval_runtime': 15.0463, 'eval_samples_per_second': 60.546, 'eval_steps_per_second': 0.997, 'epoch': 164.0}\n",
      "{'loss': 0.1599, 'learning_rate': 2.2636363636363637e-05, 'epoch': 164.18}\n",
      "{'eval_loss': 0.22612187266349792, 'eval_f1': 0.24005193588604412, 'eval_runtime': 14.712, 'eval_samples_per_second': 61.922, 'eval_steps_per_second': 1.02, 'epoch': 165.0}\n",
      "{'loss': 0.1557, 'learning_rate': 2.2477272727272727e-05, 'epoch': 165.14}\n",
      "{'eval_loss': 0.22139745950698853, 'eval_f1': 0.22497949461242006, 'eval_runtime': 15.3708, 'eval_samples_per_second': 59.268, 'eval_steps_per_second': 0.976, 'epoch': 166.0}\n",
      "{'loss': 0.1615, 'learning_rate': 2.231818181818182e-05, 'epoch': 166.09}\n",
      "{'eval_loss': 0.2213362157344818, 'eval_f1': 0.21961232823620805, 'eval_runtime': 15.5444, 'eval_samples_per_second': 58.606, 'eval_steps_per_second': 0.965, 'epoch': 167.0}\n",
      "{'loss': 0.1592, 'learning_rate': 2.215909090909091e-05, 'epoch': 167.05}\n",
      "{'loss': 0.1567, 'learning_rate': 2.2000000000000003e-05, 'epoch': 168.0}\n",
      "{'eval_loss': 0.2236429899930954, 'eval_f1': 0.227774257178304, 'eval_runtime': 15.8315, 'eval_samples_per_second': 57.544, 'eval_steps_per_second': 0.947, 'epoch': 168.0}\n",
      "{'loss': 0.1571, 'learning_rate': 2.1840909090909093e-05, 'epoch': 168.95}\n",
      "{'eval_loss': 0.22466246783733368, 'eval_f1': 0.21755743676411735, 'eval_runtime': 14.8961, 'eval_samples_per_second': 61.157, 'eval_steps_per_second': 1.007, 'epoch': 169.0}\n",
      "{'loss': 0.1578, 'learning_rate': 2.1681818181818182e-05, 'epoch': 169.91}\n",
      "{'eval_loss': 0.22208771109580994, 'eval_f1': 0.23330525837917912, 'eval_runtime': 14.7248, 'eval_samples_per_second': 61.868, 'eval_steps_per_second': 1.019, 'epoch': 170.0}\n",
      "{'loss': 0.1536, 'learning_rate': 2.1522727272727276e-05, 'epoch': 170.86}\n",
      "{'eval_loss': 0.22596371173858643, 'eval_f1': 0.2377720431390683, 'eval_runtime': 16.0446, 'eval_samples_per_second': 56.779, 'eval_steps_per_second': 0.935, 'epoch': 171.0}\n",
      "{'loss': 0.159, 'learning_rate': 2.1363636363636362e-05, 'epoch': 171.82}\n",
      "{'eval_loss': 0.22747518122196198, 'eval_f1': 0.21984621984621985, 'eval_runtime': 15.0939, 'eval_samples_per_second': 60.356, 'eval_steps_per_second': 0.994, 'epoch': 172.0}\n",
      "{'loss': 0.1594, 'learning_rate': 2.1204545454545455e-05, 'epoch': 172.77}\n",
      "{'eval_loss': 0.22262905538082123, 'eval_f1': 0.2205133667057195, 'eval_runtime': 14.7696, 'eval_samples_per_second': 61.681, 'eval_steps_per_second': 1.016, 'epoch': 173.0}\n",
      "{'loss': 0.1553, 'learning_rate': 2.1045454545454545e-05, 'epoch': 173.73}\n",
      "{'eval_loss': 0.22134312987327576, 'eval_f1': 0.23128288477553186, 'eval_runtime': 14.8805, 'eval_samples_per_second': 61.221, 'eval_steps_per_second': 1.008, 'epoch': 174.0}\n",
      "{'loss': 0.1538, 'learning_rate': 2.0886363636363638e-05, 'epoch': 174.68}\n",
      "{'eval_loss': 0.22289027273654938, 'eval_f1': 0.24589685725483598, 'eval_runtime': 15.3539, 'eval_samples_per_second': 59.333, 'eval_steps_per_second': 0.977, 'epoch': 175.0}\n",
      "{'loss': 0.1566, 'learning_rate': 2.0727272727272728e-05, 'epoch': 175.64}\n",
      "{'eval_loss': 0.22253508865833282, 'eval_f1': 0.23053967425828906, 'eval_runtime': 15.9803, 'eval_samples_per_second': 57.008, 'eval_steps_per_second': 0.939, 'epoch': 176.0}\n",
      "{'loss': 0.1521, 'learning_rate': 2.056818181818182e-05, 'epoch': 176.59}\n",
      "{'eval_loss': 0.2205793410539627, 'eval_f1': 0.2392613864353846, 'eval_runtime': 15.1335, 'eval_samples_per_second': 60.197, 'eval_steps_per_second': 0.991, 'epoch': 177.0}\n",
      "{'loss': 0.1584, 'learning_rate': 2.040909090909091e-05, 'epoch': 177.55}\n",
      "{'eval_loss': 0.22226227819919586, 'eval_f1': 0.24069367655509977, 'eval_runtime': 14.8852, 'eval_samples_per_second': 61.202, 'eval_steps_per_second': 1.008, 'epoch': 178.0}\n",
      "{'loss': 0.1514, 'learning_rate': 2.025e-05, 'epoch': 178.5}\n",
      "{'eval_loss': 0.22256532311439514, 'eval_f1': 0.23498189743048967, 'eval_runtime': 15.0553, 'eval_samples_per_second': 60.51, 'eval_steps_per_second': 0.996, 'epoch': 179.0}\n",
      "{'loss': 0.1553, 'learning_rate': 2.009090909090909e-05, 'epoch': 179.45}\n",
      "{'eval_loss': 0.2307606041431427, 'eval_f1': 0.23808706104576283, 'eval_runtime': 15.8875, 'eval_samples_per_second': 57.341, 'eval_steps_per_second': 0.944, 'epoch': 180.0}\n",
      "{'loss': 0.1568, 'learning_rate': 1.993181818181818e-05, 'epoch': 180.41}\n",
      "{'eval_loss': 0.2264404296875, 'eval_f1': 0.23491138197020553, 'eval_runtime': 14.9501, 'eval_samples_per_second': 60.936, 'eval_steps_per_second': 1.003, 'epoch': 181.0}\n",
      "{'loss': 0.1491, 'learning_rate': 1.9772727272727274e-05, 'epoch': 181.36}\n",
      "{'eval_loss': 0.2248431146144867, 'eval_f1': 0.23409197573770105, 'eval_runtime': 15.4483, 'eval_samples_per_second': 58.971, 'eval_steps_per_second': 0.971, 'epoch': 182.0}\n",
      "{'loss': 0.1551, 'learning_rate': 1.9613636363636364e-05, 'epoch': 182.32}\n",
      "{'eval_loss': 0.22645583748817444, 'eval_f1': 0.22797970986397856, 'eval_runtime': 15.1656, 'eval_samples_per_second': 60.07, 'eval_steps_per_second': 0.989, 'epoch': 183.0}\n",
      "{'loss': 0.1492, 'learning_rate': 1.9454545454545457e-05, 'epoch': 183.27}\n",
      "{'eval_loss': 0.22530940175056458, 'eval_f1': 0.2306893551971921, 'eval_runtime': 15.1064, 'eval_samples_per_second': 60.306, 'eval_steps_per_second': 0.993, 'epoch': 184.0}\n",
      "{'loss': 0.1587, 'learning_rate': 1.9295454545454547e-05, 'epoch': 184.23}\n",
      "{'eval_loss': 0.22592417895793915, 'eval_f1': 0.24158145517700466, 'eval_runtime': 15.6215, 'eval_samples_per_second': 58.317, 'eval_steps_per_second': 0.96, 'epoch': 185.0}\n",
      "{'loss': 0.1495, 'learning_rate': 1.913636363636364e-05, 'epoch': 185.18}\n",
      "{'eval_loss': 0.22250054776668549, 'eval_f1': 0.23833516114514705, 'eval_runtime': 15.9509, 'eval_samples_per_second': 57.113, 'eval_steps_per_second': 0.94, 'epoch': 186.0}\n",
      "{'loss': 0.1507, 'learning_rate': 1.8977272727272726e-05, 'epoch': 186.14}\n",
      "{'eval_loss': 0.22364279627799988, 'eval_f1': 0.24075425790754257, 'eval_runtime': 15.0722, 'eval_samples_per_second': 60.442, 'eval_steps_per_second': 0.995, 'epoch': 187.0}\n",
      "{'loss': 0.1529, 'learning_rate': 1.881818181818182e-05, 'epoch': 187.09}\n",
      "{'eval_loss': 0.22270043194293976, 'eval_f1': 0.23789016317687794, 'eval_runtime': 15.5323, 'eval_samples_per_second': 58.652, 'eval_steps_per_second': 0.966, 'epoch': 188.0}\n",
      "{'loss': 0.1518, 'learning_rate': 1.865909090909091e-05, 'epoch': 188.05}\n",
      "{'loss': 0.1504, 'learning_rate': 1.85e-05, 'epoch': 189.0}\n",
      "{'eval_loss': 0.22195760905742645, 'eval_f1': 0.2296773046097753, 'eval_runtime': 14.997, 'eval_samples_per_second': 60.745, 'eval_steps_per_second': 1.0, 'epoch': 189.0}\n",
      "{'loss': 0.1515, 'learning_rate': 1.8340909090909092e-05, 'epoch': 189.95}\n",
      "{'eval_loss': 0.22458547353744507, 'eval_f1': 0.237868622249961, 'eval_runtime': 15.1566, 'eval_samples_per_second': 60.106, 'eval_steps_per_second': 0.99, 'epoch': 190.0}\n",
      "{'loss': 0.1499, 'learning_rate': 1.8181818181818182e-05, 'epoch': 190.91}\n",
      "{'eval_loss': 0.22499290108680725, 'eval_f1': 0.23775746793819497, 'eval_runtime': 15.0536, 'eval_samples_per_second': 60.517, 'eval_steps_per_second': 0.996, 'epoch': 191.0}\n",
      "{'loss': 0.1521, 'learning_rate': 1.8022727272727275e-05, 'epoch': 191.86}\n",
      "{'eval_loss': 0.2250673919916153, 'eval_f1': 0.2408709948258508, 'eval_runtime': 14.945, 'eval_samples_per_second': 60.957, 'eval_steps_per_second': 1.004, 'epoch': 192.0}\n",
      "{'loss': 0.1469, 'learning_rate': 1.7863636363636365e-05, 'epoch': 192.82}\n",
      "{'eval_loss': 0.22242791950702667, 'eval_f1': 0.23079395924046683, 'eval_runtime': 14.8803, 'eval_samples_per_second': 61.222, 'eval_steps_per_second': 1.008, 'epoch': 193.0}\n",
      "{'loss': 0.1531, 'learning_rate': 1.7704545454545455e-05, 'epoch': 193.77}\n",
      "{'eval_loss': 0.22543200850486755, 'eval_f1': 0.241880585523687, 'eval_runtime': 15.2099, 'eval_samples_per_second': 59.895, 'eval_steps_per_second': 0.986, 'epoch': 194.0}\n",
      "{'loss': 0.1484, 'learning_rate': 1.7545454545454545e-05, 'epoch': 194.73}\n",
      "{'eval_loss': 0.22514918446540833, 'eval_f1': 0.2456752429625074, 'eval_runtime': 15.5953, 'eval_samples_per_second': 58.415, 'eval_steps_per_second': 0.962, 'epoch': 195.0}\n",
      "{'loss': 0.1477, 'learning_rate': 1.7386363636363638e-05, 'epoch': 195.68}\n",
      "{'eval_loss': 0.21953760087490082, 'eval_f1': 0.22845603434568296, 'eval_runtime': 15.8365, 'eval_samples_per_second': 57.525, 'eval_steps_per_second': 0.947, 'epoch': 196.0}\n",
      "{'loss': 0.1467, 'learning_rate': 1.7227272727272728e-05, 'epoch': 196.64}\n",
      "{'eval_loss': 0.22407785058021545, 'eval_f1': 0.23411197626992952, 'eval_runtime': 15.2468, 'eval_samples_per_second': 59.75, 'eval_steps_per_second': 0.984, 'epoch': 197.0}\n",
      "{'loss': 0.1535, 'learning_rate': 1.706818181818182e-05, 'epoch': 197.59}\n",
      "{'eval_loss': 0.22693145275115967, 'eval_f1': 0.24517611334091186, 'eval_runtime': 16.8826, 'eval_samples_per_second': 53.961, 'eval_steps_per_second': 0.888, 'epoch': 198.0}\n",
      "{'loss': 0.1449, 'learning_rate': 1.690909090909091e-05, 'epoch': 198.55}\n",
      "{'eval_loss': 0.22552882134914398, 'eval_f1': 0.2423697910626015, 'eval_runtime': 15.0939, 'eval_samples_per_second': 60.355, 'eval_steps_per_second': 0.994, 'epoch': 199.0}\n",
      "{'loss': 0.149, 'learning_rate': 1.675e-05, 'epoch': 199.5}\n",
      "{'eval_loss': 0.22473236918449402, 'eval_f1': 0.24586876825904672, 'eval_runtime': 15.5806, 'eval_samples_per_second': 58.47, 'eval_steps_per_second': 0.963, 'epoch': 200.0}\n",
      "{'loss': 0.1438, 'learning_rate': 1.6590909090909094e-05, 'epoch': 200.45}\n",
      "{'eval_loss': 0.22413824498653412, 'eval_f1': 0.24160417030017634, 'eval_runtime': 14.9768, 'eval_samples_per_second': 60.827, 'eval_steps_per_second': 1.002, 'epoch': 201.0}\n",
      "{'loss': 0.1533, 'learning_rate': 1.643181818181818e-05, 'epoch': 201.41}\n",
      "{'eval_loss': 0.22131793200969696, 'eval_f1': 0.2500097400880305, 'eval_runtime': 15.9082, 'eval_samples_per_second': 57.266, 'eval_steps_per_second': 0.943, 'epoch': 202.0}\n",
      "{'loss': 0.1444, 'learning_rate': 1.6272727272727273e-05, 'epoch': 202.36}\n",
      "{'eval_loss': 0.22098655998706818, 'eval_f1': 0.2664082803782569, 'eval_runtime': 14.9422, 'eval_samples_per_second': 60.968, 'eval_steps_per_second': 1.004, 'epoch': 203.0}\n",
      "{'loss': 0.1515, 'learning_rate': 1.6113636363636363e-05, 'epoch': 203.32}\n",
      "{'eval_loss': 0.22187498211860657, 'eval_f1': 0.2684974456664299, 'eval_runtime': 15.6822, 'eval_samples_per_second': 58.091, 'eval_steps_per_second': 0.956, 'epoch': 204.0}\n",
      "{'loss': 0.1431, 'learning_rate': 1.5954545454545456e-05, 'epoch': 204.27}\n",
      "{'eval_loss': 0.22857263684272766, 'eval_f1': 0.2662408230147208, 'eval_runtime': 14.9442, 'eval_samples_per_second': 60.96, 'eval_steps_per_second': 1.004, 'epoch': 205.0}\n",
      "{'loss': 0.1476, 'learning_rate': 1.5795454545454546e-05, 'epoch': 205.23}\n",
      "{'eval_loss': 0.22539378702640533, 'eval_f1': 0.27284724805059923, 'eval_runtime': 14.9419, 'eval_samples_per_second': 60.97, 'eval_steps_per_second': 1.004, 'epoch': 206.0}\n",
      "{'loss': 0.1493, 'learning_rate': 1.563636363636364e-05, 'epoch': 206.18}\n",
      "{'eval_loss': 0.22380170226097107, 'eval_f1': 0.2677240752687547, 'eval_runtime': 14.9824, 'eval_samples_per_second': 60.805, 'eval_steps_per_second': 1.001, 'epoch': 207.0}\n",
      "{'loss': 0.1483, 'learning_rate': 1.547727272727273e-05, 'epoch': 207.14}\n",
      "{'eval_loss': 0.22482547163963318, 'eval_f1': 0.2761484699867241, 'eval_runtime': 16.5007, 'eval_samples_per_second': 55.21, 'eval_steps_per_second': 0.909, 'epoch': 208.0}\n",
      "{'loss': 0.1481, 'learning_rate': 1.531818181818182e-05, 'epoch': 208.09}\n",
      "{'eval_loss': 0.22571058571338654, 'eval_f1': 0.2773587663991446, 'eval_runtime': 15.79, 'eval_samples_per_second': 57.695, 'eval_steps_per_second': 0.95, 'epoch': 209.0}\n",
      "{'loss': 0.1465, 'learning_rate': 1.5159090909090909e-05, 'epoch': 209.05}\n",
      "{'loss': 0.1477, 'learning_rate': 1.5e-05, 'epoch': 210.0}\n",
      "{'eval_loss': 0.22062399983406067, 'eval_f1': 0.2818546002505567, 'eval_runtime': 15.1712, 'eval_samples_per_second': 60.048, 'eval_steps_per_second': 0.989, 'epoch': 210.0}\n",
      "{'loss': 0.1463, 'learning_rate': 1.4840909090909092e-05, 'epoch': 210.95}\n",
      "{'eval_loss': 0.2258523851633072, 'eval_f1': 0.2823745619023504, 'eval_runtime': 14.9786, 'eval_samples_per_second': 60.82, 'eval_steps_per_second': 1.001, 'epoch': 211.0}\n",
      "{'loss': 0.144, 'learning_rate': 1.4681818181818183e-05, 'epoch': 211.91}\n",
      "{'eval_loss': 0.22661073505878448, 'eval_f1': 0.27442654241392733, 'eval_runtime': 15.3432, 'eval_samples_per_second': 59.375, 'eval_steps_per_second': 0.978, 'epoch': 212.0}\n",
      "{'loss': 0.1476, 'learning_rate': 1.4522727272727273e-05, 'epoch': 212.86}\n",
      "{'eval_loss': 0.2258644998073578, 'eval_f1': 0.27553861446659483, 'eval_runtime': 15.8284, 'eval_samples_per_second': 57.555, 'eval_steps_per_second': 0.948, 'epoch': 213.0}\n",
      "{'loss': 0.1483, 'learning_rate': 1.4363636363636365e-05, 'epoch': 213.82}\n",
      "{'eval_loss': 0.22535674273967743, 'eval_f1': 0.2828506868059788, 'eval_runtime': 14.8141, 'eval_samples_per_second': 61.495, 'eval_steps_per_second': 1.013, 'epoch': 214.0}\n",
      "{'loss': 0.1472, 'learning_rate': 1.4204545454545456e-05, 'epoch': 214.77}\n",
      "{'eval_loss': 0.22582146525382996, 'eval_f1': 0.2822227857724815, 'eval_runtime': 16.8494, 'eval_samples_per_second': 54.067, 'eval_steps_per_second': 0.89, 'epoch': 215.0}\n",
      "{'loss': 0.1421, 'learning_rate': 1.4045454545454544e-05, 'epoch': 215.73}\n",
      "{'eval_loss': 0.2262725979089737, 'eval_f1': 0.27734385162065295, 'eval_runtime': 15.3872, 'eval_samples_per_second': 59.205, 'eval_steps_per_second': 0.975, 'epoch': 216.0}\n",
      "{'loss': 0.1471, 'learning_rate': 1.3886363636363636e-05, 'epoch': 216.68}\n",
      "{'eval_loss': 0.22334347665309906, 'eval_f1': 0.27524782312945123, 'eval_runtime': 14.8791, 'eval_samples_per_second': 61.227, 'eval_steps_per_second': 1.008, 'epoch': 217.0}\n",
      "{'loss': 0.1446, 'learning_rate': 1.3727272727272727e-05, 'epoch': 217.64}\n",
      "{'eval_loss': 0.22404590249061584, 'eval_f1': 0.2793609423404904, 'eval_runtime': 15.7607, 'eval_samples_per_second': 57.802, 'eval_steps_per_second': 0.952, 'epoch': 218.0}\n",
      "{'loss': 0.1447, 'learning_rate': 1.3568181818181819e-05, 'epoch': 218.59}\n",
      "{'eval_loss': 0.22447635233402252, 'eval_f1': 0.27054556305906635, 'eval_runtime': 14.9661, 'eval_samples_per_second': 60.871, 'eval_steps_per_second': 1.002, 'epoch': 219.0}\n",
      "{'loss': 0.1434, 'learning_rate': 1.340909090909091e-05, 'epoch': 219.55}\n",
      "{'eval_loss': 0.22416391968727112, 'eval_f1': 0.2813223776434749, 'eval_runtime': 15.0144, 'eval_samples_per_second': 60.675, 'eval_steps_per_second': 0.999, 'epoch': 220.0}\n",
      "{'loss': 0.145, 'learning_rate': 1.3250000000000002e-05, 'epoch': 220.5}\n",
      "{'eval_loss': 0.22487382590770721, 'eval_f1': 0.29039092092157587, 'eval_runtime': 15.0464, 'eval_samples_per_second': 60.546, 'eval_steps_per_second': 0.997, 'epoch': 221.0}\n",
      "{'loss': 0.1456, 'learning_rate': 1.3090909090909093e-05, 'epoch': 221.45}\n",
      "{'eval_loss': 0.22659185528755188, 'eval_f1': 0.2946984500801721, 'eval_runtime': 15.108, 'eval_samples_per_second': 60.299, 'eval_steps_per_second': 0.993, 'epoch': 222.0}\n",
      "{'loss': 0.144, 'learning_rate': 1.2931818181818182e-05, 'epoch': 222.41}\n",
      "{'eval_loss': 0.22824205458164215, 'eval_f1': 0.2926384337068657, 'eval_runtime': 15.0072, 'eval_samples_per_second': 60.704, 'eval_steps_per_second': 1.0, 'epoch': 223.0}\n",
      "{'loss': 0.1485, 'learning_rate': 1.2772727272727273e-05, 'epoch': 223.36}\n",
      "{'eval_loss': 0.2274526208639145, 'eval_f1': 0.29482747742607485, 'eval_runtime': 16.2646, 'eval_samples_per_second': 56.011, 'eval_steps_per_second': 0.922, 'epoch': 224.0}\n",
      "{'loss': 0.1399, 'learning_rate': 1.2613636363636363e-05, 'epoch': 224.32}\n",
      "{'eval_loss': 0.2263491004705429, 'eval_f1': 0.29389781558888267, 'eval_runtime': 15.0716, 'eval_samples_per_second': 60.445, 'eval_steps_per_second': 0.995, 'epoch': 225.0}\n",
      "{'loss': 0.1456, 'learning_rate': 1.2454545454545454e-05, 'epoch': 225.27}\n",
      "{'eval_loss': 0.2266472727060318, 'eval_f1': 0.2879835963085122, 'eval_runtime': 14.9354, 'eval_samples_per_second': 60.996, 'eval_steps_per_second': 1.004, 'epoch': 226.0}\n",
      "{'loss': 0.1415, 'learning_rate': 1.2295454545454546e-05, 'epoch': 226.23}\n",
      "{'eval_loss': 0.22724372148513794, 'eval_f1': 0.28403306507969633, 'eval_runtime': 16.2221, 'eval_samples_per_second': 56.158, 'eval_steps_per_second': 0.925, 'epoch': 227.0}\n",
      "{'loss': 0.1468, 'learning_rate': 1.2136363636363637e-05, 'epoch': 227.18}\n",
      "{'eval_loss': 0.22701503336429596, 'eval_f1': 0.292367020150707, 'eval_runtime': 15.0768, 'eval_samples_per_second': 60.424, 'eval_steps_per_second': 0.995, 'epoch': 228.0}\n",
      "{'loss': 0.1409, 'learning_rate': 1.1977272727272727e-05, 'epoch': 228.14}\n",
      "{'eval_loss': 0.2260095775127411, 'eval_f1': 0.2975944637018462, 'eval_runtime': 15.6041, 'eval_samples_per_second': 58.382, 'eval_steps_per_second': 0.961, 'epoch': 229.0}\n",
      "{'loss': 0.1474, 'learning_rate': 1.1818181818181819e-05, 'epoch': 229.09}\n",
      "{'eval_loss': 0.22548523545265198, 'eval_f1': 0.28984634535587, 'eval_runtime': 14.9548, 'eval_samples_per_second': 60.917, 'eval_steps_per_second': 1.003, 'epoch': 230.0}\n",
      "{'loss': 0.143, 'learning_rate': 1.165909090909091e-05, 'epoch': 230.05}\n",
      "{'loss': 0.1423, 'learning_rate': 1.1500000000000002e-05, 'epoch': 231.0}\n",
      "{'eval_loss': 0.22328774631023407, 'eval_f1': 0.2872925860201165, 'eval_runtime': 17.0379, 'eval_samples_per_second': 53.469, 'eval_steps_per_second': 0.88, 'epoch': 231.0}\n",
      "{'loss': 0.1424, 'learning_rate': 1.1340909090909092e-05, 'epoch': 231.95}\n",
      "{'eval_loss': 0.22234077751636505, 'eval_f1': 0.27517327983890966, 'eval_runtime': 15.2186, 'eval_samples_per_second': 59.861, 'eval_steps_per_second': 0.986, 'epoch': 232.0}\n",
      "{'loss': 0.1432, 'learning_rate': 1.1181818181818183e-05, 'epoch': 232.91}\n",
      "{'eval_loss': 0.22202488780021667, 'eval_f1': 0.27524710442236855, 'eval_runtime': 15.4803, 'eval_samples_per_second': 58.849, 'eval_steps_per_second': 0.969, 'epoch': 233.0}\n",
      "{'loss': 0.142, 'learning_rate': 1.1022727272727273e-05, 'epoch': 233.86}\n",
      "{'eval_loss': 0.2220693677663803, 'eval_f1': 0.28069334108376925, 'eval_runtime': 15.0541, 'eval_samples_per_second': 60.515, 'eval_steps_per_second': 0.996, 'epoch': 234.0}\n",
      "{'loss': 0.1411, 'learning_rate': 1.0863636363636364e-05, 'epoch': 234.82}\n",
      "{'eval_loss': 0.22243599593639374, 'eval_f1': 0.28205594918312843, 'eval_runtime': 15.4802, 'eval_samples_per_second': 58.849, 'eval_steps_per_second': 0.969, 'epoch': 235.0}\n",
      "{'loss': 0.1432, 'learning_rate': 1.0704545454545454e-05, 'epoch': 235.77}\n",
      "{'eval_loss': 0.22211019694805145, 'eval_f1': 0.2907580882650938, 'eval_runtime': 15.069, 'eval_samples_per_second': 60.455, 'eval_steps_per_second': 0.995, 'epoch': 236.0}\n",
      "{'loss': 0.1442, 'learning_rate': 1.0545454545454546e-05, 'epoch': 236.73}\n",
      "{'eval_loss': 0.22348026931285858, 'eval_f1': 0.29209185885477446, 'eval_runtime': 16.6639, 'eval_samples_per_second': 54.669, 'eval_steps_per_second': 0.9, 'epoch': 237.0}\n",
      "{'loss': 0.142, 'learning_rate': 1.0386363636363637e-05, 'epoch': 237.68}\n",
      "{'eval_loss': 0.22555719316005707, 'eval_f1': 0.2929369153577585, 'eval_runtime': 15.1888, 'eval_samples_per_second': 59.978, 'eval_steps_per_second': 0.988, 'epoch': 238.0}\n",
      "{'loss': 0.1407, 'learning_rate': 1.0227272727272729e-05, 'epoch': 238.64}\n",
      "{'eval_loss': 0.22407138347625732, 'eval_f1': 0.28878539012054927, 'eval_runtime': 15.7649, 'eval_samples_per_second': 57.787, 'eval_steps_per_second': 0.951, 'epoch': 239.0}\n",
      "{'loss': 0.1417, 'learning_rate': 1.0068181818181819e-05, 'epoch': 239.59}\n",
      "{'eval_loss': 0.2240207940340042, 'eval_f1': 0.2875032769328294, 'eval_runtime': 15.2458, 'eval_samples_per_second': 59.754, 'eval_steps_per_second': 0.984, 'epoch': 240.0}\n",
      "{'loss': 0.1461, 'learning_rate': 9.90909090909091e-06, 'epoch': 240.55}\n",
      "{'eval_loss': 0.22378526628017426, 'eval_f1': 0.28748806749316386, 'eval_runtime': 16.0116, 'eval_samples_per_second': 56.896, 'eval_steps_per_second': 0.937, 'epoch': 241.0}\n",
      "{'loss': 0.1369, 'learning_rate': 9.750000000000002e-06, 'epoch': 241.5}\n",
      "{'eval_loss': 0.2234758883714676, 'eval_f1': 0.28686903172475614, 'eval_runtime': 14.9812, 'eval_samples_per_second': 60.81, 'eval_steps_per_second': 1.001, 'epoch': 242.0}\n",
      "{'loss': 0.1407, 'learning_rate': 9.590909090909091e-06, 'epoch': 242.45}\n",
      "{'eval_loss': 0.22350816428661346, 'eval_f1': 0.2885198592012743, 'eval_runtime': 14.8891, 'eval_samples_per_second': 61.186, 'eval_steps_per_second': 1.007, 'epoch': 243.0}\n",
      "{'loss': 0.1412, 'learning_rate': 9.431818181818181e-06, 'epoch': 243.41}\n",
      "{'eval_loss': 0.22245284914970398, 'eval_f1': 0.2913745491355657, 'eval_runtime': 14.985, 'eval_samples_per_second': 60.794, 'eval_steps_per_second': 1.001, 'epoch': 244.0}\n",
      "{'loss': 0.1428, 'learning_rate': 9.272727272727273e-06, 'epoch': 244.36}\n",
      "{'eval_loss': 0.2255786657333374, 'eval_f1': 0.2937560954340422, 'eval_runtime': 15.088, 'eval_samples_per_second': 60.379, 'eval_steps_per_second': 0.994, 'epoch': 245.0}\n",
      "{'loss': 0.1394, 'learning_rate': 9.113636363636364e-06, 'epoch': 245.32}\n",
      "{'eval_loss': 0.2250414937734604, 'eval_f1': 0.2902479011567293, 'eval_runtime': 15.2606, 'eval_samples_per_second': 59.696, 'eval_steps_per_second': 0.983, 'epoch': 246.0}\n",
      "{'loss': 0.14, 'learning_rate': 8.954545454545454e-06, 'epoch': 246.27}\n",
      "{'eval_loss': 0.22489197552204132, 'eval_f1': 0.28522008335725196, 'eval_runtime': 14.9395, 'eval_samples_per_second': 60.979, 'eval_steps_per_second': 1.004, 'epoch': 247.0}\n",
      "{'loss': 0.1421, 'learning_rate': 8.795454545454545e-06, 'epoch': 247.23}\n",
      "{'eval_loss': 0.2244957834482193, 'eval_f1': 0.29256785727692197, 'eval_runtime': 15.0303, 'eval_samples_per_second': 60.611, 'eval_steps_per_second': 0.998, 'epoch': 248.0}\n",
      "{'loss': 0.1423, 'learning_rate': 8.636363636363637e-06, 'epoch': 248.18}\n",
      "{'eval_loss': 0.22466780245304108, 'eval_f1': 0.28998893309297086, 'eval_runtime': 15.0767, 'eval_samples_per_second': 60.425, 'eval_steps_per_second': 0.995, 'epoch': 249.0}\n",
      "{'loss': 0.1415, 'learning_rate': 8.477272727272729e-06, 'epoch': 249.14}\n",
      "{'eval_loss': 0.22486130893230438, 'eval_f1': 0.2833492520365121, 'eval_runtime': 15.9579, 'eval_samples_per_second': 57.088, 'eval_steps_per_second': 0.94, 'epoch': 250.0}\n",
      "{'loss': 0.1396, 'learning_rate': 8.318181818181818e-06, 'epoch': 250.09}\n",
      "{'eval_loss': 0.2246154099702835, 'eval_f1': 0.2872050011569989, 'eval_runtime': 14.8987, 'eval_samples_per_second': 61.146, 'eval_steps_per_second': 1.007, 'epoch': 251.0}\n",
      "{'loss': 0.1412, 'learning_rate': 8.15909090909091e-06, 'epoch': 251.05}\n",
      "{'loss': 0.1413, 'learning_rate': 8.000000000000001e-06, 'epoch': 252.0}\n",
      "{'eval_loss': 0.2245607078075409, 'eval_f1': 0.2839256185612536, 'eval_runtime': 17.201, 'eval_samples_per_second': 52.962, 'eval_steps_per_second': 0.872, 'epoch': 252.0}\n",
      "{'loss': 0.1418, 'learning_rate': 7.840909090909091e-06, 'epoch': 252.95}\n",
      "{'eval_loss': 0.22449524700641632, 'eval_f1': 0.2907221678016449, 'eval_runtime': 14.9835, 'eval_samples_per_second': 60.8, 'eval_steps_per_second': 1.001, 'epoch': 253.0}\n",
      "{'loss': 0.1393, 'learning_rate': 7.681818181818181e-06, 'epoch': 253.91}\n",
      "{'eval_loss': 0.2228395938873291, 'eval_f1': 0.2859108821825415, 'eval_runtime': 16.3127, 'eval_samples_per_second': 55.846, 'eval_steps_per_second': 0.92, 'epoch': 254.0}\n",
      "{'loss': 0.1369, 'learning_rate': 7.522727272727273e-06, 'epoch': 254.86}\n",
      "{'eval_loss': 0.2208668738603592, 'eval_f1': 0.2871787624425119, 'eval_runtime': 15.3918, 'eval_samples_per_second': 59.188, 'eval_steps_per_second': 0.975, 'epoch': 255.0}\n",
      "{'loss': 0.1437, 'learning_rate': 7.363636363636364e-06, 'epoch': 255.82}\n",
      "{'eval_loss': 0.2214171290397644, 'eval_f1': 0.29375384114149466, 'eval_runtime': 17.0496, 'eval_samples_per_second': 53.432, 'eval_steps_per_second': 0.88, 'epoch': 256.0}\n",
      "{'loss': 0.1393, 'learning_rate': 7.2045454545454555e-06, 'epoch': 256.77}\n",
      "{'eval_loss': 0.22167372703552246, 'eval_f1': 0.29872078008278724, 'eval_runtime': 14.9129, 'eval_samples_per_second': 61.088, 'eval_steps_per_second': 1.006, 'epoch': 257.0}\n",
      "{'loss': 0.1417, 'learning_rate': 7.045454545454545e-06, 'epoch': 257.73}\n",
      "{'eval_loss': 0.22170571982860565, 'eval_f1': 0.29042472916160167, 'eval_runtime': 14.8606, 'eval_samples_per_second': 61.303, 'eval_steps_per_second': 1.009, 'epoch': 258.0}\n",
      "{'loss': 0.1357, 'learning_rate': 6.886363636363637e-06, 'epoch': 258.68}\n",
      "{'eval_loss': 0.2238863706588745, 'eval_f1': 0.29307639543848135, 'eval_runtime': 14.9496, 'eval_samples_per_second': 60.938, 'eval_steps_per_second': 1.003, 'epoch': 259.0}\n",
      "{'loss': 0.1396, 'learning_rate': 6.727272727272728e-06, 'epoch': 259.64}\n",
      "{'eval_loss': 0.22146093845367432, 'eval_f1': 0.2778149779500749, 'eval_runtime': 15.3605, 'eval_samples_per_second': 59.308, 'eval_steps_per_second': 0.977, 'epoch': 260.0}\n",
      "{'loss': 0.1438, 'learning_rate': 6.568181818181819e-06, 'epoch': 260.59}\n",
      "{'eval_loss': 0.22081223130226135, 'eval_f1': 0.278216135797205, 'eval_runtime': 15.0335, 'eval_samples_per_second': 60.598, 'eval_steps_per_second': 0.998, 'epoch': 261.0}\n",
      "{'loss': 0.141, 'learning_rate': 6.409090909090909e-06, 'epoch': 261.55}\n",
      "{'eval_loss': 0.22096480429172516, 'eval_f1': 0.2820315695052736, 'eval_runtime': 16.6974, 'eval_samples_per_second': 54.559, 'eval_steps_per_second': 0.898, 'epoch': 262.0}\n",
      "{'loss': 0.1424, 'learning_rate': 6.25e-06, 'epoch': 262.5}\n",
      "{'eval_loss': 0.22105370461940765, 'eval_f1': 0.28800063589399066, 'eval_runtime': 15.4061, 'eval_samples_per_second': 59.132, 'eval_steps_per_second': 0.974, 'epoch': 263.0}\n",
      "{'loss': 0.1358, 'learning_rate': 6.090909090909091e-06, 'epoch': 263.45}\n",
      "{'eval_loss': 0.22126460075378418, 'eval_f1': 0.28303692929856267, 'eval_runtime': 15.178, 'eval_samples_per_second': 60.021, 'eval_steps_per_second': 0.988, 'epoch': 264.0}\n",
      "{'loss': 0.1381, 'learning_rate': 5.9318181818181825e-06, 'epoch': 264.41}\n",
      "{'eval_loss': 0.22127963602542877, 'eval_f1': 0.28537981314797684, 'eval_runtime': 15.8613, 'eval_samples_per_second': 57.435, 'eval_steps_per_second': 0.946, 'epoch': 265.0}\n",
      "{'loss': 0.1414, 'learning_rate': 5.772727272727272e-06, 'epoch': 265.36}\n",
      "{'eval_loss': 0.22140555083751678, 'eval_f1': 0.28753941996392124, 'eval_runtime': 14.9671, 'eval_samples_per_second': 60.867, 'eval_steps_per_second': 1.002, 'epoch': 266.0}\n",
      "{'loss': 0.1348, 'learning_rate': 5.613636363636364e-06, 'epoch': 266.32}\n",
      "{'eval_loss': 0.22143998742103577, 'eval_f1': 0.2868447433320639, 'eval_runtime': 15.0026, 'eval_samples_per_second': 60.723, 'eval_steps_per_second': 1.0, 'epoch': 267.0}\n",
      "{'loss': 0.1418, 'learning_rate': 5.4545454545454545e-06, 'epoch': 267.27}\n",
      "{'eval_loss': 0.22207075357437134, 'eval_f1': 0.28651044644104795, 'eval_runtime': 15.6139, 'eval_samples_per_second': 58.345, 'eval_steps_per_second': 0.961, 'epoch': 268.0}\n",
      "{'loss': 0.1406, 'learning_rate': 5.295454545454546e-06, 'epoch': 268.23}\n",
      "{'eval_loss': 0.22231526672840118, 'eval_f1': 0.28897340274375266, 'eval_runtime': 15.03, 'eval_samples_per_second': 60.612, 'eval_steps_per_second': 0.998, 'epoch': 269.0}\n",
      "{'loss': 0.1406, 'learning_rate': 5.136363636363637e-06, 'epoch': 269.18}\n",
      "{'eval_loss': 0.22254277765750885, 'eval_f1': 0.29079535657998085, 'eval_runtime': 15.3196, 'eval_samples_per_second': 59.466, 'eval_steps_per_second': 0.979, 'epoch': 270.0}\n",
      "{'loss': 0.1393, 'learning_rate': 4.977272727272727e-06, 'epoch': 270.14}\n",
      "{'eval_loss': 0.22130540013313293, 'eval_f1': 0.2883481067535257, 'eval_runtime': 16.3522, 'eval_samples_per_second': 55.711, 'eval_steps_per_second': 0.917, 'epoch': 271.0}\n",
      "{'loss': 0.1392, 'learning_rate': 4.818181818181818e-06, 'epoch': 271.09}\n",
      "{'eval_loss': 0.2215065211057663, 'eval_f1': 0.2877340424848604, 'eval_runtime': 14.9299, 'eval_samples_per_second': 61.019, 'eval_steps_per_second': 1.005, 'epoch': 272.0}\n",
      "{'loss': 0.1377, 'learning_rate': 4.6590909090909095e-06, 'epoch': 272.05}\n",
      "{'loss': 0.1407, 'learning_rate': 4.5e-06, 'epoch': 273.0}\n",
      "{'eval_loss': 0.22250762581825256, 'eval_f1': 0.2913512318510195, 'eval_runtime': 14.9884, 'eval_samples_per_second': 60.78, 'eval_steps_per_second': 1.001, 'epoch': 273.0}\n",
      "{'loss': 0.138, 'learning_rate': 4.340909090909092e-06, 'epoch': 273.95}\n",
      "{'eval_loss': 0.22269058227539062, 'eval_f1': 0.2940167684559845, 'eval_runtime': 15.8623, 'eval_samples_per_second': 57.432, 'eval_steps_per_second': 0.946, 'epoch': 274.0}\n",
      "{'loss': 0.141, 'learning_rate': 4.181818181818182e-06, 'epoch': 274.91}\n",
      "{'eval_loss': 0.22269663214683533, 'eval_f1': 0.29187767648392454, 'eval_runtime': 15.0723, 'eval_samples_per_second': 60.442, 'eval_steps_per_second': 0.995, 'epoch': 275.0}\n",
      "{'loss': 0.1399, 'learning_rate': 4.022727272727273e-06, 'epoch': 275.86}\n",
      "{'eval_loss': 0.2227904200553894, 'eval_f1': 0.290774588705031, 'eval_runtime': 17.0483, 'eval_samples_per_second': 53.436, 'eval_steps_per_second': 0.88, 'epoch': 276.0}\n",
      "{'loss': 0.1357, 'learning_rate': 3.863636363636364e-06, 'epoch': 276.82}\n",
      "{'eval_loss': 0.22293944656848907, 'eval_f1': 0.28570227263952197, 'eval_runtime': 15.1671, 'eval_samples_per_second': 60.064, 'eval_steps_per_second': 0.989, 'epoch': 277.0}\n",
      "{'loss': 0.1413, 'learning_rate': 3.704545454545455e-06, 'epoch': 277.77}\n",
      "{'eval_loss': 0.22300343215465546, 'eval_f1': 0.2885941005683707, 'eval_runtime': 14.9606, 'eval_samples_per_second': 60.893, 'eval_steps_per_second': 1.003, 'epoch': 278.0}\n",
      "{'loss': 0.1373, 'learning_rate': 3.5454545454545454e-06, 'epoch': 278.73}\n",
      "{'eval_loss': 0.22308821976184845, 'eval_f1': 0.2874562855456971, 'eval_runtime': 16.122, 'eval_samples_per_second': 56.507, 'eval_steps_per_second': 0.93, 'epoch': 279.0}\n",
      "{'loss': 0.1396, 'learning_rate': 3.386363636363637e-06, 'epoch': 279.68}\n",
      "{'eval_loss': 0.22321820259094238, 'eval_f1': 0.28619002525252524, 'eval_runtime': 15.1254, 'eval_samples_per_second': 60.23, 'eval_steps_per_second': 0.992, 'epoch': 280.0}\n",
      "{'loss': 0.1357, 'learning_rate': 3.2272727272727275e-06, 'epoch': 280.64}\n",
      "{'eval_loss': 0.22338758409023285, 'eval_f1': 0.2868160851777635, 'eval_runtime': 14.9487, 'eval_samples_per_second': 60.942, 'eval_steps_per_second': 1.003, 'epoch': 281.0}\n",
      "{'loss': 0.1394, 'learning_rate': 3.068181818181818e-06, 'epoch': 281.59}\n",
      "{'eval_loss': 0.2232801616191864, 'eval_f1': 0.28791191161795376, 'eval_runtime': 15.3654, 'eval_samples_per_second': 59.289, 'eval_steps_per_second': 0.976, 'epoch': 282.0}\n",
      "{'loss': 0.137, 'learning_rate': 2.9090909090909093e-06, 'epoch': 282.55}\n",
      "{'eval_loss': 0.2232198417186737, 'eval_f1': 0.2912347343287674, 'eval_runtime': 15.267, 'eval_samples_per_second': 59.671, 'eval_steps_per_second': 0.983, 'epoch': 283.0}\n",
      "{'loss': 0.1361, 'learning_rate': 2.7500000000000004e-06, 'epoch': 283.5}\n",
      "{'eval_loss': 0.22323597967624664, 'eval_f1': 0.2924183155518883, 'eval_runtime': 15.0446, 'eval_samples_per_second': 60.553, 'eval_steps_per_second': 0.997, 'epoch': 284.0}\n",
      "{'loss': 0.1388, 'learning_rate': 2.590909090909091e-06, 'epoch': 284.45}\n",
      "{'eval_loss': 0.22338013350963593, 'eval_f1': 0.2882187420807704, 'eval_runtime': 16.4095, 'eval_samples_per_second': 55.517, 'eval_steps_per_second': 0.914, 'epoch': 285.0}\n",
      "{'loss': 0.1384, 'learning_rate': 2.431818181818182e-06, 'epoch': 285.41}\n",
      "{'eval_loss': 0.22298923134803772, 'eval_f1': 0.2861273345787974, 'eval_runtime': 15.1536, 'eval_samples_per_second': 60.118, 'eval_steps_per_second': 0.99, 'epoch': 286.0}\n",
      "{'loss': 0.1389, 'learning_rate': 2.2727272727272728e-06, 'epoch': 286.36}\n",
      "{'eval_loss': 0.22285693883895874, 'eval_f1': 0.2846997372455422, 'eval_runtime': 16.0057, 'eval_samples_per_second': 56.917, 'eval_steps_per_second': 0.937, 'epoch': 287.0}\n",
      "{'loss': 0.1385, 'learning_rate': 2.113636363636364e-06, 'epoch': 287.32}\n",
      "{'eval_loss': 0.22294484078884125, 'eval_f1': 0.28449898606983576, 'eval_runtime': 15.3238, 'eval_samples_per_second': 59.45, 'eval_steps_per_second': 0.979, 'epoch': 288.0}\n",
      "{'loss': 0.1416, 'learning_rate': 1.954545454545455e-06, 'epoch': 288.27}\n",
      "{'eval_loss': 0.22308006882667542, 'eval_f1': 0.28471757724968166, 'eval_runtime': 14.9212, 'eval_samples_per_second': 61.054, 'eval_steps_per_second': 1.005, 'epoch': 289.0}\n",
      "{'loss': 0.1372, 'learning_rate': 1.7954545454545456e-06, 'epoch': 289.23}\n",
      "{'eval_loss': 0.22321370244026184, 'eval_f1': 0.2855550767315473, 'eval_runtime': 15.9608, 'eval_samples_per_second': 57.077, 'eval_steps_per_second': 0.94, 'epoch': 290.0}\n",
      "{'loss': 0.137, 'learning_rate': 1.6363636363636367e-06, 'epoch': 290.18}\n",
      "{'eval_loss': 0.22328321635723114, 'eval_f1': 0.287506375481059, 'eval_runtime': 15.9584, 'eval_samples_per_second': 57.086, 'eval_steps_per_second': 0.94, 'epoch': 291.0}\n",
      "{'loss': 0.1385, 'learning_rate': 1.4772727272727273e-06, 'epoch': 291.14}\n",
      "{'eval_loss': 0.2233525961637497, 'eval_f1': 0.2875145880435941, 'eval_runtime': 15.9435, 'eval_samples_per_second': 57.139, 'eval_steps_per_second': 0.941, 'epoch': 292.0}\n",
      "{'loss': 0.1387, 'learning_rate': 1.3181818181818182e-06, 'epoch': 292.09}\n",
      "{'eval_loss': 0.22335577011108398, 'eval_f1': 0.28519006434121846, 'eval_runtime': 14.9855, 'eval_samples_per_second': 60.792, 'eval_steps_per_second': 1.001, 'epoch': 293.0}\n",
      "{'loss': 0.1368, 'learning_rate': 1.159090909090909e-06, 'epoch': 293.05}\n",
      "{'loss': 0.1383, 'learning_rate': 1.0000000000000002e-06, 'epoch': 294.0}\n",
      "{'eval_loss': 0.22347868978977203, 'eval_f1': 0.2877194179066282, 'eval_runtime': 15.9437, 'eval_samples_per_second': 57.139, 'eval_steps_per_second': 0.941, 'epoch': 294.0}\n",
      "{'loss': 0.138, 'learning_rate': 8.40909090909091e-07, 'epoch': 294.95}\n",
      "{'eval_loss': 0.22351087629795074, 'eval_f1': 0.28571070047791824, 'eval_runtime': 14.8729, 'eval_samples_per_second': 61.253, 'eval_steps_per_second': 1.009, 'epoch': 295.0}\n",
      "{'loss': 0.1373, 'learning_rate': 6.818181818181818e-07, 'epoch': 295.91}\n",
      "{'eval_loss': 0.22352056205272675, 'eval_f1': 0.28693361929203826, 'eval_runtime': 14.9387, 'eval_samples_per_second': 60.983, 'eval_steps_per_second': 1.004, 'epoch': 296.0}\n",
      "{'loss': 0.1376, 'learning_rate': 5.227272727272728e-07, 'epoch': 296.86}\n",
      "{'eval_loss': 0.2235114723443985, 'eval_f1': 0.286754302734644, 'eval_runtime': 15.8414, 'eval_samples_per_second': 57.508, 'eval_steps_per_second': 0.947, 'epoch': 297.0}\n",
      "{'loss': 0.1367, 'learning_rate': 3.6363636363636366e-07, 'epoch': 297.82}\n",
      "{'eval_loss': 0.22352351248264313, 'eval_f1': 0.2867548161575701, 'eval_runtime': 14.8902, 'eval_samples_per_second': 61.181, 'eval_steps_per_second': 1.007, 'epoch': 298.0}\n",
      "{'loss': 0.1387, 'learning_rate': 2.0454545454545458e-07, 'epoch': 298.77}\n",
      "{'eval_loss': 0.22351941466331482, 'eval_f1': 0.2867548161575701, 'eval_runtime': 15.0817, 'eval_samples_per_second': 60.404, 'eval_steps_per_second': 0.995, 'epoch': 299.0}\n",
      "{'loss': 0.138, 'learning_rate': 4.545454545454546e-08, 'epoch': 299.73}\n",
      "{'eval_loss': 0.2235228419303894, 'eval_f1': 0.2867548161575701, 'eval_runtime': 16.4421, 'eval_samples_per_second': 55.407, 'eval_steps_per_second': 0.912, 'epoch': 300.0}\n",
      "{'train_runtime': 46569.7757, 'train_samples_per_second': 8.903, 'train_steps_per_second': 0.142, 'train_loss': 0.23404444872429878, 'epoch': 300.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e91c451b52942d7a53d99014c15b340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_idx = 10000\n",
    "scenarios = [\n",
    "            {'dataset': best_ds\n",
    "             ,'epoch': 150\n",
    "             ,'architecture': 'additional_linear'\n",
    "             ,'weight_decay': 0.1\n",
    "             ,'batch_size': 64\n",
    "            }\n",
    "            \n",
    "            ,{'dataset': best_ds\n",
    "             ,'epoch': 300\n",
    "             ,'architecture': 'lstm'\n",
    "             ,'weight_decay': 0.1\n",
    "             ,'batch_size': 64\n",
    "            }\n",
    "            ]\n",
    "\n",
    "run_scenarios(model_idx, scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn_f1_score</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crf</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_1_ds_ori_linear_e15_ld01_b64_wF</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10_ds_down_linear_e15_ld01_b64_wF</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_100_ds_down_additional_linear_e50_ld01_b64_wF</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.3460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_101_ds_down_lstm_e70_ld01_b64_wF</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10000_ds_down_additional_linear_e100_ld05_b512_wF</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10000_ds_down_additional_linear_e150_ld01_b64_wF</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.4807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10001_ds_down_lstm_e300_ld01_b64_wF</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sklearn_f1_score      f1\n",
       "random forest                                                   0.14  0.0000\n",
       "crf                                                             0.14  0.0000\n",
       "sc_1_ds_ori_linear_e15_ld01_b64_wF                              0.60  0.5338\n",
       "sc_10_ds_down_linear_e15_ld01_b64_wF                            0.62  0.5491\n",
       "sc_100_ds_down_additional_linear_e50_ld01_b64_wF                0.42  0.3460\n",
       "sc_101_ds_down_lstm_e70_ld01_b64_wF                             0.14  0.0000\n",
       "sc_10000_ds_down_additional_linear_e100_ld05_b5...              0.14  0.0000\n",
       "sc_10000_ds_down_additional_linear_e150_ld01_b6...              0.57  0.4807\n",
       "sc_10001_ds_down_lstm_e300_ld01_b64_wF                          0.33  0.3333"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTuning.modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4314</td>\n",
       "      <td>0.237635</td>\n",
       "      <td>0.136534</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1680</td>\n",
       "      <td>0.182450</td>\n",
       "      <td>0.310048</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.161732</td>\n",
       "      <td>0.373332</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.158205</td>\n",
       "      <td>0.466623</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.170560</td>\n",
       "      <td>0.487552</td>\n",
       "      <td>sc_1_ds_ori_linear_e15_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>296</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.223521</td>\n",
       "      <td>0.286934</td>\n",
       "      <td>sc_10001_ds_down_lstm_e300_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>297</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.223511</td>\n",
       "      <td>0.286754</td>\n",
       "      <td>sc_10001_ds_down_lstm_e300_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>298</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.223524</td>\n",
       "      <td>0.286755</td>\n",
       "      <td>sc_10001_ds_down_lstm_e300_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>299</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.223519</td>\n",
       "      <td>0.286755</td>\n",
       "      <td>sc_10001_ds_down_lstm_e300_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.223523</td>\n",
       "      <td>0.286755</td>\n",
       "      <td>sc_10001_ds_down_lstm_e300_ld01_b64_wF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1029 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Epoch  Training Loss  Validation Loss        F1  \\\n",
       "0        1         0.4314         0.237635  0.136534   \n",
       "2        2         0.1680         0.182450  0.310048   \n",
       "4        3         0.1130         0.161732  0.373332   \n",
       "6        4         0.0716         0.158205  0.466623   \n",
       "8        5         0.0493         0.170560  0.487552   \n",
       "..     ...            ...              ...       ...   \n",
       "604    296         0.1373         0.223521  0.286934   \n",
       "606    297         0.1376         0.223511  0.286754   \n",
       "608    298         0.1367         0.223524  0.286755   \n",
       "610    299         0.1387         0.223519  0.286755   \n",
       "612    300         0.1380         0.223523  0.286755   \n",
       "\n",
       "                                      Model  \n",
       "0        sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "2        sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "4        sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "6        sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "8        sc_1_ds_ori_linear_e15_ld01_b64_wF  \n",
       "..                                      ...  \n",
       "604  sc_10001_ds_down_lstm_e300_ld01_b64_wF  \n",
       "606  sc_10001_ds_down_lstm_e300_ld01_b64_wF  \n",
       "608  sc_10001_ds_down_lstm_e300_ld01_b64_wF  \n",
       "610  sc_10001_ds_down_lstm_e300_ld01_b64_wF  \n",
       "612  sc_10001_ds_down_lstm_e300_ld01_b64_wF  \n",
       "\n",
       "[1029 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTuning.modelPerformanceLog.bert_epoch_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning learning decay & batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:  sc_100000_ds_down\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611edbe7374c4cf9ba28557d77727d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1382 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5321de75014936b20e69fe7c265ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33b174e8e104ac6bf5aca16b6ba5e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  sc_100000_ds_down_lstm_e800_ld01_b64_wF\n",
      "{'loss': 1.5746, 'learning_rate': 4.994034090909091e-05, 'epoch': 0.95}\n",
      "{'eval_loss': 1.3054938316345215, 'eval_f1': 0.0, 'eval_runtime': 16.8179, 'eval_samples_per_second': 54.168, 'eval_steps_per_second': 0.892, 'epoch': 1.0}\n",
      "{'loss': 1.2782, 'learning_rate': 4.988068181818182e-05, 'epoch': 1.91}\n",
      "{'eval_loss': 1.1840885877609253, 'eval_f1': 0.0, 'eval_runtime': 18.032, 'eval_samples_per_second': 50.521, 'eval_steps_per_second': 0.832, 'epoch': 2.0}\n",
      "{'loss': 1.1791, 'learning_rate': 4.982102272727273e-05, 'epoch': 2.86}\n",
      "{'eval_loss': 1.0998882055282593, 'eval_f1': 0.0, 'eval_runtime': 17.8819, 'eval_samples_per_second': 50.945, 'eval_steps_per_second': 0.839, 'epoch': 3.0}\n",
      "{'loss': 1.1053, 'learning_rate': 4.976136363636364e-05, 'epoch': 3.82}\n",
      "{'eval_loss': 1.0259116888046265, 'eval_f1': 0.0, 'eval_runtime': 17.1009, 'eval_samples_per_second': 53.272, 'eval_steps_per_second': 0.877, 'epoch': 4.0}\n",
      "{'loss': 1.0384, 'learning_rate': 4.970170454545455e-05, 'epoch': 4.77}\n",
      "{'eval_loss': 0.9587966203689575, 'eval_f1': 0.0, 'eval_runtime': 17.5995, 'eval_samples_per_second': 51.763, 'eval_steps_per_second': 0.852, 'epoch': 5.0}\n",
      "{'loss': 0.974, 'learning_rate': 4.964204545454545e-05, 'epoch': 5.73}\n",
      "{'eval_loss': 0.8967070579528809, 'eval_f1': 0.0, 'eval_runtime': 18.4318, 'eval_samples_per_second': 49.425, 'eval_steps_per_second': 0.814, 'epoch': 6.0}\n",
      "{'loss': 0.9215, 'learning_rate': 4.958238636363637e-05, 'epoch': 6.68}\n",
      "{'eval_loss': 0.8376345634460449, 'eval_f1': 0.0, 'eval_runtime': 17.9503, 'eval_samples_per_second': 50.751, 'eval_steps_per_second': 0.836, 'epoch': 7.0}\n",
      "{'loss': 0.8659, 'learning_rate': 4.9522727272727275e-05, 'epoch': 7.64}\n",
      "{'eval_loss': 0.7817948460578918, 'eval_f1': 0.0, 'eval_runtime': 18.0493, 'eval_samples_per_second': 50.473, 'eval_steps_per_second': 0.831, 'epoch': 8.0}\n",
      "{'loss': 0.8162, 'learning_rate': 4.946306818181819e-05, 'epoch': 8.59}\n",
      "{'eval_loss': 0.7308738231658936, 'eval_f1': 0.0, 'eval_runtime': 18.3236, 'eval_samples_per_second': 49.717, 'eval_steps_per_second': 0.819, 'epoch': 9.0}\n",
      "{'loss': 0.7706, 'learning_rate': 4.940340909090909e-05, 'epoch': 9.55}\n",
      "{'eval_loss': 0.6852002143859863, 'eval_f1': 0.0, 'eval_runtime': 19.2408, 'eval_samples_per_second': 47.347, 'eval_steps_per_second': 0.78, 'epoch': 10.0}\n",
      "{'loss': 0.724, 'learning_rate': 4.9343749999999997e-05, 'epoch': 10.5}\n",
      "{'eval_loss': 0.6442583203315735, 'eval_f1': 0.0, 'eval_runtime': 16.8282, 'eval_samples_per_second': 54.135, 'eval_steps_per_second': 0.891, 'epoch': 11.0}\n",
      "{'loss': 0.6966, 'learning_rate': 4.9284090909090915e-05, 'epoch': 11.45}\n",
      "{'eval_loss': 0.6077360510826111, 'eval_f1': 0.0, 'eval_runtime': 17.111, 'eval_samples_per_second': 53.241, 'eval_steps_per_second': 0.877, 'epoch': 12.0}\n",
      "{'loss': 0.6603, 'learning_rate': 4.922443181818182e-05, 'epoch': 12.41}\n",
      "{'eval_loss': 0.575322687625885, 'eval_f1': 0.0, 'eval_runtime': 17.6531, 'eval_samples_per_second': 51.606, 'eval_steps_per_second': 0.85, 'epoch': 13.0}\n",
      "{'loss': 0.6234, 'learning_rate': 4.916477272727273e-05, 'epoch': 13.36}\n",
      "{'eval_loss': 0.5467277765274048, 'eval_f1': 0.0, 'eval_runtime': 18.0428, 'eval_samples_per_second': 50.491, 'eval_steps_per_second': 0.831, 'epoch': 14.0}\n",
      "{'loss': 0.6019, 'learning_rate': 4.9105113636363636e-05, 'epoch': 14.32}\n",
      "{'eval_loss': 0.5217381119728088, 'eval_f1': 0.0, 'eval_runtime': 17.6636, 'eval_samples_per_second': 51.575, 'eval_steps_per_second': 0.849, 'epoch': 15.0}\n",
      "{'loss': 0.5886, 'learning_rate': 4.904545454545455e-05, 'epoch': 15.27}\n",
      "{'eval_loss': 0.5000895261764526, 'eval_f1': 0.0, 'eval_runtime': 18.2624, 'eval_samples_per_second': 49.884, 'eval_steps_per_second': 0.821, 'epoch': 16.0}\n",
      "{'loss': 0.5607, 'learning_rate': 4.898579545454546e-05, 'epoch': 16.23}\n",
      "{'eval_loss': 0.481547087430954, 'eval_f1': 0.0, 'eval_runtime': 18.2047, 'eval_samples_per_second': 50.042, 'eval_steps_per_second': 0.824, 'epoch': 17.0}\n",
      "{'loss': 0.5382, 'learning_rate': 4.8926136363636365e-05, 'epoch': 17.18}\n",
      "{'eval_loss': 0.4664286971092224, 'eval_f1': 0.0, 'eval_runtime': 16.7395, 'eval_samples_per_second': 54.422, 'eval_steps_per_second': 0.896, 'epoch': 18.0}\n",
      "{'loss': 0.5341, 'learning_rate': 4.8866477272727276e-05, 'epoch': 18.14}\n",
      "{'eval_loss': 0.4550626575946808, 'eval_f1': 0.0, 'eval_runtime': 17.282, 'eval_samples_per_second': 52.714, 'eval_steps_per_second': 0.868, 'epoch': 19.0}\n",
      "{'loss': 0.5184, 'learning_rate': 4.880681818181819e-05, 'epoch': 19.09}\n",
      "{'eval_loss': 0.44650474190711975, 'eval_f1': 0.0, 'eval_runtime': 18.1665, 'eval_samples_per_second': 50.147, 'eval_steps_per_second': 0.826, 'epoch': 20.0}\n",
      "{'loss': 0.5105, 'learning_rate': 4.874715909090909e-05, 'epoch': 20.05}\n",
      "{'loss': 0.4977, 'learning_rate': 4.8687500000000004e-05, 'epoch': 21.0}\n",
      "{'eval_loss': 0.4400425851345062, 'eval_f1': 0.0, 'eval_runtime': 17.0975, 'eval_samples_per_second': 53.283, 'eval_steps_per_second': 0.877, 'epoch': 21.0}\n"
     ]
    }
   ],
   "source": [
    "model_idx = 100000\n",
    "scenarios = [\n",
    "            {'dataset': 'down'\n",
    "             ,'epoch': 800\n",
    "             ,'architecture': 'lstm'\n",
    "             ,'weight_decay': 0.1\n",
    "             ,'batch_size': 64\n",
    "            }\n",
    "\n",
    "            ]\n",
    "\n",
    "run_scenarios(model_idx, scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn_f1_score</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crf</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_1_ds_ori_linear_e15_ld01_b64_wF</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10_ds_down_linear_e15_ld01_b64_wF</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_100_ds_down_additional_linear_e50_ld01_b64_wF</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.3460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_101_ds_down_lstm_e70_ld01_b64_wF</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10000_ds_down_additional_linear_e100_ld05_b512_wF</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sklearn_f1_score      f1\n",
       "random forest                                                   0.14  0.0000\n",
       "crf                                                             0.14  0.0000\n",
       "sc_1_ds_ori_linear_e15_ld01_b64_wF                              0.60  0.5338\n",
       "sc_10_ds_down_linear_e15_ld01_b64_wF                            0.62  0.5491\n",
       "sc_100_ds_down_additional_linear_e50_ld01_b64_wF                0.42  0.3460\n",
       "sc_101_ds_down_lstm_e70_ld01_b64_wF                             0.14  0.0000\n",
       "sc_10000_ds_down_additional_linear_e100_ld05_b5...              0.14  0.0000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTuning.modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelTuning.modelPerformanceLog.bert_epoch_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training:  sc_100000_ds_scr\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614d2da8e940469a9391da86b498d7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/95286 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2db6e402d64083a920b9ce9ff96eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff42cc7ad9eb40e88d212fe8d6d23f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:  sc_100000_ds_scr_linear_e10_ld01_b128_wF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tina.vu/work/fun/sentilens_env_wipp/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0341, 'learning_rate': 4.5006711409395974e-05, 'epoch': 1.0}\n",
      "{'eval_loss': 0.29800546169281006, 'eval_f1': 0.5056252139297225, 'eval_runtime': 18.0774, 'eval_samples_per_second': 50.394, 'eval_steps_per_second': 0.443, 'epoch': 1.0}\n",
      "{'loss': 0.0006, 'learning_rate': 4.0013422818791946e-05, 'epoch': 2.0}\n",
      "{'eval_loss': 0.32127606868743896, 'eval_f1': 0.49374912550738204, 'eval_runtime': 17.0059, 'eval_samples_per_second': 53.57, 'eval_steps_per_second': 0.47, 'epoch': 2.0}\n",
      "{'loss': 0.0003, 'learning_rate': 3.5020134228187925e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 0.33480408787727356, 'eval_f1': 0.5111566636092125, 'eval_runtime': 16.9126, 'eval_samples_per_second': 53.865, 'eval_steps_per_second': 0.473, 'epoch': 3.0}\n",
      "{'loss': 0.0002, 'learning_rate': 3.0026845637583893e-05, 'epoch': 3.99}\n",
      "{'eval_loss': 0.3487224578857422, 'eval_f1': 0.4916302020721394, 'eval_runtime': 17.1002, 'eval_samples_per_second': 53.274, 'eval_steps_per_second': 0.468, 'epoch': 4.0}\n",
      "{'loss': 0.0002, 'learning_rate': 2.5033557046979865e-05, 'epoch': 4.99}\n",
      "{'eval_loss': 0.3631078600883484, 'eval_f1': 0.48606630026569597, 'eval_runtime': 18.5637, 'eval_samples_per_second': 49.074, 'eval_steps_per_second': 0.431, 'epoch': 5.0}\n",
      "{'loss': 0.0001, 'learning_rate': 2.004026845637584e-05, 'epoch': 5.99}\n",
      "{'eval_loss': 0.37215954065322876, 'eval_f1': 0.49033283157310176, 'eval_runtime': 19.9276, 'eval_samples_per_second': 45.715, 'eval_steps_per_second': 0.401, 'epoch': 6.0}\n",
      "{'loss': 0.0001, 'learning_rate': 1.5046979865771812e-05, 'epoch': 6.99}\n",
      "{'eval_loss': 0.3595803380012512, 'eval_f1': 0.5088633780187717, 'eval_runtime': 25.7811, 'eval_samples_per_second': 35.336, 'eval_steps_per_second': 0.31, 'epoch': 7.0}\n",
      "{'loss': 0.0001, 'learning_rate': 1.0053691275167786e-05, 'epoch': 7.99}\n",
      "{'eval_loss': 0.36876246333122253, 'eval_f1': 0.49896316690672404, 'eval_runtime': 18.332, 'eval_samples_per_second': 49.694, 'eval_steps_per_second': 0.436, 'epoch': 8.0}\n",
      "{'loss': 0.0, 'learning_rate': 5.060402684563759e-06, 'epoch': 8.99}\n",
      "{'eval_loss': 0.38171881437301636, 'eval_f1': 0.5153680133961264, 'eval_runtime': 18.3329, 'eval_samples_per_second': 49.692, 'eval_steps_per_second': 0.436, 'epoch': 9.0}\n",
      "{'loss': 0.0, 'learning_rate': 6.711409395973155e-08, 'epoch': 9.99}\n",
      "{'eval_loss': 0.3831060230731964, 'eval_f1': 0.5173377947392303, 'eval_runtime': 26.63, 'eval_samples_per_second': 34.21, 'eval_steps_per_second': 0.3, 'epoch': 10.0}\n",
      "{'train_runtime': 69364.6942, 'train_samples_per_second': 13.737, 'train_steps_per_second': 0.107, 'train_loss': 0.0035562589002797384, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08dd392e4fe4c42ac1314cd598e4a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/911 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_idx = 100000\n",
    "scenarios = [\n",
    "            {'dataset': 'scr'\n",
    "             ,'epoch': 10\n",
    "             ,'architecture': 'linear'\n",
    "             ,'weight_decay': 0.1\n",
    "             ,'batch_size': 128\n",
    "            }\n",
    "            \n",
    "            ]\n",
    "\n",
    "run_scenarios(model_idx, scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sklearn_f1_score</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crf</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_1_ds_ori_linear_e15_ld01_b64_wF</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10_ds_down_linear_e15_ld01_b64_wF</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_100_ds_down_additional_linear_e50_ld01_b64_wF</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.3460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_101_ds_down_lstm_e70_ld01_b64_wF</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10000_ds_down_additional_linear_e100_ld05_b512_wF</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10000_ds_down_additional_linear_e150_ld01_b64_wF</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.4807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_10001_ds_down_lstm_e300_ld01_b64_wF</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sc_100000_ds_scr_linear_e10_ld01_b128_wF</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.5562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sklearn_f1_score      f1\n",
       "random forest                                                   0.14  0.0000\n",
       "crf                                                             0.14  0.0000\n",
       "sc_1_ds_ori_linear_e15_ld01_b64_wF                              0.60  0.5338\n",
       "sc_10_ds_down_linear_e15_ld01_b64_wF                            0.62  0.5491\n",
       "sc_100_ds_down_additional_linear_e50_ld01_b64_wF                0.42  0.3460\n",
       "sc_101_ds_down_lstm_e70_ld01_b64_wF                             0.14  0.0000\n",
       "sc_10000_ds_down_additional_linear_e100_ld05_b5...              0.14  0.0000\n",
       "sc_10000_ds_down_additional_linear_e150_ld01_b6...              0.57  0.4807\n",
       "sc_10001_ds_down_lstm_e300_ld01_b64_wF                          0.33  0.3333\n",
       "sc_100000_ds_scr_linear_e10_ld01_b128_wF                        0.59  0.5562"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelTuning.modelPerformanceLog.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6. <a id='toc7_6_'></a>[Load saved model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1. <a id='toc7_6_1_'></a>[Load model manually](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForTokenClassification\n",
    "\n",
    "# # Reload the model\n",
    "# loaded_model = AutoModelForTokenClassification.from_pretrained('model/distilbert-base-uncased-absa-downsample-1-3').to(device) #output_model_dir\n",
    "# loaded_tokenizer = AutoTokenizer.from_pretrained('model/distilbert-base-uncased-absa-downsample-1-3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = 99\n",
    "# sample_input = df_train.iloc[num]['text']\n",
    "# print(sample_input)\n",
    "# print(df_train.iloc[num]['aspects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming you have some input data\n",
    "# input_data = [sample_input]\n",
    "\n",
    "# # Tokenize and get predictions\n",
    "# inputs = loaded_tokenizer(input_data, is_split_into_words=True, return_tensors=\"pt\")\n",
    "\n",
    "# input_ids = inputs[\"input_ids\"].to(device)\n",
    "# attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "# # Make predictions\n",
    "# with torch.no_grad():\n",
    "#   outputs = loaded_model(input_ids, attention_mask)\n",
    "\n",
    "# predicted_label_idx = torch.argmax(outputs.logits, axis=-1).cpu().numpy()\n",
    "# df_res = pd.DataFrame({'predicted_label': predicted_label_idx.tolist(), \n",
    "#                       'input_ids': inputs['input_ids'].numpy().tolist()}\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index2tag_new = loaded_model.config.id2label.copy()\n",
    "# index2tag_new[-100] = \"IGN\"\n",
    "# df_res[\"input_tokens\"] = df_res[\"input_ids\"].apply(\n",
    "#     lambda x: loaded_tokenizer.convert_ids_to_tokens(x))\n",
    "# df_res[\"predicted_label_text\"] = df_res[\"predicted_label\"].apply(\n",
    "#     lambda x: [index2tag_new[i] for i in x])\n",
    "# df_res['predicted_label'] = df_res.apply(\n",
    "#     lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "# df_res['predicted_label_text'] = df_res.apply(\n",
    "#     lambda x: x['predicted_label_text'][:len(x['input_ids'])], axis=1)\n",
    "\n",
    "# df_res_tokens = df_res.apply(pd.Series.explode)\n",
    "\n",
    "# df_res_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2. <a id='toc7_6_2_'></a>[Pipeline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "\n",
    "# token_classifier = pipeline(\n",
    "#     \"token-classification\", model='model/distilbert-base-uncased-absa-downsample-1-3', aggregation_strategy=\"simple\"\n",
    "# )\n",
    "# token_classifier(sample_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentilens_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
